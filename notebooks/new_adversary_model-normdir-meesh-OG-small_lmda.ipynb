{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed182ac-bc78-4d44-b703-561a052cfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import EfficientNet\n",
    "from utils.loss_functions import tkd_kdloss\n",
    "from utils.loss_functions import DKDLoss, DirectNormLoss, KDLoss\n",
    "from torch.optim import lr_scheduler\n",
    "from utils.misc_tools import best_LR_wider\n",
    "\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7437867-ecd5-4643-9fb8-a2fc1d1f15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters / Inputs\n",
    "teacher_learning_rate = 0.0005 # 0.096779\n",
    "student_learning_rate = teacher_learning_rate / 5\n",
    "teacher_epochs = 10\n",
    "student_epochs = teacher_epochs\n",
    "teacher_patience = 12\n",
    "student_patience = 180\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "weight_decay = 1e-5\n",
    "epsilon = 0.05\n",
    "margin = 0.01\n",
    "num_classes = 16\n",
    "base_save_dir = \"disparity_pipeline_out\"\n",
    "teacher_name = 'efficientnetb3'\n",
    "\n",
    "# list of lambda values to loop through for grid search\n",
    "teacher_lambda_factor_list = [0]\n",
    "# student_lambda_factor_list = [0,20,40,80,100,150]\n",
    "# student_lambda_factor_list = [0,5,10,15,20,25,30,40,80,100,150]\n",
    "# student_lambda_factor_list = [0,0.5,1,1.5,2, 2.5,3]\n",
    "# student_lambda_factor_list = [1.5]\n",
    "student_lambda_factor_list = [0,0.5,1,1.5,2,3,5,10,15,20,25,30,40,80,100,150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e9799-abe8-4878-88f0-b2402d0fa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels used including for plotting\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "class_names_new = [f\"Class {label}\" for label in range(num_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11b671f-0b71-438a-bf75-7ceb293b72ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eabaae7-724f-4ee9-9df8-9463d205b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './WIDER/Annotations/wider_attribute_trainval.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    data = json.load(file)\n",
    "\n",
    "class_idx = data['scene_id_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142a7d7-9627-48b6-a5aa-86527150ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_mapping = {\n",
    "    0: \"Team_Sports\",\n",
    "    1: \"Celebration\",\n",
    "    2: \"Parade\",\n",
    "    3: \"Waiter_Or_Waitress\",\n",
    "    4: \"Individual_Sports\",\n",
    "    5: \"Surgeons\",\n",
    "    6: \"Spa\",\n",
    "    7: \"Law_Enforcement\",\n",
    "    8: \"Business\",\n",
    "    9: \"Dresses\",\n",
    "    10: \"Water_Activities\",\n",
    "    11: \"Picnic\",\n",
    "    12: \"Rescue\",\n",
    "    13: \"Cheering\",\n",
    "    14: \"Performance_And_Entertainment\",\n",
    "    15: \"Family\"\n",
    "}\n",
    "\n",
    "# Ensure that all 16 new classes are covered\n",
    "# If some classes are not explicitly mentioned in new_label_mapping, add them\n",
    "for i in range(num_classes):\n",
    "    if i not in new_label_mapping:\n",
    "        new_label_mapping[i] = \"Additional Category {}\".format(i)\n",
    "\n",
    "class_idx = new_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab11dc9-d6c6-4c45-8452-cff149af8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "\n",
    "        # Create a mapping from old labels to new labels\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "\n",
    "        self.new_label_mapping = {\n",
    "            0: 2,  # Parade\n",
    "            1: 8,  # Business\n",
    "            2: 7,  # Law Enforcement\n",
    "            3: 14,  # Performance and Entertainment\n",
    "            4: 1,  # Celebration\n",
    "            5: 13,  # Cheering\n",
    "            6: 8,  # Business\n",
    "            7: 8,  # Business\n",
    "            8: 1,  # Celebration\n",
    "            9: 14,  # Performance and Entertainment\n",
    "            10: 15, # Family\n",
    "            11: 15, # Family\n",
    "            12: 11, # Picnic\n",
    "            13: 7, # Law Enforcement\n",
    "            14: 6, # Spa\n",
    "            15: 13, # Cheering\n",
    "            16: 5, # Surgeons\n",
    "            17: 3, # Waiter or Waitress\n",
    "            18: 4, # Individual Sports\n",
    "            19: 0, # Team Sports\n",
    "            20: 0, # Team Sports\n",
    "            21: 0, # Team Sports\n",
    "            22: 4, # Individual Sports\n",
    "            23: 10, # Water Activities\n",
    "            24: 4, # Individual Sports\n",
    "            25: 1, # Celebration\n",
    "            26: 9, # Dresses\n",
    "            27: 12, # Rescue\n",
    "            28: 10,# Water Activities\n",
    "            29: 0  # Team Sports\n",
    "        }\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        # Initialize transformations directly\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ] \n",
    "        )\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                ] \n",
    "            )        \n",
    "\n",
    "        self.anns = []\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs:\n",
    "            t.append(transforms.RandAugment())\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "\n",
    "        return transforms.Compose(t)\n",
    "    \n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            json_data = json.load(open(ann_file, \"r\"))\n",
    "            self.anns += json_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure the index is within bounds\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            img = Image.open(f'WIDER/Image/{ann[\"file_name\"]}').convert(\"RGB\")\n",
    "\n",
    "            # x, y, w, h = ann['bbox']\n",
    "            # img_area = img.crop([x, y, x+w, y+h])\n",
    "            img_area = self.augment(img)\n",
    "            img_area = self.transform(img_area)\n",
    "            attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "            attributes_list = [[max(0, element) for element in inner_list] for inner_list in attributes_list]\n",
    "            num_people = len(attributes_list)\n",
    "            attributes_distribution = [max(sum(attribute), 0)/num_people for attribute in zip(*attributes_list)]\n",
    "            # Extract label from image path\n",
    "            img_path = f'WIDER/Image/{ann[\"file_name\"]}'\n",
    "            label = self.extract_label(img_path)\n",
    "            \n",
    "            return {\n",
    "                \"file\": ann[\"file_name\"],\n",
    "                \"label\": label,\n",
    "                \"target\": torch.tensor([attributes_distribution[0]], dtype=torch.float32),\n",
    "                \"img\": img_area\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during the processing of an image, log the error and the index\n",
    "            print(f\"Error processing image at index {idx}: {e}\")\n",
    "            # Instead of returning None, raise the exception\n",
    "            raise\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            new_label_mapping = self.new_label_mapping[remapped_label]\n",
    "            return new_label_mapping\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c75bb-56ba-497e-8160-745d070907fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c07e8c-9d6a-4f00-9b72-dbb9f35f6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188300a-7896-4ed7-ba20-549a3057fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = DataSet(train_file, augs = ['RandAugment'], img_size = 226, dataset = 'wider')\n",
    "train_dataset = DataSet(train_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "test_dataset = DataSet(test_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                         num_workers=num_workers, collate_fn=custom_collate)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b6bb60-dc13-4d86-b5a9-f84b376823dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def calculate_recall_multiclass(conf_matrix):\n",
    "    recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    recalls[np.isnan(recalls)] = 0\n",
    "    return recalls\n",
    "\n",
    "def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes):\n",
    "    predictions = pred.cpu()\n",
    "    true_labels = label.cpu()\n",
    "    gender = gender.cpu()\n",
    "\n",
    "    # Identify male and female indices based on the gender threshold\n",
    "    male_indices = np.where(gender >= 0.5)[0]\n",
    "    female_indices = np.where(gender < 0.5)[0]\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot_labels = one_hot_encode(true_labels, num_classes=num_classes)\n",
    "    one_hot_preds = one_hot_encode(predictions, num_classes=num_classes)\n",
    "\n",
    "    # Initialize recall arrays\n",
    "    male_recall = np.zeros(num_classes)\n",
    "    female_recall = np.zeros(num_classes)\n",
    "\n",
    "    # Extract predictions and labels for male and female indices\n",
    "    male_predictions = np.argmax(one_hot_preds[male_indices], axis=1)\n",
    "    female_predictions = np.argmax(one_hot_preds[female_indices], axis=1)\n",
    "    male_labels = np.argmax(one_hot_labels[male_indices], axis=1)\n",
    "    female_labels = np.argmax(one_hot_labels[female_indices], axis=1)\n",
    "\n",
    "    # Check if the class labels are within the expected range\n",
    "    assert (0 <= male_predictions.min() < num_classes) and (0 <= male_predictions.max() < num_classes), \"Invalid class indices in male predictions\"\n",
    "    assert (0 <= female_predictions.min() < num_classes) and (0 <= female_predictions.max() < num_classes), \"Invalid class indices in female predictions\"\n",
    "    assert (0 <= male_labels.min() < num_classes) and (0 <= male_labels.max() < num_classes), \"Invalid class indices in male labels\"\n",
    "    assert (0 <= female_labels.min() < num_classes) and (0 <= female_labels.max() < num_classes), \"Invalid class indices in female labels\"\n",
    "\n",
    "    # Calculate confusion matrices for each gender\n",
    "    male_conf_matrix = confusion_matrix(male_labels, male_predictions, labels=np.arange(num_classes))\n",
    "    female_conf_matrix = confusion_matrix(female_labels, female_predictions, labels=np.arange(num_classes))\n",
    "\n",
    "    # Calculate recall for each class and gender\n",
    "    male_recall[:len(male_conf_matrix)] = calculate_recall_multiclass(male_conf_matrix)\n",
    "    female_recall[:len(female_conf_matrix)] = calculate_recall_multiclass(female_conf_matrix)\n",
    "\n",
    "    return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5bc74-4a24-42a0-9ca4-a4e04861d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=256):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  # Outputting a single value for bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4478596-7a51-4d2f-8c6f-deb4f1274be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_fea(model, dataloader):\n",
    "    ''' Used to extract the feature embeddings in a teacher model '''\n",
    "    \n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    model.avgpool.register_forward_hook(get_features('feats'))\n",
    "\n",
    "    EMB = {}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch_data in dataloader:\n",
    "            FEATS = []\n",
    "            features = {}\n",
    "            # images, labels = images.cuda(), labels.cuda()\n",
    "            images = batch_data[\"img\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "            curr_batch_size = len(images)\n",
    "\n",
    "\n",
    "            # compute output\n",
    "            # emb_fea, logits = model(images, embed=True)\n",
    "            outputs = model(images)\n",
    "            # feats = features['feats'].cpu().numpy()\n",
    "            # emb_fea = feats.flatten()\n",
    "            FEATS.append(features['feats'].cpu().numpy())\n",
    "            emb_fea = np.concatenate(FEATS)\n",
    "            # reshape embedding features to flatten \n",
    "            emb_fea = emb_fea.reshape((curr_batch_size, emb_fea.shape[1]))\n",
    "\n",
    "\n",
    "            for emb, i in zip(emb_fea, labels):\n",
    "                i = i.item()\n",
    "                emb_size = len(emb) \n",
    "                if str(i) in EMB:\n",
    "                    for j in range(emb_size):\n",
    "                        EMB[str(i)][j].append(round(emb[j].item(), 4))\n",
    "                else:\n",
    "                    EMB[str(i)] = [[] for _ in range(emb_size)]\n",
    "                    for j in range(emb_size):\n",
    "                        EMB[str(i)][j].append(round(emb[j].item(), 4))\n",
    "\n",
    "    for key, value in EMB.items():\n",
    "        for i in range(emb_size):\n",
    "            EMB[key][i] = round(np.array(EMB[key][i]).mean(), 4)\n",
    "\n",
    "    return EMB\n",
    "\n",
    "def retrieve_teacher_class_weights(model, lmda, data_name, dataloader, model_name, best_model_weights):\n",
    "    ''' Use the extracted feature embeddings to create a json of class means for teacher'''\n",
    "\n",
    "    # session = boto3.session.Session()\n",
    "    # s3 = session.client('s3')\n",
    "\n",
    "    # teacher_model_weights_buffer = io.BytesIO()\n",
    "    # s3.download_fileobj(bucket_name, model_weight_path, teacher_model_weights_buffer)\n",
    "    # teacher_model_weights_buffer.seek(0)  \n",
    "\n",
    "    # # Load the model\n",
    "    # # model = models_package.__dict__[model_name](num_class=num_class)\n",
    "    # checkpoint = torch.load(teacher_model_weights_buffer)\n",
    "    # # print(\"Keys in checkpoint:\", checkpoint.keys())\n",
    "    \n",
    "    # print(\"model is loaded properly\")\n",
    "    # checkpoint = model.state_dict()\n",
    "    checkpoint = best_model_weights\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint.items():\n",
    "        name = k[7:] if k.startswith('module.') else k\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "    # emb = get_emb_fea(model=model, dataloader=dataloader, batch_size=batch_size)\n",
    "    # emb_json = json.dumps(emb, indent=4)\n",
    "    # with open(\"./class_means/{}_embedding_fea/{}.json\".format(data_name, model_name), 'w', encoding='utf-8') as f:\n",
    "    #     f.write(emb_json)\n",
    "\n",
    "    emb = get_emb_fea(model=model, dataloader=dataloader)\n",
    "    emb_json = json.dumps(emb, indent=4)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    output_dir = \"./class_means/{}_embedding_fea\".format(data_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(\"{}/{}_lmda_{}.json\".format(output_dir, model_name, lmda), 'w', encoding='utf-8') as f:\n",
    "        f.write(emb_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18d2428-0165-453f-a3a9-341cb7cf0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_teacher(teacher, teacher_optimizer, teacher_loss_fn, patience=teacher_patience, \n",
    "                  epochs=teacher_epochs, device=device, base_save_dir=base_save_dir, teacher_name=teacher_name):\n",
    "    \n",
    "    train_accuracies = []\n",
    "    train_disparities = []\n",
    "    train_mean_non_zero_abs_disparities = []\n",
    "    train_losses = []\n",
    "    train_main_losses = []\n",
    "    val_accuracies = []\n",
    "    val_disparities = []\n",
    "    val_mean_non_zero_abs_disparities = []\n",
    "    val_losses = []\n",
    "    val_main_losses = []\n",
    "    \n",
    "    patience_counter = 0 \n",
    "    best_val_accuracy = 0\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_mean_abs_disparity = 0\n",
    "    teacher_best_model_state = None\n",
    "\n",
    "    # Create a subdirectory for the current lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lambda_factor}')\n",
    "    os.makedirs(lambda_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Training Teacher with Lambda Value of {lambda_factor}')\n",
    "    \n",
    "    # Training and Validation Loop\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize metrics for each epoch\n",
    "        epoch_train_disparities = []\n",
    "        epoch_train_losses = []\n",
    "        epoch_train_accuracies = []\n",
    "        epoch_val_disparities = []\n",
    "        epoch_val_losses = []\n",
    "        epoch_val_accuracies = []\n",
    "    \n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Training\n",
    "        for batch_data in tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs}, Training'):\n",
    "            # Load data to device\n",
    "            teacher.train()\n",
    "            teacher.to(device)\n",
    "            images = batch_data[\"img\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "            gender_scores = batch_data[\"target\"].to(device)\n",
    "    \n",
    "            teacher_optimizer.zero_grad()            \n",
    "            # Forward pass through actor\n",
    "            teacher_output = teacher(images)\n",
    "    \n",
    "            main_loss = teacher_loss_fn(teacher_output, labels)\n",
    "            class_predictions = torch.argmax(teacher_output, dim=1)\n",
    "\n",
    "\n",
    "            main_loss.backward()\n",
    "            teacher_optimizer.step()\n",
    "    \n",
    "            # Calculate and accumulate metrics\n",
    "            accuracy = (class_predictions == labels).float().mean().item()\n",
    "            epoch_train_accuracies.append(accuracy)\n",
    "    \n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (class_predictions == labels).sum().item()\n",
    "            num_batches += 1\n",
    "            recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "            confusion_male += recall_diff[1]\n",
    "            confusion_female += recall_diff[2]\n",
    "            bias = np.mean(recall_diff[0])\n",
    "            epoch_train_disparities.append(bias)        \n",
    "            # Record the losses\n",
    "            epoch_train_losses.append(main_loss.item())\n",
    "    \n",
    "        confusion_male /= num_batches\n",
    "        confusion_female /= num_batches\n",
    "    \n",
    "        # Calculate training metrics for the epoch\n",
    "        train_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "        train_non_zero_abs_values = np.abs(train_epoch_disparity[train_epoch_disparity != 0])\n",
    "        \n",
    "        # Store average training metrics for the epoch\n",
    "        train_accuracy = np.mean(epoch_train_accuracies)\n",
    "        train_disparity = np.mean(epoch_train_disparities)\n",
    "        train_mean_non_zero_abs_disparity = np.mean(train_non_zero_abs_values)\n",
    "        train_main_loss = np.mean([x for x in epoch_train_losses])\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_disparities.append(train_disparity)\n",
    "        train_mean_non_zero_abs_disparities.append(train_mean_non_zero_abs_disparity)\n",
    "        train_main_losses.append(train_main_loss)\n",
    "\n",
    "    \n",
    "        # Validation Phase\n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        teacher.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(testloader, desc=f'Epoch {epoch+1}/{epochs}, Validation'):\n",
    "                # Load data to device\n",
    "                images = batch_data[\"img\"].to(device)\n",
    "                labels = batch_data[\"label\"].to(device)\n",
    "                gender_scores = batch_data[\"target\"].to(device)\n",
    "        \n",
    "                # Forward pass\n",
    "                teacher_output = teacher(images)\n",
    "                class_predictions = torch.argmax(teacher_output, dim=1)\n",
    "        \n",
    "                # Calculate and accumulate validation metrics\n",
    "                accuracy = (class_predictions == labels).float().mean().item()\n",
    "    \n",
    "                # Compute bias\n",
    "                num_batches += 1\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "                \n",
    "                # Calculate validation losses (similar to training losses)\n",
    "                batch_bias = np.mean(recall_diff[0])\n",
    "                val_main_loss = teacher_loss_fn(teacher_output, labels)\n",
    "            \n",
    "                epoch_val_accuracies.append(accuracy)\n",
    "                epoch_val_losses.append(val_main_loss.item())\n",
    "                \n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "    \n",
    "            val_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_non_zero_abs_values = np.abs(val_epoch_disparity[val_epoch_disparity != 0])\n",
    "    \n",
    "            # Store average training metrics for the epoch\n",
    "            val_accuracy = np.mean(epoch_val_accuracies)\n",
    "            val_disparity = np.mean(epoch_val_disparities)\n",
    "            val_mean_non_zero_abs_disparity = np.mean(val_non_zero_abs_values)\n",
    "            val_main_loss = np.mean([x for x in epoch_val_losses])\n",
    "\n",
    "        \n",
    "            val_accuracies.append(val_accuracy)\n",
    "            val_disparities.append(val_disparity)\n",
    "            val_mean_non_zero_abs_disparities.append(val_mean_non_zero_abs_disparity)\n",
    "            val_main_losses.append(val_main_loss)\n",
    "\n",
    "\n",
    "            # Check if current validation combined loss is lower than the best combined loss\n",
    "        if val_main_loss < best_val_loss:\n",
    "            best_val_loss = val_main_loss\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_mean_non_zero_abs_disparity = val_mean_non_zero_abs_disparity\n",
    "        \n",
    "            # Create a mapping of class recall disparities\n",
    "            class_recall_mapping = {class_name: val_epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "        \n",
    "            teacher_best_model_state = {\n",
    "                'epoch': epoch,\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'best_val_mean_abs_disparity': best_val_mean_non_zero_abs_disparity,\n",
    "                'class_recall_mapping': class_recall_mapping\n",
    "            }\n",
    "            save_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lambda_factor}.pth')\n",
    "            torch.save(teacher_best_model_state, save_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"TEACHER - Lambda {lambda_factor} - Epoch {epoch + 1} Metrics:\")\n",
    "        print(\"-\"*50)\n",
    "        print(f\"TRAINING Accuracy: {train_accuracy:.6f}, VALIDATION Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"TRAINING Disparity: {train_mean_non_zero_abs_disparity:.6f}, VALIDATION Disparity: {val_mean_non_zero_abs_disparity:.4f}\")\n",
    "        print(f\"TRAINING Main Loss: {train_main_loss:.6f}, VALIDATION Main Loss: {val_main_loss:.4f}\")\n",
    "        print(\"-\"*50 + \"\\n\")\n",
    "        # Print disparities by class label\n",
    "        for class_label, recall_diff in class_recall_mapping.items():\n",
    "            print(f\"Class {class_label}: Val Disparity = {recall_diff}\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "      \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot Training and Validation Accuracy\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(train_accuracies, label='Training Accuracy')\n",
    "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "        plt.title('Teacher Training and Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training and Validation Disparity\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(train_mean_non_zero_abs_disparities, label='Training Mean Absolute Disparity')\n",
    "        plt.plot(val_mean_non_zero_abs_disparities, label='Validation Mean Absolute Disparity')\n",
    "        plt.title('Teacher Training and Validation Mean Absolute Disparity')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Absolute Disparity')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(train_main_losses, label='Training Main Loss')\n",
    "        plt.title('Teacher Training Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    \n",
    "        # Plot Validation Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(val_main_losses, label='Validation Main Loss')\n",
    "        plt.title('Teacher Validation Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    best_epoch = teacher_best_model_state['epoch'] + 1 if teacher_best_model_state else epochs\n",
    "    # extract class embeddings for teacher\n",
    "    retrieve_teacher_class_weights(teacher, lambda_factor, 'WIDER', trainloader, teacher_name, best_model_weights = teacher_best_model_state['teacher_state_dict'])\n",
    "    print(f\"Finished Training TEACHER with lambda value of {lambda_factor}. Best epoch number: {best_epoch}\")\n",
    "\n",
    "    return teacher_best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777235b-0ae2-47e8-a1a8-562402565000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_student(student, teacher, student_optimizer, student_loss_fn, critic, critic_optimizer, critic_loss_fn,\n",
    "                  lambda_factor, momentum, t, warm_up, weight_decay, T_EMB, num_classes, epsilon=epsilon, margin=margin, patience=student_patience, \n",
    "                  epochs=student_epochs, device=device, base_save_dir=base_save_dir, student_scheduler=None, critic_scheduler=None):\n",
    "    \n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    train_accuracies = []\n",
    "    train_disparities = []\n",
    "    train_mean_non_zero_abs_disparities = []\n",
    "    train_losses = []\n",
    "    train_main_losses = []\n",
    "    train_critic_losses = []\n",
    "    train_kd_losses = []\n",
    "    val_accuracies = []\n",
    "    val_disparities = []\n",
    "    val_mean_non_zero_abs_disparities = []\n",
    "    val_losses = []\n",
    "    val_main_losses = []\n",
    "    val_critic_losses = []\n",
    "    val_kd_losses = []\n",
    "    \n",
    "    patience_counter = 0 \n",
    "    best_val_accuracy = 0\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_mean_abs_disparity = 0\n",
    "    student_best_model_state = None\n",
    "\n",
    "    warm_up=20.0 #loss weight warm up epochs\n",
    "    cls_loss_factor =1.0 # cls loss weight factor\n",
    "    kd_loss_factor =1.0 #KD loss weight factor\n",
    "    nd_loss_factor =1.0 # ND loss weight factor\n",
    "    kd_loss = KDLoss(kl_loss_factor=kd_loss_factor, T=t).to(device)\n",
    "    nd_loss = DirectNormLoss(num_class=num_classes, nd_loss_factor=nd_loss_factor).to(device)\n",
    "    \n",
    "    # set up teacher class embeddings\n",
    "    T_EMB = T_EMB\n",
    "    \n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "\n",
    "    student.to(device)\n",
    "    critic.to(device)\n",
    "    \n",
    "    # Create a subdirectory for the current lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'STUDENT_lambda_{lambda_factor}')\n",
    "    os.makedirs(lambda_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Training Student with Lambda Value of {lambda_factor}')\n",
    "\n",
    "    # Training and Validation Loop\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize metrics for each epoch\n",
    "        epoch_train_disparities = []\n",
    "        epoch_train_losses = []\n",
    "        epoch_train_accuracies = []\n",
    "        epoch_val_disparities = []\n",
    "        epoch_val_losses = []\n",
    "        epoch_val_accuracies = []\n",
    "    \n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Training\n",
    "        student.train()\n",
    "        for batch_data in tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs}, Training'):\n",
    "            # Load data to device\n",
    "            images = batch_data[\"img\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "            gender_scores = batch_data[\"target\"].to(device)\n",
    "            curr_batch_size = len(images)\n",
    "            \n",
    "            # set up feature collection for student\n",
    "            s_FEATS = []\n",
    "            features = {}\n",
    "\n",
    "            # set a hook for penultimate layer feature embedding\n",
    "            student.avgpool.register_forward_hook(get_features('feats'))\n",
    "            \n",
    "            # compute output\n",
    "            student_output = student(images)\n",
    "            class_predictions = torch.argmax(student_output, dim=1)\n",
    "\n",
    "            s_FEATS.append(features['feats'].cpu().numpy())\n",
    "            s_emb = np.concatenate(s_FEATS)\n",
    "            # reshape embedding features to flatten \n",
    "            s_emb = s_emb.reshape((curr_batch_size, s_emb.shape[1]))\n",
    "            s_emb = torch.from_numpy(s_emb)\n",
    "            s_emb = s_emb.to(device)\n",
    "    \n",
    "            # fix embedding output on student model\n",
    "            s_emb_size = 1280\n",
    "            t_emb_size = 1536\n",
    "            \n",
    "            emb_inflate = nn.Sequential(\n",
    "                nn.BatchNorm1d(s_emb_size),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(s_emb_size, t_emb_size)\n",
    "                )\n",
    "            # clean_model\n",
    "            for m in student.modules():\n",
    "                if isinstance(m, nn.BatchNorm1d):\n",
    "                    m.weight.data.fill_(1)\n",
    "                    m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    m.bias.data.zero_()\n",
    "        \n",
    "            # inflate size of student embeddings to match teacher embedding size\n",
    "            emb_inflate.to(device)\n",
    "            s_emb = emb_inflate(s_emb)\n",
    "        \n",
    "            logit_inflate = nn.Sequential(\n",
    "                nn.Linear(1536, num_classes),\n",
    "                )\n",
    "            logit_inflate.to(device)\n",
    "            s_out = logit_inflate(s_emb)\n",
    "\n",
    "            \n",
    "            ##\n",
    "            with torch.no_grad():\n",
    "                # set up feature collection for teacher\n",
    "                t_FEATS = []\n",
    "                features = {}\n",
    "\n",
    "                # set a hook for penultimate layer feature embedding\n",
    "                teacher.avgpool.register_forward_hook(get_features('feats'))\n",
    "\n",
    "                # compute outputs\n",
    "                teacher_output = teacher(images)\n",
    "    \n",
    "                t_FEATS.append(features['feats'].cpu().numpy())\n",
    "                t_emb = np.concatenate(t_FEATS)\n",
    "                # reshape embedding features to flatten \n",
    "                t_emb = t_emb.reshape((curr_batch_size, t_emb.shape[1]))\n",
    "            \n",
    "            t_emb = torch.from_numpy(t_emb)    \n",
    "            t_emb = t_emb.to(device)\n",
    "            t_out = teacher.classifier(t_emb)\n",
    "\n",
    "                \n",
    "            # Compute bias\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (class_predictions == labels).sum().item()\n",
    "            num_batches += 1\n",
    "            recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "            confusion_male += recall_diff[1]\n",
    "            confusion_female += recall_diff[2]\n",
    "            bias = np.mean(recall_diff[0])\n",
    "            bias_mean = torch.tensor([bias], device=device, dtype=torch.float32)\n",
    "\n",
    "            critic_optimizer.zero_grad()\n",
    "            \n",
    "            for param in critic.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in student.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            critic.train()\n",
    "            student.eval()\n",
    "\n",
    "            critic_output = critic(student_output)\n",
    "            critic_loss = critic_loss_fn(critic_output, bias_mean)\n",
    "            critic_loss.backward(retain_graph=True)\n",
    "    \n",
    "            critic_optimizer.step()\n",
    "    \n",
    "            for param in critic.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in student.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            student.train()\n",
    "            critic.eval()\n",
    "    \n",
    "            student_optimizer.zero_grad()\n",
    "    \n",
    "            critic_output = critic(student_output)\n",
    "            \n",
    "            #cls loss\n",
    "            cls_loss = student_loss_fn(student_output, labels) * cls_loss_factor\n",
    "            # KD loss\n",
    "            div_loss = kd_loss(s_out = s_out, t_out = t_out) * min(1.0, epoch/warm_up)\n",
    "            # ND loss\n",
    "            norm_dir_loss = nd_loss(s_emb=s_emb, t_emb=t_emb, T_EMB=T_EMB, labels=labels)\n",
    "    \n",
    "            # combined_loss = (cls_loss + div_loss + norm_dir_loss) * max(1, lambda_factor * (abs(critic_output[0][0]) - epsilon + margin) + 1)\n",
    "            combined_loss = (cls_loss + div_loss + norm_dir_loss) * max(1, lambda_factor * (abs(critic_output[0][0]) - epsilon + margin) + 1) \n",
    "\n",
    "            combined_loss.backward(retain_graph=True)\n",
    "            student_optimizer.step()\n",
    "    \n",
    "            # Calculate and accumulate metrics\n",
    "            accuracy = (class_predictions == labels).float().mean().item()\n",
    "            epoch_train_accuracies.append(accuracy)\n",
    "            epoch_train_disparities.append(bias)\n",
    "        \n",
    "            # Record the losses\n",
    "            epoch_train_losses.append((combined_loss.item(), cls_loss.item(), critic_loss.item(), div_loss.item(), norm_dir_loss.item()))\n",
    "    \n",
    "        confusion_male /= num_batches\n",
    "        confusion_female /= num_batches\n",
    "    \n",
    "        # Calculate training metrics for the epoch\n",
    "        train_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "        train_non_zero_abs_values = np.abs(train_epoch_disparity[train_epoch_disparity != 0])\n",
    "        \n",
    "        # Store average training metrics for the epoch\n",
    "        train_accuracy = np.mean(epoch_train_accuracies)\n",
    "        train_disparity = np.mean(epoch_train_disparities)\n",
    "        train_mean_non_zero_abs_disparity = np.mean(train_non_zero_abs_values)\n",
    "        train_combined_loss = np.mean([x[0] for x in epoch_train_losses])\n",
    "        train_main_loss = np.mean([x[1] for x in epoch_train_losses])\n",
    "        train_critic_loss = np.mean([x[2] for x in epoch_train_losses])\n",
    "        train_kd_loss = np.mean([x[3] for x in epoch_train_losses])\n",
    "        \n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_disparities.append(train_disparity)\n",
    "        train_mean_non_zero_abs_disparities.append(train_mean_non_zero_abs_disparity)\n",
    "        train_losses.append(train_combined_loss)\n",
    "        train_main_losses.append(train_main_loss)\n",
    "        train_critic_losses.append(train_critic_loss)\n",
    "        train_kd_losses.append(train_kd_loss)\n",
    "\n",
    "        # Validation Phase\n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        student.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(testloader, desc=f'Epoch {epoch+1}/{epochs}, Validation'):\n",
    "                # Load data to device\n",
    "                images = batch_data[\"img\"].to(device)\n",
    "                labels = batch_data[\"label\"].to(device)\n",
    "                gender_scores = batch_data[\"target\"].to(device)\n",
    "                curr_batch_size = len(images)\n",
    "\n",
    "                                \n",
    "                # set up feature collection for student\n",
    "                s_FEATS = []\n",
    "                features = {}\n",
    "\n",
    "                # set a hook for penultimate layer feature embedding\n",
    "                student.avgpool.register_forward_hook(get_features('feats'))\n",
    "                \n",
    "                # Forward pass\n",
    "                student_output = student(images)\n",
    "                val_critic_output = critic(student_output)\n",
    "                class_predictions = torch.argmax(student_output, dim=1)\n",
    "                \n",
    "    \n",
    "                s_FEATS.append(features['feats'].cpu().numpy())\n",
    "                s_emb = np.concatenate(s_FEATS)\n",
    "                \n",
    "                # reshape embedding features to flatten \n",
    "                s_emb = s_emb.reshape((curr_batch_size, s_emb.shape[1]))\n",
    "                s_emb = torch.from_numpy(s_emb)\n",
    "                s_emb = s_emb.to(device)\n",
    "        \n",
    "                # fix embedding output on student model\n",
    "                s_emb_size = 1280\n",
    "                t_emb_size = 1536\n",
    "                \n",
    "                emb_inflate = nn.Sequential(\n",
    "                    nn.BatchNorm1d(s_emb_size),\n",
    "                    nn.Dropout(0.5),\n",
    "                    nn.Linear(s_emb_size, t_emb_size)\n",
    "                    )\n",
    "                # clean_model\n",
    "                for m in student.modules():\n",
    "                    if isinstance(m, nn.BatchNorm1d):\n",
    "                        m.weight.data.fill_(1)\n",
    "                        m.bias.data.zero_()\n",
    "                    elif isinstance(m, nn.Linear):\n",
    "                        m.bias.data.zero_()\n",
    "            \n",
    "                # inflate size of student embeddings to match teacher embedding size\n",
    "                emb_inflate.to(device)\n",
    "                s_emb = emb_inflate(s_emb)\n",
    "            \n",
    "                logit_inflate = nn.Sequential(\n",
    "                    nn.Linear(1536, num_classes),\n",
    "                    )\n",
    "                logit_inflate.to(device)\n",
    "                s_out = logit_inflate(s_emb)\n",
    "\n",
    "                \n",
    "                # val_critic_output = critic(student_output)\n",
    "                # class_predictions = torch.argmax(student_output, dim=1)\n",
    "                \n",
    "\n",
    "                # set up feature collection for teacher\n",
    "                t_FEATS = []\n",
    "                features = {}\n",
    "\n",
    "                # set a hook for penultimate layer feature embedding\n",
    "                teacher.avgpool.register_forward_hook(get_features('feats'))\n",
    "\n",
    "                # compute outputs\n",
    "                teacher_output = teacher(images)\n",
    "    \n",
    "                t_FEATS.append(features['feats'].cpu().numpy())\n",
    "                t_emb = np.concatenate(t_FEATS)\n",
    "                # reshape embedding features to flatten \n",
    "                t_emb = t_emb.reshape((curr_batch_size, t_emb.shape[1]))\n",
    "            \n",
    "                t_emb = torch.from_numpy(t_emb)    \n",
    "                t_emb = t_emb.to(device)\n",
    "                t_out = teacher.classifier(t_emb)\n",
    "\n",
    "                                \n",
    "                # Calculate and accumulate validation metrics\n",
    "                accuracy = (class_predictions == labels).float().mean().item()\n",
    "    \n",
    "                # Compute bias\n",
    "                num_batches += 1\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "                \n",
    "                # Calculate validation losses (similar to training losses)\n",
    "                batch_bias = np.mean(recall_diff[0])\n",
    "                mean_batch_bias = torch.tensor([batch_bias], device=device, dtype=torch.float32)\n",
    "                val_critic_loss = critic_loss_fn(val_critic_output, mean_batch_bias)\n",
    "\n",
    "                #cls loss\n",
    "                val_cls_loss = student_loss_fn(student_output, labels) * cls_loss_factor\n",
    "                # KD loss\n",
    "                val_div_loss = kd_loss(s_out = s_out, t_out = t_out) * min(1.0, epoch/warm_up)\n",
    "                # ND loss\n",
    "                val_norm_dir_loss = nd_loss(s_emb=s_emb, t_emb=t_emb, T_EMB=T_EMB, labels=labels)\n",
    "        \n",
    "                # val_combined_loss = (val_cls_loss + val_div_loss + val_norm_dir_loss) * max(1, lambda_factor * (abs(val_critic_output[0][0]) - epsilon + margin) + 1)\n",
    "                val_combined_loss = (val_cls_loss + val_div_loss + val_norm_dir_loss) * max(1, lambda_factor * (abs(val_critic_output[0][0]) - epsilon + margin) + 1) \n",
    "                    \n",
    "                epoch_val_accuracies.append(accuracy)\n",
    "                epoch_val_losses.append((val_combined_loss.item(), val_cls_loss.item(), val_critic_loss.item(), val_div_loss.item(), val_norm_dir_loss.item()))\n",
    "                \n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "    \n",
    "            val_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_non_zero_abs_values = np.abs(val_epoch_disparity[val_epoch_disparity != 0])\n",
    "    \n",
    "            # Store average training metrics for the epoch\n",
    "            val_accuracy = np.mean(epoch_val_accuracies)\n",
    "            val_disparity = np.mean(epoch_val_disparities)\n",
    "            val_mean_non_zero_abs_disparity = np.mean(val_non_zero_abs_values)\n",
    "            val_combined_loss = np.mean([x[0] for x in epoch_val_losses])\n",
    "            val_main_loss = np.mean([x[1] for x in epoch_val_losses])\n",
    "            val_critic_loss = np.mean([x[2] for x in epoch_val_losses])\n",
    "            val_kd_loss = np.mean([x[3] for x in epoch_val_losses])\n",
    "\n",
    "            val_accuracies.append(val_accuracy)\n",
    "            val_disparities.append(val_disparity)\n",
    "            val_mean_non_zero_abs_disparities.append(val_mean_non_zero_abs_disparity)\n",
    "            val_losses.append(val_combined_loss)\n",
    "            val_main_losses.append(val_main_loss)\n",
    "            val_critic_losses.append(val_critic_loss)\n",
    "            val_kd_losses.append(val_kd_loss)\n",
    "\n",
    "            critic_scheduler.step(val_critic_loss)\n",
    "            student_scheduler.step(val_main_loss)\n",
    "\n",
    "            # Check if current validation combined loss is lower than the best combined loss\n",
    "        if val_combined_loss < best_val_loss:\n",
    "            best_val_loss = val_combined_loss\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_mean_non_zero_abs_disparity = val_mean_non_zero_abs_disparity\n",
    "        \n",
    "            # Create a mapping of class recall disparities\n",
    "            class_recall_mapping = {class_name: val_epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "        \n",
    "            student_best_model_state = {\n",
    "                'epoch': epoch,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'critic_state_dict': critic.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'best_val_mean_abs_disparity': best_val_mean_non_zero_abs_disparity,\n",
    "                'class_recall_mapping': class_recall_mapping\n",
    "            }\n",
    "            save_path = os.path.join(lambda_dir, f'STUDENT_best_model_lambda_{lambda_factor}.pth')\n",
    "            torch.save(student_best_model_state, save_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"STUDENT - Lambda {lambda_factor} - Epoch {epoch + 1} Metrics:\")\n",
    "        print(\"-\"*50)\n",
    "        print(f\"TRAINING Accuracy: {train_accuracy:.6f}, VALIDATION Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"TRAINING Disparity: {train_mean_non_zero_abs_disparity:.6f}, VALIDATION Disparity: {val_mean_non_zero_abs_disparity:.4f}\")\n",
    "        print(f\"TRAINING Combined Loss: {train_combined_loss:.6f}, VALIDATION Combined Loss: {val_combined_loss:.4f}\")\n",
    "        print(\"-\"*50 + \"\\n\")\n",
    "        # Print disparities by class label\n",
    "        for class_label, recall_diff in class_recall_mapping.items():\n",
    "            print(f\"Class {class_label}: Val Disparity = {recall_diff}\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "      \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot Training and Validation Accuracy\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(train_accuracies, label='Training Accuracy')\n",
    "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "        plt.title('Student Training and Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training and Validation Disparity\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(train_mean_non_zero_abs_disparities, label='Training Mean Absolute Disparity')\n",
    "        plt.plot(val_mean_non_zero_abs_disparities, label='Validation Mean Absolute Disparity')\n",
    "        plt.title('Student Training and Validation Mean Absolute Disparity')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Absolute Disparity')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(train_losses, label='Training Combined Loss')\n",
    "        plt.plot(train_main_losses, label='Training Main Loss')\n",
    "        plt.plot(train_critic_losses, label='Training Critic Loss')\n",
    "        plt.plot(train_kd_losses, label='Training KD Loss')\n",
    "        plt.title('Student Training Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    \n",
    "        # Plot Validation Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(val_losses, label='Validation Combined Loss')\n",
    "        plt.plot(val_main_losses, label='Validation Main Loss')\n",
    "        plt.plot(val_critic_losses, label='Validation Critic Loss')\n",
    "        plt.plot(val_kd_losses, label='Validation KD Loss')\n",
    "        plt.title('Student Validation Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    best_epoch = student_best_model_state['epoch'] + 1 if student_best_model_state else epochs\n",
    "    print(f\"Finished Training STUDENT with lambda value of {lambda_factor}. Best epoch number: {best_epoch}\")\n",
    "\n",
    "    return student_best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6358c-aa9d-4987-9640-e4eaba63590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_LR(teacher = False, student = False):\n",
    "    if teacher:\n",
    "        # Load EfficientNet variant \n",
    "        model = models.efficientnet_b3(pretrained=True)\n",
    "    if student:\n",
    "        # Load EfficientNet variant \n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        \n",
    "    # Determine the number of output features from the feature extractor part of EfficientNet \n",
    "    num_ftrs = model.classifier[1].in_features\n",
    "    \n",
    "    # Modify the classifier layer of the EfficientNet model to match your number of classes\n",
    "    model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Redefine your main model optimizer if needed\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    \n",
    "    # Find best learning rate\n",
    "    optimal_learning_rate = best_LR_wider('efficientnet', model, trainloader, \n",
    "                                          criterion, optimizer, \n",
    "                                          scheduler, device, num_epochs=5, \n",
    "                                          lr_range=(1e-4, 1e-1), plot_loss=False)\n",
    "    \n",
    "    print(optimal_learning_rate)\n",
    "    return optimal_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03663353-2a12-482a-b399-5a379744db4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# teacher_learning_rate = find_optimal_LR(teacher = True)\n",
    "# student_learning_rate = find_optimal_LR(student = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69469e9d-e2f6-4ad7-882c-da526ce3676b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TEACHER\n",
    "# Create dict to store best model states\n",
    "teacher_model_states_best = {}\n",
    "\n",
    "# Loop through the lambda_factor_list\n",
    "for lambda_factor in teacher_lambda_factor_list:\n",
    "    # Load EfficientNet B3 model for Teacher\n",
    "    teacher = models.efficientnet_b3(pretrained=True)\n",
    "    \n",
    "    # Determine the number of output features from the feature extractor part of EfficientNet B3\n",
    "    num_ftrs = teacher.classifier[1].in_features\n",
    "    \n",
    "    # Modify the classifier layer of the EfficientNet model to match your number of classes\n",
    "    teacher.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Redefine your main model optimizer if needed\n",
    "    teacher_optimizer = optim.Adam(teacher.parameters(), lr=teacher_learning_rate)\n",
    "    teacher_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    best_model_state = train_teacher(teacher, teacher_optimizer, teacher_loss_fn,\n",
    "                                     teacher_patience, teacher_epochs, device, \n",
    "                                     base_save_dir=base_save_dir, teacher_name = teacher_name)\n",
    "    teacher_model_states_best[lambda_factor] = best_model_state\n",
    "\n",
    "# Save the collective best model states to a file\n",
    "teacher_collective_save_path = os.path.join(base_save_dir, 'teacher_model_states_best.pth')\n",
    "torch.save(teacher_model_states_best, teacher_collective_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce8bbe-1656-4ea3-b715-a24fb78835e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # STUDENT\n",
    "# Create dict to store best model states\n",
    "student_model_states_best = {}\n",
    "\n",
    "# Specify the lambda_factor for the teacher model to load\n",
    "lambda_factor = 0\n",
    "\n",
    "# Set extra parameters\n",
    "momentum = 0.9 # SGD momentum\n",
    "t=4.0 #temperature\n",
    "warm_up=20.0 #loss weight warm up epochs\n",
    "weight_decay = 5e-4 \n",
    "\n",
    "\n",
    "# Define the path to the saved model file for this lambda_factor\n",
    "lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lambda_factor}')\n",
    "teacher_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lambda_factor}.pth')\n",
    "\n",
    "# Initialize the EfficientNet model without pre-trained weights\n",
    "teacher = models.efficientnet_b3(pretrained=False)\n",
    "\n",
    "# Adjust the classifier layer to match your number of classes\n",
    "num_ftrs = teacher.classifier[1].in_features\n",
    "teacher.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Load the model state\n",
    "teacher_best_model_state = torch.load(teacher_path)\n",
    "teacher.load_state_dict(teacher_best_model_state['teacher_state_dict'])\n",
    "\n",
    "\n",
    "# Loop through the lambda_factor_list\n",
    "for lambda_factor in student_lambda_factor_list:\n",
    "    # Load EfficientNet B0 model for Student\n",
    "    student = models.efficientnet_b0(pretrained=True)\n",
    "    \n",
    "    # Determine the number of output features from the feature extractor part of EfficientNet B0\n",
    "    num_ftrs = student.classifier[1].in_features  # This is the correct number of input features for your adversarial classifier\n",
    "    \n",
    "    # Modify the classifier layer of the EfficientNet model to match your number of classes\n",
    "    student.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    # Extract the class embeddings from the teacher\n",
    "    for param in teacher.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    ## get teacher class mean embeddings    \n",
    "    with open(f\"./class_means/WIDER_embedding_fea/efficientnetb3_lmda_0.json\", 'r') as f:\n",
    "        T_EMB = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "    # Initialize the Critic model\n",
    "    critic = Critic(input_size=num_classes)\n",
    "    critic_optimizer = optim.Adam(critic.parameters(), lr=student_learning_rate, weight_decay=weight_decay)\n",
    "    critic_scheduler = lr_scheduler.ReduceLROnPlateau(critic_optimizer, mode='min', factor=0.2, patience=5, min_lr=0.0001)\n",
    "    critic_loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    student_optimizer = optim.Adam(student.parameters(), lr=student_learning_rate, weight_decay=weight_decay)\n",
    "    student_scheduler = lr_scheduler.ReduceLROnPlateau(student_optimizer, mode='min', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    student_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    student_best_model_state = train_student(student, teacher, student_optimizer, student_loss_fn, critic, \n",
    "                                             critic_optimizer, critic_loss_fn,\n",
    "                                             lambda_factor, momentum, t, warm_up, weight_decay, T_EMB, \n",
    "                                             num_classes, epsilon, margin, student_patience, student_epochs, \n",
    "                                             device, base_save_dir=base_save_dir, \n",
    "                                             student_scheduler=student_scheduler, critic_scheduler=critic_scheduler)\n",
    "    student_model_states_best[lambda_factor] = student_best_model_state\n",
    "\n",
    "# Save the collective best model states to a file\n",
    "student_collective_save_path = os.path.join(base_save_dir, 'student_model_states_best.pth')\n",
    "torch.save(student_model_states_best, student_collective_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d96960-7dec-414b-a22d-2044772c2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "collective_save_path = os.path.join(base_save_dir, 'student_model_states_best.pth')\n",
    "\n",
    "# Load the saved model states\n",
    "teacher_model_states_best = torch.load(collective_save_path)\n",
    "\n",
    "# Example: Accessing the best_val_accuracy for a specific lambda value\n",
    "teacher_lambda_value = [0,0.5,1,1.5,2,3,5,10,15,20,25,30,40,80,100,150]\n",
    "for lambda_value in teacher_lambda_value:\n",
    "    if lambda_value in teacher_model_states_best:\n",
    "        best_model_state = teacher_model_states_best[lambda_value]\n",
    "        best_val_accuracy = best_model_state['best_val_accuracy']\n",
    "        best_val_disparity = best_model_state['best_val_mean_abs_disparity']\n",
    "        print(f\"Best validation accuracy for lambda {lambda_value}: {best_val_accuracy}\")\n",
    "        print(f\"Best validation disparity for lambda {lambda_value}: {best_val_disparity}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"No model state found for lambda {lambda_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43191bf7-8b27-4aec-88cf-f2856db3851e",
   "metadata": {},
   "source": [
    "### PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1950eb4-50da-4693-a4e7-db39460a0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance_metrics(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_teacher_preds = []\n",
    "    all_student_preds = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "            \n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1).cpu().numpy()\n",
    "        student_preds = torch.argmax(student_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_teacher_preds.append(teacher_preds)\n",
    "        all_student_preds.append(student_preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_teacher_preds = np.concatenate(all_teacher_preds)\n",
    "    all_student_preds = np.concatenate(all_student_preds)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': (accuracy_score(all_labels, all_teacher_preds), accuracy_score(all_labels, all_student_preds)),\n",
    "        'precision': (precision_score(all_labels, all_teacher_preds, average='weighted', zero_division=0), precision_score(all_labels, all_student_preds, average='weighted', zero_division=0)),\n",
    "        'recall': (recall_score(all_labels, all_teacher_preds, average='weighted'), recall_score(all_labels, all_student_preds, average='weighted')),\n",
    "        'f1': (f1_score(all_labels, all_teacher_preds, average='weighted'), f1_score(all_labels, all_student_preds, average='weighted'))\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'all_labels': all_labels,\n",
    "        'all_teacher_preds': all_teacher_preds,\n",
    "        'all_student_preds': all_student_preds\n",
    "    }\n",
    "\n",
    "def compare_model_size(teacher, student):\n",
    "    teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "    student_params = sum(p.numel() for p in student.parameters())\n",
    "    return teacher_params, student_params\n",
    "\n",
    "def compare_inference_time(teacher, student, dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    data = next(dataiter)\n",
    "    inputs = data['img']\n",
    "    inputs = inputs.to(device)\n",
    "\n",
    "    teacher_time, student_time = 0, 0\n",
    "\n",
    "    if teacher is not None:\n",
    "        teacher = teacher.to(device)\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "        teacher_time = time.time() - start_time\n",
    "\n",
    "    if student is not None:\n",
    "        student = student.to(device)\n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            student_outputs = student(inputs)\n",
    "        student_time = time.time() - start_time\n",
    "    \n",
    "    return teacher_time, student_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b744a8-ec73-4758-9db3-280d0f02710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_results = {}\n",
    "\n",
    "# Loop through each lambda value\n",
    "for lmda_teacher in teacher_lambda_factor_list:\n",
    "    for lmda_student in student_lambda_factor_list:\n",
    "\n",
    "        # Define the path to the saved model file for this lambda_factor\n",
    "        lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lmda_teacher}')\n",
    "        teacher_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lmda_teacher}.pth')\n",
    "        \n",
    "        # Initialize the EfficientNet model without pre-trained weights\n",
    "        teacher_model = models.efficientnet_b3(pretrained=False)\n",
    "        \n",
    "        # Adjust the classifier layer to match the number of classes\n",
    "        num_ftrs = teacher_model.classifier[1].in_features\n",
    "        teacher_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        # Load the model state\n",
    "        teacher_best_model_state = torch.load(teacher_path)\n",
    "        teacher_model.load_state_dict(teacher_best_model_state['teacher_state_dict'])\n",
    "        teacher_model = teacher_model.to(device)\n",
    "        \n",
    "        # Define the path to the saved model file for this lambda_factor\n",
    "        lambda_dir = os.path.join(base_save_dir, f'STUDENT_lambda_{lmda_student}')\n",
    "        student_path = os.path.join(lambda_dir, f'STUDENT_best_model_lambda_{lmda_student}.pth')\n",
    "        \n",
    "        # Initialize the EfficientNet model without pre-trained weights\n",
    "        student_model = models.efficientnet_b0(pretrained=False)\n",
    "        \n",
    "        # Adjust the classifier layer to match the number of classes\n",
    "        num_ftrs = student_model.classifier[1].in_features\n",
    "        student_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        # Load the model state\n",
    "        student_best_model_state = torch.load(student_path)\n",
    "        student_model.load_state_dict(student_best_model_state['student_state_dict'])\n",
    "        student_model = student_model.to(device)\n",
    "        \n",
    "        # Compute performance metrics\n",
    "        performance_metrics = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "    \n",
    "        # Compute model sizes\n",
    "        teacher_params, student_params = compare_model_size(teacher_model, student_model)\n",
    "    \n",
    "        # Construct a unique key for the current combination of lambda values\n",
    "        lambda_key = (lmda_teacher, lmda_student)\n",
    "\n",
    "        # Update results for the current lambda value\n",
    "        if lambda_key in lambda_results:\n",
    "            lambda_results[lambda_key].update({\n",
    "                'performance_metrics': performance_metrics,\n",
    "                'teacher_params': teacher_params,\n",
    "                'student_params': student_params\n",
    "            })\n",
    "        else:\n",
    "            lambda_results[lambda_key] = {\n",
    "                'performance_metrics': performance_metrics,\n",
    "                'teacher_params': teacher_params,\n",
    "                'student_params': student_params\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c096a70-c15d-4931-8acf-4a6eeff9c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracies\n",
    "teacher_accuracies = []\n",
    "student_accuracies = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Access the performance metrics for each pair\n",
    "    teacher_accuracy = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['accuracy'][0]\n",
    "    student_accuracy = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['accuracy'][1]\n",
    "\n",
    "    # Append accuracies to the lists\n",
    "    teacher_accuracies.append((lmda_teacher, teacher_accuracy))\n",
    "    student_accuracies.append((lmda_student, student_accuracy))\n",
    "\n",
    "# To plot, you might need to separate the lambda values and accuracies\n",
    "teacher_lambdas, teacher_acc = zip(*teacher_accuracies)\n",
    "student_lambdas, student_acc = zip(*student_accuracies)\n",
    "\n",
    "# Print out metrics \n",
    "print(f'teacher: {100*teacher_acc[0]:9.2f}\\n - - student - - ')\n",
    "for index, lmbda in enumerate(student_lambdas):\n",
    "    print(f'lambda {lmbda}: {100*student_acc[index]:9.2f}')\n",
    "\n",
    "# Plotting only with markers and no lines\n",
    "plt.scatter(teacher_lambdas, teacher_acc, label='Teacher Accuracy', marker='o')\n",
    "plt.scatter(student_lambdas, student_acc, label='Student Accuracy', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd15e20-0e67-4a9b-b216-ae32f861f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store precisions\n",
    "teacher_precisions = []\n",
    "student_precisions = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the precision metrics for each pair\n",
    "        teacher_precision = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['precision'][0]\n",
    "        student_precision = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['precision'][1]\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append precisions to the lists along with lambda values\n",
    "    teacher_precisions.append((lmda_teacher, teacher_precision))\n",
    "    student_precisions.append((lmda_student, student_precision))\n",
    "\n",
    "# Extracting lambda values and precisions\n",
    "teacher_lambdas, teacher_prec = zip(*teacher_precisions)\n",
    "student_lambdas, student_prec = zip(*student_precisions)\n",
    "\n",
    "# Print out metrics \n",
    "print(f'teacher: {100*teacher_prec[0]:9.2f}\\n - - student - - ')\n",
    "for index, lmbda in enumerate(student_lambdas):\n",
    "    print(f'lambda {lmbda}: {100*student_prec[index]:9.2f}')\n",
    "\n",
    "# Creating a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(teacher_lambdas, teacher_prec, label='Teacher Precision', marker='o')\n",
    "plt.scatter(student_lambdas, student_prec, label='Student Precision', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13440e50-05ad-41c3-a77c-9abf38d4b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store recalls\n",
    "teacher_recalls = []\n",
    "student_recalls = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the recall metrics for each pair\n",
    "        teacher_recall = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['recall'][0]\n",
    "        student_recall = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['recall'][1]\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append recalls to the lists along with lambda values\n",
    "    teacher_recalls.append((lmda_teacher, teacher_recall))\n",
    "    student_recalls.append((lmda_student, student_recall))\n",
    "\n",
    "# Extracting lambda values and recalls\n",
    "teacher_lambdas, teacher_rec = zip(*teacher_recalls)\n",
    "student_lambdas, student_rec = zip(*student_recalls)\n",
    "\n",
    "# Print out metrics \n",
    "print(f'teacher: {100*teacher_rec[0]:9.2f}\\n - - student - - ')\n",
    "for index, lmbda in enumerate(student_lambdas):\n",
    "    print(f'lambda {lmbda}: {100*student_rec[index]:9.2f}')\n",
    "\n",
    "\n",
    "# Creating a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(teacher_lambdas, teacher_rec, label='Teacher Recall', marker='o')\n",
    "plt.scatter(student_lambdas, student_rec, label='Student Recall', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b152f1dc-8c4c-46c8-b5e0-c3910ebf02ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store F1 scores\n",
    "teacher_f1s = []\n",
    "student_f1s = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the F1 scores for each pair\n",
    "        teacher_f1 = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['f1'][0]\n",
    "        student_f1 = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['f1'][1]\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append F1 scores to the lists along with lambda values\n",
    "    teacher_f1s.append((lmda_teacher, teacher_f1))\n",
    "    student_f1s.append((lmda_student, student_f1))\n",
    "\n",
    "# Extracting lambda values and F1 scores\n",
    "teacher_lambdas, teacher_f1_scores = zip(*teacher_f1s)\n",
    "student_lambdas, student_f1_scores = zip(*student_f1s)\n",
    "\n",
    "# Print out metrics \n",
    "print(f'teacher: {100*teacher_f1_scores[0]:9.2f}\\n - - student - - ')\n",
    "for index, lmbda in enumerate(student_lambdas):\n",
    "    print(f'lambda {lmbda}: {100*student_f1_scores[index]:9.2f}')\n",
    "\n",
    "# Creating a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(teacher_lambdas, teacher_f1_scores, label='Teacher F1 Score', marker='o')\n",
    "plt.scatter(student_lambdas, student_f1_scores, label='Student F1 Score', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6663a3-dc75-4f11-8e9f-44a8af5bb462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store model sizes\n",
    "teacher_sizes = []\n",
    "student_sizes = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the model sizes for each pair\n",
    "        teacher_size = lambda_results[(lmda_teacher, lmda_student)]['teacher_params'] / 1e6  # Convert to millions\n",
    "        student_size = lambda_results[(lmda_teacher, lmda_student)]['student_params'] / 1e6\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append model sizes to the lists along with lambda values\n",
    "    teacher_sizes.append((lmda_teacher, teacher_size))\n",
    "    student_sizes.append((lmda_student, student_size))\n",
    "\n",
    "# Extracting lambda values and model sizes\n",
    "teacher_lambdas, teacher_model_sizes = zip(*teacher_sizes)\n",
    "student_lambdas, student_model_sizes = zip(*student_sizes)\n",
    "\n",
    "# Print out metrics \n",
    "print(f'teacher: {teacher_model_sizes[0]:9.2f}\\n - - student - - ')\n",
    "for index, lmbda in enumerate(student_lambdas):\n",
    "    print(f'lambda {lmbda}: {student_model_sizes[index]:9.2f}')\n",
    "\n",
    "# Creating a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(teacher_lambdas, teacher_model_sizes, label='Teacher Model Size', marker='o')\n",
    "plt.scatter(student_lambdas, student_model_sizes, label='Student Model Size', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Model Size (Millions of Parameters)')\n",
    "plt.title('Model Size Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f079468-fb5f-4ea9-8a58-2d3fd37db033",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Define the path to the saved model file for this lambda_factor\n",
    "        lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lmda_teacher}')\n",
    "        teacher_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lmda_teacher}.pth')\n",
    "        \n",
    "        # Initialize the EfficientNet model without pre-trained weights\n",
    "        teacher_model = models.efficientnet_b3(pretrained=False)\n",
    "        \n",
    "        # Adjust the classifier layer to match the number of classes\n",
    "        num_ftrs = teacher_model.classifier[1].in_features\n",
    "        teacher_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        # Load the model state\n",
    "        teacher_best_model_state = torch.load(teacher_path)\n",
    "        teacher_model.load_state_dict(teacher_best_model_state['teacher_state_dict'])\n",
    "        teacher_model = teacher_model.to(device)\n",
    "        \n",
    "        # Define the path to the saved model file for this lambda_factor\n",
    "        lambda_dir = os.path.join(base_save_dir, f'STUDENT_lambda_{lmda_student}')\n",
    "        student_path = os.path.join(lambda_dir, f'STUDENT_best_model_lambda_{lmda_student}.pth')\n",
    "        \n",
    "        # Initialize the EfficientNet model without pre-trained weights\n",
    "        student_model = models.efficientnet_b0(pretrained=False)\n",
    "        \n",
    "        # Adjust the classifier layer to match the number of classes\n",
    "        num_ftrs = student_model.classifier[1].in_features\n",
    "        student_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "        # Load the model state\n",
    "        student_best_model_state = torch.load(student_path)\n",
    "        student_model.load_state_dict(student_best_model_state['student_state_dict'])\n",
    "        student_model = student_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021c2eb-2ee4-4cb4-ac82-3635113354fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store inference times for each lambda value\n",
    "teacher_times = {}\n",
    "student_times = {}\n",
    "\n",
    "# Loop through each lambda value\n",
    "for lmda_teacher in teacher_lambda_factor_list:\n",
    "    # Define the path to the saved model file for this lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lmda_teacher}')\n",
    "    teacher_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lmda_teacher}.pth')\n",
    "    \n",
    "    # Initialize the EfficientNet model without pre-trained weights\n",
    "    teacher_model = models.efficientnet_b3(pretrained=False)\n",
    "    \n",
    "    # Adjust the classifier layer to match the number of classes\n",
    "    num_ftrs = teacher_model.classifier[1].in_features\n",
    "    teacher_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Load the model state\n",
    "    teacher_best_model_state = torch.load(teacher_path)\n",
    "    teacher_model.load_state_dict(teacher_best_model_state['teacher_state_dict'])\n",
    "    teacher_model = teacher_model.to(device)\n",
    "\n",
    "    teacher_time, _ = compare_inference_time(teacher_model, None, testloader)\n",
    "    teacher_times[lmda_teacher] = teacher_time  # Store the inference time for the teacher model\n",
    "\n",
    "for lmda_student in student_lambda_factor_list:\n",
    "    # Define the path to the saved model file for this lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'STUDENT_lambda_{lmda_student}')\n",
    "    student_path = os.path.join(lambda_dir, f'STUDENT_best_model_lambda_{lmda_student}.pth')\n",
    "    \n",
    "    # Initialize the EfficientNet model without pre-trained weights\n",
    "    student_model = models.efficientnet_b0(pretrained=False)\n",
    "    \n",
    "    # Adjust the classifier layer to match the number of classes\n",
    "    num_ftrs = student_model.classifier[1].in_features\n",
    "    student_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Load the model state\n",
    "    student_best_model_state = torch.load(student_path)\n",
    "    student_model.load_state_dict(student_best_model_state['student_state_dict'])\n",
    "    student_model = student_model.to(device)\n",
    "\n",
    "    _, student_time = compare_inference_time(None, student_model, testloader)\n",
    "    student_times[lmda_student] = student_time  # Store the inference time for the student model\n",
    "\n",
    "# Extracting lambda values and inference times\n",
    "teacher_lambdas, teacher_inference_times = zip(*teacher_times.items())\n",
    "student_lambdas, student_inference_times = zip(*student_times.items())\n",
    "\n",
    "# Print out metrics \n",
    "print(f'teacher: {100*teacher_inference_times[0]:9.2f}\\n - - student - - ')\n",
    "for index, lmbda in enumerate(student_lambdas):\n",
    "    print(f'lambda {lmbda}: {100*student_inference_times[index]:9.2f}')\n",
    "\n",
    "# Creating a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(teacher_lambdas, teacher_inference_times, label='Teacher Inference Time', marker='o')\n",
    "plt.scatter(student_lambdas, student_inference_times, label='Student Inference Time', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Inference Time (s)')\n",
    "plt.title('Inference Time Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99617c4-9bfc-4978-96b5-2af3113b0b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teacher_disparities = []\n",
    "student_disparities = []\n",
    "\n",
    "# Loop through each lambda_factor in the teacher_lambda_factor_list and extract the disparity values for the teacher\n",
    "for lambda_factor in teacher_lambda_factor_list:\n",
    "    # Load teacher model\n",
    "    teacher_path = os.path.join(base_save_dir, f'TEACHER_lambda_{lambda_factor}', f'TEACHER_best_model_lambda_{lambda_factor}.pth')\n",
    "    teacher_best_model_state = torch.load(teacher_path)\n",
    "    teacher_disparities.append((lambda_factor, teacher_best_model_state['best_val_mean_abs_disparity']))\n",
    "\n",
    "# Loop through each lambda_factor in the student_lambda_factor_list and extract the disparity values for the student\n",
    "for lambda_factor in student_lambda_factor_list:\n",
    "    # Load student model\n",
    "    student_path = os.path.join(base_save_dir, f'STUDENT_lambda_{lambda_factor}', f'STUDENT_best_model_lambda_{lambda_factor}.pth')\n",
    "    student_best_model_state = torch.load(student_path)\n",
    "    student_disparities.append((lambda_factor, student_best_model_state['best_val_mean_abs_disparity']))\n",
    "\n",
    "# Unpack the lambda factors and disparities for plotting\n",
    "teacher_lambdas, teacher_disp_values = zip(*teacher_disparities)\n",
    "student_lambdas, student_disp_values = zip(*student_disparities)\n",
    "\n",
    "# Print out metrics \n",
    "print(f'teacher: {100*teacher_disp_values[0]:9.2f}\\n - - student - - ')\n",
    "for index, lmbda in enumerate(student_lambdas):\n",
    "    print(f'lambda {lmbda}: {100*student_disp_values[index]:9.2f}')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(teacher_lambdas, teacher_disp_values, label='Teacher', color='blue')\n",
    "plt.scatter(student_lambdas, student_disp_values, label='Student', color='red')\n",
    "plt.xlabel('Lambda Factor')\n",
    "plt.ylabel('Best Val Mean Abs Disparity')\n",
    "plt.title('Best Validation Mean Absolute Disparity vs Lambda Factor')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1544cc96-9ec4-411e-8520-0bc614f7dfda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution(predictions, class_names, title):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=predictions)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(all_labels, predictions, class_names, title):\n",
    "    cm = confusion_matrix(all_labels, predictions)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(pd.DataFrame(cm, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to generate predictions and compute metrics\n",
    "def generate_predictions_and_metrics(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch['img'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            \n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Loop over each lambda value for the teacher model\n",
    "for lmda_teacher in teacher_lambda_factor_list:\n",
    "    # Define the path to the saved model file for this lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lmda_teacher}')\n",
    "    teacher_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lmda_teacher}.pth')\n",
    "    \n",
    "    # Initialize the EfficientNet model without pre-trained weights\n",
    "    teacher_model = models.efficientnet_b3(pretrained=False)\n",
    "    \n",
    "    # Adjust the classifier layer to match the number of classes\n",
    "    num_ftrs = teacher_model.classifier[1].in_features\n",
    "    teacher_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Load the model state\n",
    "    teacher_best_model_state = torch.load(teacher_path)\n",
    "    teacher_model.load_state_dict(teacher_best_model_state['teacher_state_dict'])\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    \n",
    "    # Generate predictions for the teacher model\n",
    "    all_labels, all_teacher_preds = generate_predictions_and_metrics(teacher_model, testloader)\n",
    "\n",
    "    # Plot distribution and confusion matrix for the teacher model\n",
    "    plot_distribution(all_teacher_preds, class_names_new, f'Teacher Model Predictions (Lambda={lmda_teacher})')\n",
    "    plot_confusion_matrix(all_labels, all_teacher_preds, class_names_new, f'Teacher Confusion Matrix (Lambda={lmda_teacher})')\n",
    "\n",
    "    # Print classification report for the teacher model\n",
    "    teacher_report = classification_report(all_labels, all_teacher_preds, target_names=class_names_new, zero_division=0)\n",
    "    print(f'Classification Report - Teacher Model (Lambda={lmda_teacher})')\n",
    "    print(teacher_report)\n",
    "\n",
    "# Loop over each lambda value for the student model\n",
    "for lmda_student in student_lambda_factor_list:\n",
    "    # Define the path to the saved model file for this lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'STUDENT_lambda_{lmda_student}')\n",
    "    student_path = os.path.join(lambda_dir, f'STUDENT_best_model_lambda_{lmda_student}.pth')\n",
    "    \n",
    "    # Initialize the EfficientNet model without pre-trained weights\n",
    "    student_model = models.efficientnet_b0(pretrained=False)\n",
    "    \n",
    "    # Adjust the classifier layer to match the number of classes\n",
    "    num_ftrs = student_model.classifier[1].in_features\n",
    "    student_model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Load the model state\n",
    "    student_best_model_state = torch.load(student_path)\n",
    "    student_model.load_state_dict(student_best_model_state['student_state_dict'])\n",
    "    student_model = student_model.to(device)\n",
    "\n",
    "    # Generate predictions for the student model\n",
    "    all_labels, all_student_preds = generate_predictions_and_metrics(student_model, testloader)\n",
    "\n",
    "    # Plot distribution and confusion matrix for the student model\n",
    "    plot_distribution(all_student_preds, class_names_new, f'Student Model Predictions (Lambda={lmda_student})')\n",
    "    plot_confusion_matrix(all_labels, all_student_preds, class_names_new, f'Student Confusion Matrix (Lambda={lmda_student})')\n",
    "\n",
    "    # Print classification report for the student model\n",
    "    student_report = classification_report(all_labels, all_student_preds, target_names=class_names_new, zero_division=0)\n",
    "    print(f'Classification Report - Student Model (Lambda={lmda_student})')\n",
    "    print(student_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f315002-1f2b-44ba-9fb0-e5e97f085686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_bias_variance_tradeoff(base_save_dir, model_type, lambda_list):\n",
    "    bias_values = []\n",
    "    accuracy_values = []\n",
    "\n",
    "    for lambda_factor in lambda_list:\n",
    "        model_path = os.path.join(base_save_dir, f'{model_type.upper()}_lambda_{lambda_factor}', f'{model_type.upper()}_best_model_lambda_{lambda_factor}.pth')\n",
    "        if os.path.exists(model_path):\n",
    "            model_state = torch.load(model_path)\n",
    "\n",
    "            disparity = model_state['best_val_mean_abs_disparity']\n",
    "            accuracy = model_state['best_val_accuracy']\n",
    "            bias_values.append(disparity)\n",
    "            accuracy_values.append(accuracy)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(bias_values, accuracy_values, label=f'{model_type.title()} Model')\n",
    "    plt.xlabel('Mean Absolute Disparity')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title(f'{model_type.title()} Model Accuracy vs Disparity')\n",
    "    for i, lambda_factor in enumerate(lambda_list):\n",
    "        plt.annotate(f'={lambda_factor}', (bias_values[i], accuracy_values[i]), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plot for Teacher\n",
    "plot_bias_variance_tradeoff(base_save_dir, 'teacher', teacher_lambda_factor_list)\n",
    "\n",
    "# Plot for Student\n",
    "plot_bias_variance_tradeoff(base_save_dir, 'student', student_lambda_factor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdd0df1-76fb-4b09-8c0d-7e47353b9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance_metrics_for_demo(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "\n",
    "    detailed_info = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        # Assuming gender or other attributes are part of 'target'\n",
    "        attributes = batch['target'].to(device)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "\n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1)\n",
    "        student_preds = torch.argmax(student_outputs, dim=1)\n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            if teacher_preds[i] != labels[i] and student_preds[i] == labels[i]:\n",
    "                info = {\n",
    "                    'image': inputs[i],\n",
    "                    'actual_class': labels[i].item(),\n",
    "                    'teacher_pred_class': teacher_preds[i].item(),\n",
    "                    'student_pred_class': student_preds[i].item(),\n",
    "                    'actual_attribute': attributes[i].item()\n",
    "                }\n",
    "                detailed_info.append(info)\n",
    "\n",
    "    return detailed_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443cb3fc-8301-4ae9-b3d3-8aac0922459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_class_filter(info_list, display_class, new_label_mapping, rows=10, cols=5):\n",
    "    # Filter the info list based on the specified class, student correct and teacher incorrect predictions\n",
    "    filtered_info = [info for info in info_list if info['actual_class'] == display_class and \n",
    "                     info['student_pred_class'] == display_class and \n",
    "                     info['teacher_pred_class'] != display_class]\n",
    "\n",
    "    # Calculate the number of images to display based on the length of the filtered list\n",
    "    num_images = len(filtered_info)\n",
    "    if num_images == 0:\n",
    "        print(f\"No images to display for class {display_class}.\")\n",
    "        return  # Skip this class as there are no images to display\n",
    "\n",
    "    total_plots = min(rows * cols, num_images)  # Ensure we don't exceed the number of filtered images\n",
    "\n",
    "    # Determine the number of rows needed based on the number of images\n",
    "    rows = (total_plots + cols - 1) // cols\n",
    "\n",
    "    # Create a figure with the adjusted number of rows and columns\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 3 * rows))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(total_plots):\n",
    "        data = filtered_info[i]\n",
    "        image = data['image']\n",
    "        actual_class = new_label_mapping[data['actual_class']]  # Get class name from the mapping\n",
    "        teacher_pred_class = new_label_mapping[data['teacher_pred_class']]  # Get class name from the mapping\n",
    "        student_pred_class = new_label_mapping[data['student_pred_class']]  # Get class name from the mapping\n",
    "        actual_attribute = round(data['actual_attribute'], 3)\n",
    "    \n",
    "        # Normalize the image for display\n",
    "        image_display = image.cpu().numpy().transpose(1, 2, 0)\n",
    "        image_display = (image_display - image_display.min()) / (image_display.max() - image_display.min())\n",
    "    \n",
    "        # Set the title with the class and attribute information\n",
    "        title = f'Attr: {actual_attribute}\\nTrue: {actual_class}\\nTeacher: {teacher_pred_class}\\nStudent: {student_pred_class}'\n",
    "    \n",
    "        axes[i].imshow(image_display)\n",
    "        axes[i].set_title(title, fontsize=12, pad=4)\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Turn off any unused axes\n",
    "    for i in range(total_plots, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Adjust layout for clarity\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.5, hspace=0.6)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e779e9-3486-4ce4-8ac8-d2f097938583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the Teacher Model for a specific lambda value\n",
    "def load_teacher_model(lambda_factor):\n",
    "    lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lambda_factor}')\n",
    "    teacher_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lambda_factor}.pth')\n",
    "\n",
    "    teacher_model = models.efficientnet_b3(pretrained=False)\n",
    "    num_ftrs = teacher_model.classifier[1].in_features\n",
    "    teacher_model.classifier[1] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    teacher_best_model_state = torch.load(teacher_path)\n",
    "    teacher_model.load_state_dict(teacher_best_model_state['teacher_state_dict'])\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    return teacher_model\n",
    "\n",
    "# Load the Student Model for a specific lambda value\n",
    "def load_student_model(lambda_factor):\n",
    "    lambda_dir = os.path.join(base_save_dir, f'STUDENT_lambda_{lambda_factor}')\n",
    "    student_path = os.path.join(lambda_dir, f'STUDENT_best_model_lambda_{lambda_factor}.pth')\n",
    "\n",
    "    student_model = models.efficientnet_b0(pretrained=False)\n",
    "    num_ftrs = student_model.classifier[1].in_features\n",
    "    student_model.classifier[1] = torch.nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    student_best_model_state = torch.load(student_path)\n",
    "    student_model.load_state_dict(student_best_model_state['student_state_dict'])\n",
    "    student_model = student_model.to(device)\n",
    "    return student_model\n",
    "\n",
    "# Load models for a specific lambda value\n",
    "teacher_lambda_factor = 0 \n",
    "student_lambda_factor = 50\n",
    "\n",
    "teacher_model = load_teacher_model(teacher_lambda_factor)\n",
    "student_model = load_student_model(student_lambda_factor)\n",
    "\n",
    "# Assuming 'testloader', 'new_label_mapping', and 'num_classes' are defined\n",
    "# Get detailed info where student is correct and teacher is wrong\n",
    "detailed_info = compare_performance_metrics_for_demo(teacher_model, student_model, testloader)\n",
    "\n",
    "# Plot images\n",
    "for i in range(num_classes):\n",
    "    print('='*60)\n",
    "    print(f'CLASS {i}: {new_label_mapping[i]}')\n",
    "    print('='*60)\n",
    "    plot_images_with_class_filter(detailed_info, display_class=i, new_label_mapping=new_label_mapping, rows=100, cols=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0350e0b-5239-4d45-a4fb-745c23926ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdf270-2dd5-41d2-99a4-227d52d48ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
