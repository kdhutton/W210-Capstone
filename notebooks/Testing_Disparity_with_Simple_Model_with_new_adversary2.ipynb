{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed182ac-bc78-4d44-b703-561a052cfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision.models import EfficientNet\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7437867-ecd5-4643-9fb8-a2fc1d1f15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.0005 # 0.096779\n",
    "epochs = 100 #3\n",
    "epochs_pretrain = 3\n",
    "epochs_optimal_lr = 3\n",
    "patience = 6\n",
    "momentum = 0.9\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "# list of lambda values to loop through for grid search\n",
    "lmda_list = [5,0]\n",
    "\n",
    "# labels used including for plotting\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "num_classes = 16\n",
    "class_names_new = [f\"Class {label}\" for label in range(num_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a11b671f-0b71-438a-bf75-7ceb293b72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# Count the number of GPUs available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\"CUDA Available:\", cuda_available)\n",
    "print(\"Number of GPUs:\", num_gpus)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eabaae7-724f-4ee9-9df8-9463d205b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your JSON file is named 'your_file.json'\n",
    "file_path = './WIDER/Annotations/wider_attribute_trainval.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    data = json.load(file)\n",
    "\n",
    "class_idx = data['scene_id_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c142a7d7-9627-48b6-a5aa-86527150ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_mapping = {\n",
    "    0: \"Team_Sports\",\n",
    "    1: \"Celebration\",\n",
    "    2: \"Parade\",\n",
    "    3: \"Waiter_Or_Waitress\",\n",
    "    4: \"Individual_Sports\",\n",
    "    5: \"Surgeons\",\n",
    "    6: \"Spa\",\n",
    "    7: \"Law_Enforcement\",\n",
    "    8: \"Business\",\n",
    "    9: \"Dresses\",\n",
    "    10: \"Water_Activities\",\n",
    "    11: \"Picnic\",\n",
    "    12: \"Rescue\",\n",
    "    13: \"Cheering\",\n",
    "    14: \"Performance_And_Entertainment\",\n",
    "    15: \"Family\"\n",
    "}\n",
    "\n",
    "# Ensure that all 16 new classes are covered\n",
    "# If some classes are not explicitly mentioned in new_label_mapping, add them\n",
    "for i in range(num_classes):\n",
    "    if i not in new_label_mapping:\n",
    "        new_label_mapping[i] = \"Additional Category {}\".format(i)\n",
    "\n",
    "class_idx = new_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab11dc9-d6c6-4c45-8452-cff149af8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "\n",
    "        # Create a mapping from old labels to new labels\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "\n",
    "        self.new_label_mapping = {\n",
    "            0: 2,  # Parade\n",
    "            1: 8,  # Business\n",
    "            2: 7,  # Law Enforcement\n",
    "            3: 14,  # Performance and Entertainment\n",
    "            4: 1,  # Celebration\n",
    "            5: 13,  # Cheering\n",
    "            6: 8,  # Business\n",
    "            7: 8,  # Business\n",
    "            8: 1,  # Celebration\n",
    "            9: 14,  # Performance and Entertainment\n",
    "            10: 15, # Family\n",
    "            11: 15, # Family\n",
    "            12: 11, # Picnic\n",
    "            13: 7, # Law Enforcement\n",
    "            14: 6, # Spa\n",
    "            15: 13, # Cheering\n",
    "            16: 5, # Surgeons\n",
    "            17: 3, # Waiter or Waitress\n",
    "            18: 4, # Individual Sports\n",
    "            19: 0, # Team Sports\n",
    "            20: 0, # Team Sports\n",
    "            21: 0, # Team Sports\n",
    "            22: 4, # Individual Sports\n",
    "            23: 10, # Water Activities\n",
    "            24: 4, # Individual Sports\n",
    "            25: 1, # Celebration\n",
    "            26: 9, # Dresses\n",
    "            27: 12, # Rescue\n",
    "            28: 10,# Water Activities\n",
    "            29: 0  # Team Sports\n",
    "        }\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        # Initialize transformations directly\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ] \n",
    "        )\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                ] \n",
    "            )        \n",
    "\n",
    "        self.anns = []\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs:\n",
    "            t.append(transforms.RandAugment())\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "\n",
    "        return transforms.Compose(t)\n",
    "    \n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            json_data = json.load(open(ann_file, \"r\"))\n",
    "            self.anns += json_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure the index is within bounds\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            img = Image.open(f'WIDER/Image/{ann[\"file_name\"]}').convert(\"RGB\")\n",
    "\n",
    "            # If this is the wider dataset, proceed with specific processing\n",
    "            # x, y, w, h = ann['bbox']\n",
    "            # img_area = img.crop([x, y, x+w, y+h])\n",
    "            img_area = self.augment(img)\n",
    "            img_area = self.transform(img_area)\n",
    "            attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "            num_people = len(attributes_list)\n",
    "            attributes_distribution = [max(sum(attribute), 0)/num_people for attribute in zip(*attributes_list)]\n",
    "            # Extract label from image path\n",
    "            img_path = f'WIDER/Image/{ann[\"file_name\"]}'\n",
    "            label = self.extract_label(img_path)  # You might need to implement this method\n",
    "            \n",
    "            return {\n",
    "                \"label\": label,\n",
    "                \"target\": torch.tensor([attributes_distribution[0]], dtype=torch.float32),\n",
    "                \"img\": img_area\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during the processing of an image, log the error and the index\n",
    "            print(f\"Error processing image at index {idx}: {e}\")\n",
    "            # Instead of returning None, raise the exception\n",
    "            raise\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            new_label_mapping = self.new_label_mapping[remapped_label]\n",
    "            return new_label_mapping\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "742c75bb-56ba-497e-8160-745d070907fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21c07e8c-9d6a-4f00-9b72-dbb9f35f6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e188300a-7896-4ed7-ba20-549a3057fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = DataSet(train_file, augs = ['RandAugment'], img_size = 226, dataset = 'wider')\n",
    "train_dataset = DataSet(train_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "test_dataset = DataSet(test_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                         num_workers=num_workers, collate_fn=custom_collate)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c464baa9-1e78-4409-8133-cbbc815ace9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def calculate_recall_multiclass(conf_matrix):\n",
    "    if conf_matrix.size == 0:\n",
    "        return np.array([0])  # Return an array with a single zero if the confusion matrix is empty\n",
    "\n",
    "    recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    recalls[np.isnan(recalls)] = 0  # Replace NaN with 0\n",
    "    return recalls  # This will always be an array\n",
    "\n",
    "def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes):\n",
    "    predictions = pred.cpu().numpy()\n",
    "    true_labels = label.cpu().numpy()\n",
    "    gender = gender.cpu().numpy()\n",
    "\n",
    "    class_disparities = []  # This is the correct variable name\n",
    "    batch_biases = []  # Store batch biases\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        male_indices = np.where((gender >= 0.5) & (true_labels == cls))[0]\n",
    "        female_indices = np.where((gender < 0.5) & (true_labels == cls))[0]\n",
    "\n",
    "        if len(male_indices) > 0 and len(female_indices) > 0:\n",
    "            male_pred_cls = predictions[male_indices]\n",
    "            female_pred_cls = predictions[female_indices]\n",
    "            male_true_cls = true_labels[male_indices]\n",
    "            female_true_cls = true_labels[female_indices]\n",
    "\n",
    "            # Ensure that both male and female true labels contain the class 'cls'\n",
    "            if cls in male_true_cls and cls in female_true_cls:\n",
    "                male_conf_matrix = confusion_matrix(male_true_cls, male_pred_cls, labels=[cls])\n",
    "                female_conf_matrix = confusion_matrix(female_true_cls, female_pred_cls, labels=[cls])\n",
    "\n",
    "                if male_conf_matrix.size > 0 and female_conf_matrix.size > 0:\n",
    "                    male_recall_cls = calculate_recall_multiclass(male_conf_matrix)[0]  # Take first element\n",
    "                    female_recall_cls = calculate_recall_multiclass(female_conf_matrix)[0]  # Take first element\n",
    "\n",
    "                    disparity = male_recall_cls - female_recall_cls\n",
    "                    class_disparities.append(disparity)\n",
    "                    batch_biases.append(disparity)\n",
    "\n",
    "    return np.mean(batch_biases) if batch_biases else 0, class_disparities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b6bb60-dc13-4d86-b5a9-f84b376823dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot_encode(labels, num_classes):\n",
    "#     return np.eye(num_classes)[labels]\n",
    "\n",
    "# def calculate_recall_multiclass(conf_matrix):\n",
    "#     recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "#     recalls[np.isnan(recalls)] = 0  # Replace NaN with 0\n",
    "#     return recalls\n",
    "\n",
    "# def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes):\n",
    "#     predictions = pred.cpu()\n",
    "#     true_labels = label.cpu()\n",
    "#     gender = gender.cpu()\n",
    "\n",
    "#     # Identify male and female indices based on the gender threshold\n",
    "#     male_indices = np.where(gender >= 0.5)[0]\n",
    "#     female_indices = np.where(gender < 0.5)[0]\n",
    "\n",
    "#     # Convert labels to one-hot encoding\n",
    "#     one_hot_labels = one_hot_encode(true_labels, num_classes=num_classes)\n",
    "#     one_hot_preds = one_hot_encode(predictions, num_classes=num_classes)\n",
    "\n",
    "#     # Initialize recall arrays\n",
    "#     male_recall = np.zeros(num_classes)\n",
    "#     female_recall = np.zeros(num_classes)\n",
    "\n",
    "#     # Extract predictions and labels for male and female indices\n",
    "#     male_predictions = np.argmax(one_hot_preds[male_indices], axis=1)\n",
    "#     female_predictions = np.argmax(one_hot_preds[female_indices], axis=1)\n",
    "#     male_labels = np.argmax(one_hot_labels[male_indices], axis=1)\n",
    "#     female_labels = np.argmax(one_hot_labels[female_indices], axis=1)\n",
    "\n",
    "#     # Check if the class labels are within the expected range\n",
    "#     assert (0 <= male_predictions.min() < num_classes) and (0 <= male_predictions.max() < num_classes), \"Invalid class indices in male predictions\"\n",
    "#     assert (0 <= female_predictions.min() < num_classes) and (0 <= female_predictions.max() < num_classes), \"Invalid class indices in female predictions\"\n",
    "#     assert (0 <= male_labels.min() < num_classes) and (0 <= male_labels.max() < num_classes), \"Invalid class indices in male labels\"\n",
    "#     assert (0 <= female_labels.min() < num_classes) and (0 <= female_labels.max() < num_classes), \"Invalid class indices in female labels\"\n",
    "\n",
    "#     # Calculate confusion matrices for each gender\n",
    "#     male_conf_matrix = confusion_matrix(male_labels, male_predictions, labels=np.arange(num_classes))\n",
    "#     female_conf_matrix = confusion_matrix(female_labels, female_predictions, labels=np.arange(num_classes))\n",
    "\n",
    "#     # Calculate recall for each class and gender\n",
    "#     male_recall[:len(male_conf_matrix)] = calculate_recall_multiclass(male_conf_matrix)\n",
    "#     female_recall[:len(female_conf_matrix)] = calculate_recall_multiclass(female_conf_matrix)\n",
    "\n",
    "#     # return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n",
    "#     return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df5bc74-4a24-42a0-9ca4-a4e04861d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EfficientNet B0 model\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "# Determine the number of output features from the feature extractor part of EfficientNet B0\n",
    "num_ftrs = model.classifier[1].in_features  # This is the correct number of input features for your adversarial classifier\n",
    "\n",
    "# Modify the classifier layer of the EfficientNet model to match your number of classes\n",
    "model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "# Move the EfficientNet model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=256):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  # Outputting a single value for bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))  # Assuming bias is a probability-like value\n",
    "        return x\n",
    "\n",
    "# Initialize the Critic model\n",
    "critic = Critic(input_size=16).to(device)  # Adjust the input size based on your model's output\n",
    "critic_optimizer = optim.Adam(critic.parameters(), lr=learning_rate)\n",
    "critic_loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# Redefine your main model optimizer if needed\n",
    "actor_optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "actor_loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfd36bf-6777-440c-bc9e-9af81eb18a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_factor = 3\n",
    "epsilon = 0.1\n",
    "margin = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2777235b-0ae2-47e8-a1a8-562402565000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Training:   0%|                                                                                                   | 0/162 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     34\u001b[0m class_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(actor_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Compute bias\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# bias, class_disparities = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# bias_mean = torch.tensor([bias], device=device, dtype=torch.float32)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m recall_diff \u001b[38;5;241m=\u001b[39m evaluate_model_with_gender_multiclass(\u001b[43mpredicted\u001b[49m, val_labels, val_targets, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\n\u001b[1;32m     40\u001b[0m confusion_male \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m recall_diff[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     41\u001b[0m confusion_female \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m recall_diff[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted' is not defined"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "train_disparities = []\n",
    "val_accuracies = []\n",
    "val_disparities = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_main_losses = []\n",
    "val_main_losses = []\n",
    "train_bias_losses = []\n",
    "val_bias_losses = []\n",
    "\n",
    "# Training and Validation Loop\n",
    "for epoch in range(epochs):\n",
    "    # Initialize metrics for each epoch\n",
    "    epoch_train_accuracies = []\n",
    "    epoch_train_disparities = []\n",
    "    epoch_val_accuracies = []\n",
    "    epoch_val_disparities = []\n",
    "    epoch_class_disparities = []\n",
    "    epoch_train_losses = []\n",
    "    epoch_train_accuracies = []\n",
    "    epoch_train_disparities = []\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch_data in tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs}, Training'):\n",
    "        # Load data to device\n",
    "        images = batch_data[\"img\"].to(device)\n",
    "        labels = batch_data[\"label\"].to(device)\n",
    "        gender_scores = batch_data[\"target\"].to(device)\n",
    "\n",
    "        # Forward pass through actor\n",
    "        actor_output = model(images)\n",
    "        class_predictions = torch.argmax(actor_output, dim=1)\n",
    "\n",
    "        # Compute bias\n",
    "        bias, class_disparities = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes)\n",
    "        bias_mean = torch.tensor([bias], device=device, dtype=torch.float32)\n",
    "\n",
    "        # Actor update\n",
    "        actor_optimizer.zero_grad()\n",
    "        main_loss = actor_loss_fn(actor_output, labels)\n",
    "        combined_loss = main_loss + lambda_factor * bias_mean\n",
    "        combined_loss.backward()\n",
    "        actor_optimizer.step()\n",
    "    \n",
    "        # Critic update\n",
    "        critic_optimizer.zero_grad()\n",
    "        critic_output = critic(actor_output.detach())\n",
    "        critic_loss = critic_loss_fn(critic_output, bias_mean)\n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "    \n",
    "        # Calculate and accumulate metrics\n",
    "        accuracy = (class_predictions == labels).float().mean().item()\n",
    "        epoch_train_accuracies.append(accuracy)\n",
    "        epoch_train_disparities.append(bias)\n",
    "    \n",
    "        # Record the losses (the correction is here)\n",
    "        combined_loss_value = combined_loss.item()\n",
    "        main_loss_value = main_loss.item()\n",
    "        bias_loss_value = (lambda_factor * bias_mean).item()\n",
    "    \n",
    "        epoch_train_losses.append((combined_loss_value, main_loss_value, bias_loss_value))\n",
    "\n",
    "    # Store average training metrics for the epoch\n",
    "    train_accuracy = np.mean(epoch_train_accuracies)\n",
    "    train_disparity = np.mean(epoch_train_disparities)\n",
    "    avg_combined_loss = np.mean([x[0] for x in epoch_train_losses])\n",
    "    avg_main_loss = np.mean([x[1] for x in epoch_train_losses])\n",
    "    avg_bias_loss = np.mean([x[2] for x in epoch_train_losses])\n",
    "    \n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_disparities.append(train_disparity)\n",
    "    train_losses.append(avg_combined_loss)  # Corrected line\n",
    "    train_main_losses.append(avg_main_loss)\n",
    "    train_bias_losses.append(avg_bias_loss)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    epoch_val_accuracies = []\n",
    "    epoch_val_disparities = [] \n",
    "    epoch_val_losses = []\n",
    "    sum_val_class_disparities = np.full((num_classes,), 0.0)  # Initialize sum array for class disparities\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_data in testloader:\n",
    "            # Load data to device\n",
    "            images = batch_data[\"img\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "            gender_scores = batch_data[\"target\"].to(device)\n",
    "    \n",
    "            # Forward pass\n",
    "            actor_output = model(images)\n",
    "            class_predictions = torch.argmax(actor_output, dim=1)\n",
    "    \n",
    "            # Calculate and accumulate validation metrics\n",
    "            accuracy = (class_predictions == labels).float().mean().item()\n",
    "            mean_batch_bias, class_disparity = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes)\n",
    "            \n",
    "            # Calculate validation losses (similar to training losses)\n",
    "            val_main_loss = actor_loss_fn(actor_output, labels)\n",
    "            val_bias_loss = (lambda_factor * torch.tensor([mean_batch_bias], device=device, dtype=torch.float32)).item()\n",
    "            val_combined_loss = val_main_loss + val_bias_loss\n",
    "    \n",
    "            epoch_val_accuracies.append(accuracy)\n",
    "            epoch_val_disparities.append(mean_batch_bias) \n",
    "            epoch_val_losses.append((val_combined_loss.item(), val_main_loss.item(), val_bias_loss))\n",
    "    \n",
    "            # Update sum of class disparities\n",
    "            for cls, disparity in enumerate(class_disparity):\n",
    "                sum_val_class_disparities[cls] += disparity\n",
    "    \n",
    "        # Calculate average validation metrics for the epoch\n",
    "        val_accuracy = np.mean(epoch_val_accuracies)\n",
    "        val_disparity = np.mean(epoch_val_disparities)\n",
    "        avg_val_combined_loss = np.mean([x[0] for x in epoch_val_losses])\n",
    "        avg_val_main_loss = np.mean([x[1] for x in epoch_val_losses])\n",
    "        avg_val_bias_loss = np.mean([x[2] for x in epoch_val_losses])\n",
    "        epoch_average_class_disparities = sum_val_class_disparities / len(testloader)\n",
    "    \n",
    "        # Append these averages to their respective lists for tracking across epochs\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_disparities.append(val_disparity)\n",
    "        val_losses.append(avg_val_combined_loss)\n",
    "        val_main_losses.append(avg_val_main_loss)\n",
    "        val_bias_losses.append(avg_val_bias_loss)\n",
    "    \n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot Training and Validation Accuracy\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(train_accuracies, label='Training Accuracy')\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Training and Validation Disparity\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(train_disparities, label='Training Disparity')\n",
    "    plt.plot(val_disparities, label='Validation Disparity')\n",
    "    plt.title('Training and Validation Disparity')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Disparity')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot Training Loss Components, Including Combined Loss\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(train_losses, label='Training Combined Loss')\n",
    "    plt.plot(train_main_losses, label='Training Main Loss')\n",
    "    plt.plot(train_bias_losses, label='Training Bias Loss')\n",
    "    plt.title('Training Loss Components')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Validation Loss Components, Including Combined Loss\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(val_losses, label='Validation Combined Loss')\n",
    "    plt.plot(val_main_losses, label='Validation Main Loss')\n",
    "    plt.plot(val_bias_losses, label='Validation Bias Loss')\n",
    "    plt.title('Validation Loss Components')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Logging epoch metrics\n",
    "    print(f\"Epoch {epoch + 1}: Training Accuracy = {train_accuracy}, Validation Accuracy = {val_accuracy}\")\n",
    "    print(f\"Epoch {epoch + 1}: Training Disparity = {train_disparity}, Validation Disparity = {val_disparity}\")\n",
    "\n",
    "    # Print class-level disparities for the epoch\n",
    "    print(f\"Epoch {epoch + 1}: Validation Class Disparities:\")\n",
    "    for cls, disparity in enumerate(epoch_average_class_disparities):\n",
    "        print(f\"  Class {cls}: Disparity = {disparity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8d2be-db17-4f32-ac35-594f77f550ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# Adversarial Intraprocessing Algorithm.\n",
    "# \"\"\"\n",
    "# import logging\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "\n",
    "# from models import load_model, Critic\n",
    "# from utils import get_best_thresh, get_test_objective, get_valid_objective, compute_bias\n",
    "\n",
    "# logger = logging.getLogger(\"Debiasing\")\n",
    "\n",
    "\n",
    "# def adversarial_debiasing(model_state_dict, data, config, device):\n",
    "#     logger.info('Training Adversarial model.')\n",
    "#     actor = load_model(data.num_features, config.get('hyperparameters', {}))\n",
    "#     actor.load_state_dict(model_state_dict)\n",
    "#     actor.to(device)\n",
    "#     hid = config['hyperparameters']['hid'] if 'hyperparameters' in config else 32\n",
    "#     critic = Critic(hid * config['adversarial']['batch_size'], num_deep=config['adversarial']['num_deep'], hid=hid)\n",
    "#     critic.to(device)\n",
    "#     critic_optimizer = optim.Adam(critic.parameters())\n",
    "#     critic_loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#     actor_optimizer = optim.Adam(actor.parameters(), lr=config['adversarial']['lr'])\n",
    "#     actor_loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "#     for epoch in range(config['adversarial']['epochs']):\n",
    "#         for param in critic.parameters():\n",
    "#             param.requires_grad = True\n",
    "#         for param in actor.parameters():\n",
    "#             param.requires_grad = False\n",
    "#         actor.eval()\n",
    "#         critic.train()\n",
    "#         for step in range(config['adversarial']['critic_steps']):\n",
    "#             critic_optimizer.zero_grad()\n",
    "#             indices = torch.randint(0, data.X_valid.size(0), (config['adversarial']['batch_size'],))\n",
    "#             cX_valid = data.X_valid_gpu[indices]\n",
    "#             cy_valid = data.y_valid[indices]\n",
    "#             cp_valid = data.p_valid[indices]\n",
    "#             with torch.no_grad():\n",
    "#                 scores = actor(cX_valid)[:, 0].reshape(-1).cpu().numpy()\n",
    "\n",
    "#             bias = compute_bias(scores, cy_valid.numpy(), cp_valid, config['metric'])\n",
    "\n",
    "#             res = critic(actor.trunc_forward(cX_valid))\n",
    "#             loss = critic_loss_fn(torch.tensor([bias], device=device), res[0])\n",
    "#             loss.backward()\n",
    "#             train_loss = loss.item()\n",
    "#             critic_optimizer.step()\n",
    "#             if (epoch % 10 == 0) and (step % 100 == 0):\n",
    "#                 logger.info(f'=======> Critic Epoch: {(epoch, step)} loss: {train_loss}')\n",
    "\n",
    "#         for param in critic.parameters():\n",
    "#             param.requires_grad = False\n",
    "#         for param in actor.parameters():\n",
    "#             param.requires_grad = True\n",
    "#         actor.train()\n",
    "#         critic.eval()\n",
    "#         for step in range(config['adversarial']['actor_steps']):\n",
    "#             actor_optimizer.zero_grad()\n",
    "#             indices = torch.randint(0, data.X_valid.size(0), (config['adversarial']['batch_size'],))\n",
    "#             cy_valid = data.y_valid_gpu[indices]\n",
    "#             cX_valid = data.X_valid_gpu[indices]\n",
    "\n",
    "#             pred_bias = critic(actor.trunc_forward(cX_valid)) # outputs of adversary model\n",
    "#             bceloss = actor_loss_fn(actor(cX_valid)[:, 0], cy_valid)\n",
    "\n",
    "#             # loss = lam*abs(pred_bias) + (1-lam)*loss   \n",
    "\n",
    "#             # max(1, lambda * abs(outputs of adversary model) - epsilon (hypderparam) + margin + 1)\n",
    "#             # epsilon = target bias (0.09?)\n",
    "#             # margin = margin of error\n",
    "#             objloss = max(1, config['adversarial']['lambda']*(abs(pred_bias[0][0])-config['objective']['epsilon']+config['adversarial']['margin'])+1) * bceloss\n",
    "#             # ce-loss instead of BCE\n",
    "#             # dont need to binarize\n",
    "            \n",
    "#             objloss.backward()\n",
    "#             train_loss = objloss.item()\n",
    "#             actor_optimizer.step()\n",
    "#             if (epoch % 10 == 0) and (step % 100 == 0):\n",
    "#                 logger.info(f'=======> Actor Epoch: {(epoch, step)} loss: {train_loss}')\n",
    "\n",
    "#         if epoch % 10 == 0:\n",
    "#             with torch.no_grad():\n",
    "#                 scores = actor(data.X_valid_gpu)[:, 0].reshape(-1, 1).cpu().numpy()\n",
    "#                 _, best_adv_obj = get_best_thresh(scores, np.linspace(0, 1, 1001), data, config, valid=False, margin=config['adversarial']['margin'])\n",
    "#                 logger.info(f'Objective: {best_adv_obj}')\n",
    "\n",
    "#     logger.info('Finding optimal threshold for Adversarial model.')\n",
    "#     with torch.no_grad():\n",
    "#         scores = actor(data.X_valid_gpu)[:, 0].reshape(-1, 1).cpu().numpy()\n",
    "\n",
    "#     best_adv_thresh, _ = get_best_thresh(scores, np.linspace(0, 1, 1001), data, config, valid=False, margin=config['adversarial']['margin'])\n",
    "\n",
    "#     logger.info('Evaluating Adversarial model on best threshold.')\n",
    "#     with torch.no_grad():\n",
    "#         labels = (actor(data.X_valid_gpu)[:, 0] > best_adv_thresh).reshape(-1, 1).cpu().numpy()\n",
    "#     results_valid = get_valid_objective(labels, data, config)\n",
    "#     logger.info(f'Results: {results_valid}')\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         labels = (actor(data.X_test_gpu)[:, 0] > best_adv_thresh).reshape(-1, 1).cpu().numpy()\n",
    "#     results_test = get_test_objective(labels, data, config)\n",
    "\n",
    "#     # return results_valid, results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836d70b-6686-4e3a-a9e6-e5266f7227ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53514c47-79ca-481f-a3d9-8b9f3abffbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
