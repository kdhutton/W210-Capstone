{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f79206-feac-4302-abb1-d699b6354a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet34_Weights\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils.loss_functions import tkd_kdloss\n",
    "\n",
    "# from models_package.models import Teacher, Student\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3c0ec8-98dc-4933-b9a3-e96fce39c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001379 # 0.096779\n",
    "epochs = 200\n",
    "epochs_pretrain = 3\n",
    "epochs_optimal_lr = 5\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "num_classes = 30\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "patience = 5\n",
    "lmda = 3\n",
    "batch_size = 320\n",
    "num_workers = 4\n",
    "\n",
    "# labels used including for plotting\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "class_names_new = [f\"Class {label}\" for label in range(30)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2770eac-10b7-47de-ba06-9aa63cd7ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46265942-58a1-4c1a-a7ea-82d919a7e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your JSON file is named 'your_file.json'\n",
    "file_path = './WIDER/Annotations/wider_attribute_trainval.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    data = json.load(file)\n",
    "\n",
    "class_idx = data['scene_id_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c922f94-bf69-40d5-bc88-1e6fab4b4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedBatchSampler:\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits=n_batches, shuffle=shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c84514-66c9-4543-8448-cafa751730ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "        # Define the original class labels\n",
    "\n",
    "        # Create a mapping from old labels to new labels\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        # Initialize transformations directly\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ] \n",
    "        )\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                ] \n",
    "            )        \n",
    "\n",
    "        self.anns = []\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs:\n",
    "            t.append(transforms.RandAugment())\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "\n",
    "        return transforms.Compose(t)\n",
    "    \n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            json_data = json.load(open(ann_file, \"r\"))\n",
    "            self.anns += json_data['images']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure the index is within bounds\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            img = Image.open(f'WIDER/Image/{ann[\"file_name\"]}').convert(\"RGB\")\n",
    "\n",
    "            # If this is the wider dataset, proceed with specific processing\n",
    "            # x, y, w, h = ann['bbox']\n",
    "            # img_area = img.crop([x, y, x+w, y+h])\n",
    "            img_area = self.augment(img)\n",
    "            img_area = self.transform(img_area)\n",
    "            attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "            num_people = len(attributes_list)\n",
    "            attributes_distribution = [max(sum(attribute), 0)/num_people for attribute in zip(*attributes_list)]\n",
    "            # Extract label from image path\n",
    "            img_path = f'WIDER/Image/{ann[\"file_name\"]}'\n",
    "            label = self.extract_label(img_path)  # You might need to implement this method\n",
    "            \n",
    "            return {\n",
    "                \"label\": label,\n",
    "                \"target\": torch.tensor([attributes_distribution[0]], dtype=torch.float32),\n",
    "                \"img\": img_area\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during the processing of an image, log the error and the index\n",
    "            print(f\"Error processing image at index {idx}: {e}\")\n",
    "            # Instead of returning None, raise the exception\n",
    "            raise\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            return remapped_label\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2490c2-046a-4a19-9717-642adbabb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012d6bd8-61d5-4a20-845b-689234718508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        # Option 1: Return a placeholder tensor (adapt the shape to match your data)\n",
    "        # return torch.tensor([]), torch.tensor([])\n",
    "        # Option 2: Raise an exception\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe2adb5-687d-4055-a108-a9c041836b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DataSet(train_file, augs = ['RandAugment'], img_size = 226, dataset = 'wider')\n",
    "test_dataset = DataSet(test_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "\n",
    "\n",
    "trainloader = DataLoader(train_dataset, \n",
    "                         batch_sampler=StratifiedBatchSampler(torch.tensor([train_dataset[i]['label'] for i in range(len(train_dataset))]), batch_size=batch_size),\n",
    "                         num_workers=num_workers, collate_fn=custom_collate)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d18d4b-a3c0-4c5b-ad75-e74b6b1b7296",
   "metadata": {},
   "source": [
    "# Start Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c37c867-c1d1-438c-ac22-755904ce121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def calculate_recall_multiclass(conf_matrix):\n",
    "    recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    recalls[np.isnan(recalls)] = 0  # Replace NaN with 0\n",
    "    return recalls\n",
    "\n",
    "def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes=30):\n",
    "    predictions = pred.cpu()\n",
    "    true_labels = label.cpu()\n",
    "    gender = gender.cpu()\n",
    "\n",
    "    # Identify male and female indices based on the gender threshold\n",
    "    male_indices = np.where(gender >= 0.5)[0]\n",
    "    female_indices = np.where(gender < 0.5)[0]\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot_labels = one_hot_encode(true_labels, num_classes=num_classes)\n",
    "    one_hot_preds = one_hot_encode(predictions, num_classes=num_classes)\n",
    "    # Initialize recall arrays\n",
    "    male_recall = np.zeros(num_classes)\n",
    "    female_recall = np.zeros(num_classes)\n",
    "\n",
    "    # Extract predictions and labels for male and female indices\n",
    "    male_predictions = np.argmax(one_hot_preds[male_indices], axis=1)\n",
    "    female_predictions = np.argmax(one_hot_preds[female_indices], axis=1)\n",
    "    male_labels = np.argmax(one_hot_labels[male_indices], axis=1)\n",
    "    female_labels = np.argmax(one_hot_labels[female_indices], axis=1)\n",
    "\n",
    "    # Check if the class labels are within the expected range\n",
    "    assert (0 <= male_predictions.min() < num_classes) and (0 <= male_predictions.max() < num_classes), \"Invalid class indices in male predictions\"\n",
    "    assert (0 <= female_predictions.min() < num_classes) and (0 <= female_predictions.max() < num_classes), \"Invalid class indices in female predictions\"\n",
    "    assert (0 <= male_labels.min() < num_classes) and (0 <= male_labels.max() < num_classes), \"Invalid class indices in male labels\"\n",
    "    assert (0 <= female_labels.min() < num_classes) and (0 <= female_labels.max() < num_classes), \"Invalid class indices in female labels\"\n",
    "\n",
    "    # Calculate confusion matrices for each gender\n",
    "    male_conf_matrix = confusion_matrix(male_labels, male_predictions, labels=np.arange(num_classes))\n",
    "    female_conf_matrix = confusion_matrix(female_labels, female_predictions, labels=np.arange(num_classes))\n",
    "\n",
    "    # Calculate recall for each class and gender\n",
    "    male_recall[:len(male_conf_matrix)] = calculate_recall_multiclass(male_conf_matrix)\n",
    "    female_recall[:len(female_conf_matrix)] = calculate_recall_multiclass(female_conf_matrix)\n",
    "\n",
    "    return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6b93cb-37c9-448f-a8d9-424d3c4d40fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the models\n",
    "###################### Testing 1 ######################\n",
    "# Create instances of your models\n",
    "# teacher_model = torchvision.models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
    "# teacher_model.fc = nn.Linear(512,30)\n",
    "student_model = torchvision.models.resnet18(weights=None).to(device)\n",
    "student_model.fc = nn.Linear(512,30)\n",
    "\n",
    "# Load teacher\n",
    "teacher_model = torch.load('teacher_model_ckd_prof.pth')\n",
    "teacher_model.load_state_dict(torch.load('teacher_model_weights_ckd_prof_checkpoint.pth'))\n",
    "# # Load the studnet\n",
    "# student_model = torch.load('student_model_ckd_prof.pth')\n",
    "# student_model.load_state_dict(torch.load('student_model_weights_ckd_prof_checkpoint.pth'))\n",
    "# student_model = student_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836f2993-0505-47c6-85ee-2ad2f45db946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(nn.Module):\n",
    "    def __init__(self, input_size=30):\n",
    "        super(Adversary, self).__init__()\n",
    "\n",
    "        self.a1 = nn.Linear(input_size*2, 16)\n",
    "        self.a2 = nn.Linear(16, 1)  # Output size 1 for regression\n",
    "        nn.init.xavier_normal_(self.a1.weight)\n",
    "        nn.init.kaiming_normal_(self.a2.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        adversary = F.relu(self.a1(input_ids))\n",
    "        adversary_output = self.a2(adversary)  # Linear activation for regression\n",
    "        return adversary_output\n",
    "\n",
    "# Instantiate the Adversary\n",
    "adv = Adversary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a761874d-cc14-482e-9c8c-6342adea3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_student(student, teacher, trainloader, criterion, optimizer, scheduler, device, alpha, temperature, epochs_pretrain, patience=5):\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs_pretrain):\n",
    "        student.train()\n",
    "        student.to(device)\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        # epoch_disparity = 0.0\n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "            \n",
    "            # If not scalar, sum up to make sure the loss is scalar\n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "                \n",
    "            # Now combine the losses\n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        print(f'*******Epoch {epoch}: loss - {epoch_loss}')\n",
    "        student_epoch_losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "005d66e3-f169-4d59-bc29-b5c0e05816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adversary(adv, student, adversary_optimizer, trainloader, adv_criterion, epochs_pretrain):\n",
    "\n",
    "  for epoch in range(epochs_pretrain):\n",
    "    epoch_loss = 0\n",
    "    epoch_batches = 0\n",
    "    for i, data in enumerate(tqdm(trainloader)): # starting from the 0th batch\n",
    "        # get the inputs and labels\n",
    "        adv.train()\n",
    "        adv.to(device)\n",
    "        inputs = data['img'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        targets = data['target'].to(device)\n",
    "        student = student.to(device)\n",
    "        adversary_optimizer.zero_grad()\n",
    "        student_output = student(inputs)\n",
    "        one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "        concatenated_output = torch.cat((student_output, one_hot_labels), dim=1)\n",
    "        adversary_output = adv(concatenated_output)\n",
    "        adversary_loss = adv_criterion(adversary_output, targets) # compute loss\n",
    "        adversary_loss.backward() # back prop\n",
    "        adversary_optimizer.step()\n",
    "        epoch_loss += adversary_loss.item()\n",
    "        epoch_batches += 1\n",
    "\n",
    "    print(\"Average Pretrain Adversary epoch loss: \", epoch_loss/epoch_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7b4731c-f105-4192-9650-6587c46f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler for the student model\n",
    "student_optimizer = optim.SGD(student_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "student_scheduler = torch.optim.lr_scheduler.StepLR(student_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# Optimizer and scheduler for the teacher model\n",
    "teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "optimizer_adv = optim.Adam(adv.parameters(), lr=learning_rate)\n",
    "\n",
    "# Instantiate the model and the loss function\n",
    "criterion_clf = nn.CrossEntropyLoss()\n",
    "adv_criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b7719f-4d65-4601-8e1d-1015de2201cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:54<00:00,  3.59s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:55<00:00,  3.61s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:55<00:00,  3.61s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:55<00:00,  3.62s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:56<00:00,  3.65s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best learning rate: 0.001139209960739268\n",
      "0.001139209960739268\n"
     ]
    }
   ],
   "source": [
    "#### finding the optimal learning rate\n",
    "def train_teacher_optimal_lr(model, trainloader, criterion, optimizer, scheduler, device, epochs_optimal_lr=5, lr_range=(1e-4, 1e-1), plot_loss=True):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    lr_values = np.logspace(np.log10(lr_range[0]), np.log10(lr_range[1]), epochs_optimal_lr * len(trainloader))  # Generate learning rates for each batch\n",
    "    lr_iter = iter(lr_values)\n",
    "    losses = []\n",
    "    lrs = []\n",
    "    \n",
    "    for epoch in range(epochs_optimal_lr):\n",
    "        for i, batch in enumerate(tqdm(trainloader)):\n",
    "            lr = next(lr_iter)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr  # Set new learning rate\n",
    "            \n",
    "            inputs, labels = batch['img'].to(device), batch['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            lrs.append(lr)\n",
    "    \n",
    "    # Calculate the derivative of the loss\n",
    "    loss_derivative = np.gradient(losses)\n",
    "    \n",
    "    # Find the learning rate corresponding to the minimum derivative (steepest decline)\n",
    "    best_lr_index = np.argmin(loss_derivative)\n",
    "    best_lr = lrs[best_lr_index]\n",
    "    \n",
    "    if plot_loss:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure()\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate Range Test')\n",
    "        plt.axvline(x=best_lr, color='red', linestyle='--', label=f'Best LR: {best_lr}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    print(f'Best learning rate: {best_lr}')\n",
    "    return best_lr\n",
    "\n",
    "############# input ############## \n",
    "best_lr = train_teacher_optimal_lr(teacher_model, trainloader, criterion_clf, teacher_optimizer, teacher_scheduler, device, epochs_optimal_lr)  \n",
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411c4f7a-d0b4-478f-9fa5-5e152e08ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(losses):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    plt.plot(epochs, losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Val Loss Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "286386b2-d6e9-447e-95b5-b3dd8f18010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the teacher model\n",
    "def train_teacher(model, trainloader, criterion, optimizer, scheduler, device, epochs, patience=5):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    epoch_losses = [] \n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches  \n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0  \n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "    \n",
    "                # Forward pass for validation\n",
    "                val_outputs = model(val_inputs)\n",
    "\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "    \n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "            total_val_loss /= num_batches\n",
    "            val_losses.append(total_val_loss)\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}| Validation Accuracy: {accuracy * 100:.2f}%')\n",
    "            \n",
    "        # Check for early stopping\n",
    "        if total_val_loss < best_val_loss:\n",
    "            best_val_loss = total_val_loss\n",
    "            patience_counter = 0 \n",
    "            torch.save(model.state_dict(), f'teacher_model_weights_ckd_prof_checkpoint.pth')\n",
    "            torch.save(model, f'teacher_model_ckd_prof_checkpoint.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print('Early stopping')\n",
    "            break  \n",
    "\n",
    "        scheduler.step()\n",
    "    plot_loss_curve(val_losses)\n",
    "    print(\"Finished Training Teacher\")\n",
    "\n",
    "def train_adversary(adv, student, optimizer, trainloader, criterion, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_batches = 0\n",
    "        for i, data in enumerate(tqdm(trainloader)):\n",
    "            # get the inputs and labels\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            student.eval()\n",
    "            student.to(device)\n",
    "            adv.train()\n",
    "            adv.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            student_output = student(inputs)\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((student_output, one_hot_labels), dim=1)\n",
    "            adversary_output = adv(concatenated_output)\n",
    "\n",
    "            adversary_loss = criterion(adversary_output, targets)\n",
    "            adversary_loss.backward()\n",
    "            epoch_loss += adversary_loss.item()\n",
    "            epoch_batches += 1\n",
    "            optimizer.step()\n",
    "        epoch_loss/=epoch_batches\n",
    "        print(\"Average Adversary epoch loss:\", epoch_loss)\n",
    "\n",
    "\n",
    "# Function to train the student model with knowledge distillation\n",
    "def train_student_with_distillation_disparity(student, teacher, adv, trainloader, testloader, criterion, adv_criterion, optimizer,\n",
    "                                              scheduler, device, alpha, temperature, epochs, lmda, patience=5):\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    num_classes = len(class_labels)\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    val_accuracies = []\n",
    "    for epoch in range(epochs):\n",
    "        student.train()\n",
    "        student.to(device)\n",
    "        adv.eval()\n",
    "        adv.to(device)\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0 \n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "\n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student(inputs)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "            \n",
    "            studetached = student_outputs.detach()\n",
    "            # One-hot encode labels and concatenate with student's predictions\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((studetached, one_hot_labels), dim=1)\n",
    "\n",
    "            # Calculate adversarial loss\n",
    "            with torch.no_grad():\n",
    "                adversary_output = adv(concatenated_output)\n",
    "\n",
    "            adversary_loss = adv_criterion(adversary_output, targets)\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "            \n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "\n",
    "            # Now combine the losses\n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss - lmda * adversary_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches\n",
    "        # print(f'*******Epoch {epoch}: running_recall_with - {running_recall_with/num_batches}  |  running_recall_without - {running_recall_without/num_batches}  |  disparity - {epoch_disparity/num_batches}******')\n",
    "        student_epoch_losses.append(epoch_loss)\n",
    "\n",
    "        student.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        # Validation after each epoch\n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "                val_targets = val_data['target'].to(device)\n",
    "                \n",
    "                # Forward pass for validation\n",
    "                val_student_outputs = student(val_inputs)\n",
    "                val_teacher_outputs = teacher(val_inputs)\n",
    "\n",
    "                val_studetached = val_student_outputs.detach()   \n",
    "                val_one_hot_labels = F.one_hot(val_labels, num_classes=num_classes).to(torch.float32)\n",
    "                val_concatenated_output = torch.cat((val_studetached, val_one_hot_labels), dim=1)\n",
    "                \n",
    "                val_adversary_output = adv(val_concatenated_output)\n",
    "                val_adversary_loss = adv_criterion(val_adversary_output, val_targets)\n",
    "                val_ce_loss = criterion(val_student_outputs, val_labels)\n",
    "                val_kd_loss = tkd_kdloss(val_student_outputs, val_teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "                \n",
    "                if val_kd_loss.ndim != 0:\n",
    "                    val_kd_loss = val_kd_loss.sum()\n",
    "                \n",
    "                val_loss = alpha * val_kd_loss + (1 - alpha) * val_ce_loss - lmda * val_adversary_loss\n",
    "                total_val_loss += val_loss.item()\n",
    "    \n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_student_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(predicted, val_labels, val_targets)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "    \n",
    "            total_val_loss /= num_batches\n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "\n",
    "            epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_losses.append(total_val_loss)\n",
    "            non_zero_abs_values = np.abs(epoch_disparity[epoch_disparity != 0])\n",
    "            mean_non_zero_abs_disparity = np.mean(non_zero_abs_values)\n",
    "            val_disparities.append(mean_non_zero_abs_disparity)\n",
    "            accuracy = total_correct / total_samples\n",
    "            val_accuracies.append(accuracy)\n",
    "            print(f'*****Epoch {epoch + 1}/{epochs}*****\\n' \n",
    "            f'*****Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}*****\\n'\n",
    "            f'*****Validation Accuracy: {accuracy * 100:.2f}%*****\\n'\n",
    "            f'*****Total Avg Disparity: {mean_non_zero_abs_disparity}*****\\n')\n",
    "            class_recall_mapping = {class_name: epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "            \n",
    "            # Print disparities by class label\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                print(f\"Class {class_label}: Recall Difference = {recall_diff}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if total_val_loss < best_val_loss:\n",
    "            best_val_loss = total_val_loss\n",
    "            patience_counter = 0 \n",
    "            torch.save(student.state_dict(), f'student_model_weights_ckd_prof_checkpoint.pth')\n",
    "            torch.save(student, f'student_model_ckd_prof_checkpoint.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print('Early stopping')\n",
    "            break  \n",
    "\n",
    "        scheduler.step()\n",
    "        plot_loss_curve(val_losses)\n",
    "    \n",
    "        file_path = f'validation{lmda}.txt'\n",
    "        \n",
    "        # Write data to the text file\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(\"Val Accuracies:\\n\")\n",
    "            for accuracy in val_accuracies:\n",
    "                file.write(f\"{accuracy}\\n\")\n",
    "        \n",
    "            file.write(\"\\nVal Disparities:\\n\")\n",
    "            for disparity in val_disparities:\n",
    "                file.write(f\"{disparity}\\n\")\n",
    "        \n",
    "        print(f\"Data has been written to {file_path}\")\n",
    "    return np.mean(val_accuracies), np.mean(val_disparities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a06902-9ad4-47a6-9a67-181e2dc43218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:55<00:00,  3.61s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:18<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss:  0.745707 Val Loss:  0.243495| Validation Accuracy: 93.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:55<00:00,  3.62s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:18<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss:  0.366040 Val Loss:  0.106669| Validation Accuracy: 97.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:53<00:00,  3.55s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:18<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss:  0.260352 Val Loss:  0.063151| Validation Accuracy: 98.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:57<00:00,  3.68s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:18<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss:  0.207233 Val Loss:  0.043025| Validation Accuracy: 99.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:55<00:00,  3.60s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:18<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss:  0.140614 Val Loss:  0.022588| Validation Accuracy: 99.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                      | 0/32 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "loops = epochs\n",
    "lmba_list = [0,0.75,1.5,5]\n",
    "\n",
    "teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=best_lr, momentum=momentum)\n",
    "teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "    \n",
    "train_teacher(teacher_model, trainloader, criterion_clf, teacher_optimizer, teacher_scheduler, device, epochs, patience=3)\n",
    "\n",
    "torch.save(teacher_model.state_dict(), 'teacher_model_weights_ckd_wider.pth')\n",
    "torch.save(teacher_model, 'teacher_model_ckd_wider.pth')\n",
    "print('teacher weights and architecture saved and exported')\n",
    "\n",
    "bias_values, accuracy_values = [], []\n",
    "\n",
    "for i in lmba_list:\n",
    "    student_model = torchvision.models.resnet18(weights=None).to(device)\n",
    "    student_model.fc = nn.Linear(512, 30)\n",
    "    adv = Adversary()\n",
    "    student_optimizer = optim.SGD(student_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    student_scheduler = torch.optim.lr_scheduler.StepLR(student_optimizer, step_size=step_size, gamma=gamma)\n",
    "    \n",
    "    optimizer_adv = optim.Adam(adv.parameters(), lr=learning_rate)\n",
    "    \n",
    "    pretrain_student(student_model, teacher_model, trainloader, criterion_clf, student_optimizer, student_scheduler, device, alpha, temperature, epochs_pretrain)\n",
    "    pretrain_adversary(adv, student_model, optimizer_adv, trainloader, adv_criterion, epochs_pretrain)\n",
    "    \n",
    "    for j in range(loops):\n",
    "        train_adversary(adv=adv, student=student_model, optimizer=optimizer_adv, trainloader=trainloader, criterion=adv_criterion, epochs=1)\n",
    "        avg_accuracy, avg_disparity = train_student_with_distillation_disparity(student_model, teacher_model, adv, trainloader, testloader, criterion_clf, adv_criterion, student_optimizer, student_scheduler, device, alpha, temperature, epochs=1, lmda=i, patience=5)\n",
    "    \n",
    "    torch.save(student_model.state_dict(), f'student_model_weights_ckd_wider_lambda{i}.pth')\n",
    "    torch.save(student_model, f'student_model_ckd_wider_lambda{i}.pth')\n",
    "\n",
    "    bias_values.append(avg_disparity)\n",
    "    accuracy_values.append(avg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c941e9-954c-4d7b-932e-06d3297c02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_size(teacher, student):\n",
    "    teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "    student_params = sum(p.numel() for p in student.parameters())\n",
    "    return teacher_params, student_params\n",
    "\n",
    "def compare_inference_time(teacher, student, dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    data = next(dataiter)\n",
    "    inputs = data['img']\n",
    "    \n",
    "    teacher = teacher.to(device)\n",
    "    student = student.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        teacher_outputs = teacher(inputs)\n",
    "    teacher_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        student_outputs = student(inputs)\n",
    "    student_time = time.time() - start_time\n",
    "    \n",
    "    return teacher_time, student_time\n",
    "\n",
    "def compare_performance_metrics(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_teacher_preds = []\n",
    "    all_student_preds = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "            \n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1).cpu().numpy()\n",
    "        student_preds = torch.argmax(student_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_teacher_preds.append(teacher_preds)\n",
    "        all_student_preds.append(student_preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_teacher_preds = np.concatenate(all_teacher_preds)\n",
    "    all_student_preds = np.concatenate(all_student_preds)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': (accuracy_score(all_labels, all_teacher_preds), accuracy_score(all_labels, all_student_preds)),\n",
    "        'precision': (precision_score(all_labels, all_teacher_preds, average='weighted', zero_division=0), precision_score(all_labels, all_student_preds, average='weighted', zero_division=0)),\n",
    "        'recall': (recall_score(all_labels, all_teacher_preds, average='weighted'), recall_score(all_labels, all_student_preds, average='weighted')),\n",
    "        'f1': (f1_score(all_labels, all_teacher_preds, average='weighted'), f1_score(all_labels, all_student_preds, average='weighted'))\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'all_labels': all_labels,\n",
    "        'all_teacher_preds': all_teacher_preds,\n",
    "        'all_student_preds': all_student_preds\n",
    "    }\n",
    "    \n",
    "def plot_comparison(labels, teacher_values, student_values, title, ylabel):\n",
    "    # Convert parameter count to millions\n",
    "    if 'Parameter Count' in title or 'Parameter Count' in ylabel:\n",
    "        teacher_values = [value / 1e6 for value in teacher_values]\n",
    "        student_values = [value / 1e6 for value in student_values]\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, teacher_values, width, label='Teacher')\n",
    "    rects2 = ax.bar(x + width/2, student_values, width, label='Student')\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c59176a-d2e0-4dbc-9526-2bd511ac7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample data (replace this with your actual data)\n",
    "# bias_values = [0.1, 0.15, 0.2, 0.25]\n",
    "# accuracy_values = [0.8, 0.85, 0.88, 0.9]\n",
    "\n",
    "# # Plotting the bias-variance trade-off curve\n",
    "# plt.plot(bias_values, accuracy_values, marker='o', linestyle='-', color='b')\n",
    "# plt.xlabel('Bias')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Bias-Variance Trade-off Curve')\n",
    "\n",
    "# # Identify the optimal point (for simplicity, just finding the maximum accuracy)\n",
    "# optimal_index = accuracy_values.index(max(accuracy_values))\n",
    "# optimal_bias = bias_values[optimal_index]\n",
    "# optimal_accuracy = accuracy_values[optimal_index]\n",
    "\n",
    "# # Mark the optimal point on the curve\n",
    "# plt.scatter(optimal_bias, optimal_accuracy, color='r', label='Optimal Point')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# print(f\"Optimal Bias: {optimal_bias}\")\n",
    "# print(f\"Optimal Accuracy: {optimal_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553968c-56b4-418e-9393-9e149db5b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight for the trade-off\n",
    "weight = 1  # Adjust this weight based on your preference\n",
    "\n",
    "# Calculate the weighted ratio\n",
    "weighted_ratios = np.array(accuracy_values) / (1 - weight * np.array(bias_values))\n",
    "closest_to_one_index = np.argmin(np.abs(weighted_ratios - 1))\n",
    "optimal_bias = bias_values[closest_to_one_index]\n",
    "optimal_accuracy = accuracy_values[closest_to_one_index]\n",
    "optimal_ratio = weighted_ratios[closest_to_one_index]\n",
    "\n",
    "# Plotting the bias-variance trade-off curve\n",
    "plt.plot(bias_values, accuracy_values, marker='o', linestyle='-', color='b', label='Trade-off Points')\n",
    "\n",
    "# Mark all points with their lambda values\n",
    "for i, (bias, acc, lmbda) in enumerate(zip(bias_values, accuracy_values, lmba_list)):\n",
    "    plt.annotate(f'λ={lmbda}', (bias, acc), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# Highlight the optimal point\n",
    "plt.scatter(optimal_bias, optimal_accuracy, color='r', s=100, marker='X', label=f'Optimal Point (λ={lmba_list[closest_to_one_index]})')\n",
    "plt.xlabel('Disparity')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Bias-Variance Trade-off Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Optimal Lambda: {lmba_list[closest_to_one_index]}\")\n",
    "print(f\"Optimal Bias/Disparity: {optimal_bias}\")\n",
    "print(f\"Optimal Accuracy: {optimal_accuracy}\")\n",
    "print(f\"Optimal Weighted Ratio: {optimal_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995827c-1726-44e2-89aa-5f346a3d4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the comparison and plotting functions after training\n",
    "teacher_params, student_params = compare_model_size(teacher_model, student_model)\n",
    "teacher_time, student_time = compare_inference_time(teacher_model, student_model, testloader)\n",
    "performance_metrics = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "\n",
    "# Extracting the metric values for plotting\n",
    "performance_labels = ['accuracy', 'precision', 'recall', 'f1']\n",
    "teacher_performance_values = [performance_metrics['metrics'][metric][0] for metric in performance_labels]\n",
    "student_performance_values = [performance_metrics['metrics'][metric][1] for metric in performance_labels]\n",
    "\n",
    "# Plotting the comparison for performance metrics\n",
    "plot_comparison(performance_labels, teacher_performance_values, student_performance_values, 'Performance Comparison', 'Score')\n",
    "\n",
    "# Plotting the comparison for model size\n",
    "model_size_labels = ['Model Size']\n",
    "teacher_model_size_values = [teacher_params]\n",
    "student_model_size_values = [student_params]\n",
    "plot_comparison(model_size_labels, teacher_model_size_values, student_model_size_values, 'Model Size Comparison', 'Parameter Count (millions)')\n",
    "\n",
    "# Plotting the comparison for inference time\n",
    "inference_time_labels = ['Inference Time']\n",
    "teacher_inference_time_values = [teacher_time]\n",
    "student_inference_time_values = [student_time]\n",
    "plot_comparison(inference_time_labels, teacher_inference_time_values, student_inference_time_values, 'Inference Time Comparison', 'Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4234e-92ab-4c09-9595-8cafffd77018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot distribution of predictions for both models side by side\n",
    "def plot_combined_distribution(teacher_preds, student_preds, class_names):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Plot for Teacher\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(x=teacher_preds)\n",
    "    plt.title('Teacher Model Predictions')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    # Plot for Student\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.countplot(x=student_preds)\n",
    "    plt.title('Student Model Predictions')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot combined confusion matrix for both Teacher and Student\n",
    "def plot_combined_confusion_matrix(all_labels, teacher_preds, student_preds, class_names):\n",
    "    cm_teacher = confusion_matrix(all_labels, teacher_preds)\n",
    "    cm_student = confusion_matrix(all_labels, student_preds)\n",
    "    # Combine both confusion matrices into one plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Confusion matrix for Teacher\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(pd.DataFrame(cm_teacher, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title('Teacher Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    # Confusion matrix for Student\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(pd.DataFrame(cm_student, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title('Student Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "performance_metrics_teacher = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "all_labels = performance_metrics_teacher['all_labels']\n",
    "all_teacher_preds = performance_metrics_teacher['all_teacher_preds']\n",
    "all_student_preds = performance_metrics_teacher['all_student_preds']\n",
    "\n",
    "# Plot combined distribution side by side for Teacher and Student\n",
    "plot_combined_distribution(all_teacher_preds, all_student_preds, class_names_new)\n",
    "\n",
    "# Plot combined confusion matrix for Teacher and Student\n",
    "plot_combined_confusion_matrix(all_labels, all_teacher_preds, all_student_preds, class_names_new)\n",
    "\n",
    "# Classification report for the Teacher model\n",
    "teacher_report = classification_report(all_labels, all_teacher_preds, target_names=class_names_new, zero_division=0)\n",
    "print('Classification Report - Teacher Model')\n",
    "print(teacher_report)\n",
    "\n",
    "# Classification report for the Student model\n",
    "student_report = classification_report(all_labels, all_student_preds, target_names=class_names_new, zero_division=0)\n",
    "print('Classification Report - Student Model')\n",
    "print(student_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8775a81-993d-40df-b9ec-392a255c3443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c418d0-c555-468f-a2a7-d5cab261c852",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
