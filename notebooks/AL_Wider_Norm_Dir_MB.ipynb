{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d669099-bfa9-4e6a-8442-389a280615dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.33.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3transfer 0.8.0 requires botocore<2.0a.0,>=1.32.7, but you have botocore 1.31.64 which is incompatible.\n",
      "boto3 1.33.1 requires botocore<1.34.0,>=1.33.1, but you have botocore 1.31.64 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorboard --quiet\n",
    "!pip3 install torch --quiet\n",
    "!pip3 install torchvision --quiet \n",
    "!pip3 install matplotlib --quiet \n",
    "!pip3 install pandas --quiet \n",
    "!pip3 install seaborn --quiet \n",
    "!pip3 install scikit-learn --quiet \n",
    "!pip3 install boto3 --quiet \n",
    "!pip3 install pycocotools --quiet\n",
    "!pip3 install s3fs --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f79206-feac-4302-abb1-d699b6354a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import argparse\n",
    "import logging\n",
    "import warnings\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pdb\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck, ResNet18_Weights, ResNet34_Weights, resnet18\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils.loss_functions import tkd_kdloss\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "from models_package.models import Teacher, Student\n",
    "import models_package\n",
    "from utils.loss_functions import DKDLoss, DirectNormLoss, KDLoss\n",
    "from utils.compare_tools import compare_model_size, compare_inference_time, compare_performance_metrics, plot_comparison\n",
    "from utils.misc_tools import colorstr, Save_Checkpoint, AverageMeter, epoch_loop_reviewkd\n",
    "from utils.misc_tools import best_LR, best_LR_wider, train_teacher, train_teacher_wider, retrieve_teacher_class_weights, new_teacher_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3c0ec8-98dc-4933-b9a3-e96fce39c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001379 # 0.096779\n",
    "num_epochs = 240 # 200\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "num_classes = 30\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "patience = 7  # for early stopping\n",
    "lmda = 3\n",
    "batch_size = 12\n",
    "num_workers = 4\n",
    "\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2770eac-10b7-47de-ba06-9aa63cd7ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9190d8-8c94-4a21-9897-df742d8d4ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc486e-c895-4eac-9be6-36361106cacb",
   "metadata": {},
   "source": [
    "## Test dataloader from utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c9ee947-9777-4c78-bf40-9321f8e85781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from data.data_loader import load_wider\n",
    "\n",
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n",
    "\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "\n",
    "trainloader, testloader  = load_wider(train_file, test_file, class_labels, batch_size, num_workers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36dcd580-0c62-4e4f-8d33-7f9daa988cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# # Iterate through batches in the trainloader\n",
    "# for batch_idx, batch in enumerate(trainloader):\n",
    "#     # Only process the first 3 batches\n",
    "#     if batch_idx >= 3:\n",
    "#         break\n",
    "\n",
    "#     # Extract labels for the current batch\n",
    "#     batch_labels = batch['label']\n",
    "\n",
    "#     # Convert batch_labels to a list if it's not already (e.g., if it's a tensor)\n",
    "#     if not isinstance(batch_labels, list):\n",
    "#         batch_labels = batch_labels.tolist()\n",
    "\n",
    "#     # Count the frequency of each label in this batch\n",
    "#     label_counts = Counter(batch_labels)\n",
    "\n",
    "#     # Print the label counts for this batch\n",
    "#     print(f\"Batch {batch_idx + 1} class counts:\")\n",
    "#     for label in range(30):  # Assuming classes are labeled from 0 to 29\n",
    "#         print(f\"  Class {label}: {label_counts[label]} instances\")\n",
    "#     print(\"-\" * 30)  # Just a separator for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4cdf75-0872-4aeb-b303-b41577ec9da3",
   "metadata": {},
   "source": [
    "# Train Teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd3fe9-9eec-41b4-b93b-92e4050053e9",
   "metadata": {},
   "source": [
    "## Prep s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee94888b-d17b-4357-b3ca-cf9d8570cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function\n",
    "model_name = 'resnet32x4_wider'\n",
    "model_weight_path = 'weights/wider_teacher_resnet32x4_weights.pth'\n",
    "num_class = 30\n",
    "data_name = 'wider'  \n",
    "batch_size = 30 \n",
    "bucket_name = '210bucket'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ead9a-1e2d-44f5-a2c2-a09d87490f97",
   "metadata": {},
   "source": [
    "## Load in models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32b19a-6e29-45c3-9fd2-3b292e0b171a",
   "metadata": {},
   "source": [
    "### resnet32x4_wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f6f112-02af-40c4-8c08-115dcefae4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "teacher_name = 'resnet32x4_wider'\n",
    "teacher_model = models_package.__dict__[teacher_name](num_class=30)\n",
    "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd81d11-126f-40d9-8b94-59f319dd26d4",
   "metadata": {},
   "source": [
    "### resnet8x4_wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34253cb5-8c60-479c-a963-8e48ea3bd526",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_name = 'resnet8x4_wider'\n",
    "student_model = models_package.__dict__[student_name](num_class=30)\n",
    "student_model.fc = nn.Linear(teacher_model.fc.in_features, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595ae429-cb22-405d-a749-4ec5f080a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler for the student model\n",
    "student_optimizer = optim.SGD(student_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "student_scheduler = torch.optim.lr_scheduler.StepLR(student_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "# Optimizer and scheduler for the teacher model\n",
    "teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Assuming the device is a CUDA device if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba630caa-caec-4b9f-b9d0-d3698f7a950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_lr = best_LR_wider('resnet32x4_lr_wider_test', teacher_model, trainloader, criterion, teacher_optimizer, teacher_scheduler, device, num_epochs=3)\n",
    "# teacher_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "375b3e13-8dd0-4006-a757-d1562f914e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                | 0/861 [00:00<?, ?it/s]Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "  0%|                                                                                                | 0/861 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m student_lr \u001b[38;5;241m=\u001b[39m \u001b[43mbest_LR_wider\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresnet8x4_lr_wider_test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstudent_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m student_lr\n",
      "File \u001b[0;32m~/W210-Capstone/notebooks/utils/misc_tools.py:369\u001b[0m, in \u001b[0;36mbest_LR_wider\u001b[0;34m(save_name, model, dataloader, criterion, optimizer, scheduler, device, num_epochs, lr_range, plot_loss)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# print(type(outputs), outputs[0], outputs[1])\u001b[39;00m\n\u001b[1;32m    368\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs[\u001b[38;5;241m0\u001b[39m], labels)\n\u001b[0;32m--> 369\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    372\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "student_lr = best_LR_wider('resnet8x4_lr_wider_test', student_model, trainloader, criterion, student_optimizer, student_scheduler, device, num_epochs=3)\n",
    "student_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "830670fb-0c74-40c5-bbbc-be1babcaa98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -f cudnn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd63a0d-492f-4d2d-9470-7e7a12d887f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n",
      "['/opt/conda/lib/python3.10/site-packages/torch']\n",
      "tensor(-7567.3711, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "8905\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.__path__)\n",
    "x = torch.randn(1, 3, 224, 224).cuda()\n",
    "conv = torch.nn.Conv2d(3, 3, 3).cuda()\n",
    "out = conv(x)\n",
    "print(out.sum())\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "359c8510-c8b9-4b6e-b06a-c74feecfb41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_lr = 0.0005953788301881531\n",
    "student_lr = 0.0011397725198066264"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6435bf80-7a48-4f27-b74d-a512e33be0c9",
   "metadata": {},
   "source": [
    "## Train Leaderboard Teacher Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7efb644-a8f8-4f11-833a-a152dbe16602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(losses):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    plt.plot(epochs, losses)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b9a888a5-4716-47f4-a8b6-db85031f1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the teacher model\n",
    "def train_teacher(model, trainloader, criterion, optimizer, scheduler, device, epochs, patience=5):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    epoch_losses = [] \n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            _, outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "\n",
    "        epoch_loss /= num_batches  \n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0  \n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "    \n",
    "                # Forward pass for validation\n",
    "                _, val_outputs = model(val_inputs)\n",
    "    \n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "                total_val_loss += val_loss.item()\n",
    "    \n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "            total_val_loss /= num_batches\n",
    "            val_losses.append(total_val_loss)\n",
    "            accuracy = total_correct / total_samples\n",
    "            print(f'*****Epoch {epoch + 1}/{num_epochs}*****\\n' \n",
    "            f'*****Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}*****\\n'\n",
    "            f'*****Validation Accuracy: {accuracy * 100:.2f}%*****\\n')\n",
    "        # Check for early stopping\n",
    "        if total_val_loss < best_val_loss:\n",
    "            best_val_loss = total_val_loss\n",
    "            patience_counter = 0 \n",
    "            torch.save(model.state_dict(), f'weights/wider/wider_teacher_model_weights_resnet32_4_v2.pth')\n",
    "            torch.save(model, f'weights/wider/wider_teacher_model_resnet32_4.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "        if (patience_counter >= patience):\n",
    "            print('Early stopping')\n",
    "            break  \n",
    "\n",
    "        scheduler.step()\n",
    "    plot_loss_curve(val_losses)\n",
    "    print(\"Finished Training Teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0760d1a1-b34a-417b-8d29-d26c835ad568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 1/240*****\n",
      "*****Train Loss:  2.975912 Val Loss:  2.832626*****\n",
      "*****Validation Accuracy: 24.36%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 2/240*****\n",
      "*****Train Loss:  2.867775 Val Loss:  2.683564*****\n",
      "*****Validation Accuracy: 28.24%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 3/240*****\n",
      "*****Train Loss:  2.782932 Val Loss:  2.592292*****\n",
      "*****Validation Accuracy: 29.71%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 4/240*****\n",
      "*****Train Loss:  2.726390 Val Loss:  2.525979*****\n",
      "*****Validation Accuracy: 31.89%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 5/240*****\n",
      "*****Train Loss:  2.675066 Val Loss:  2.474137*****\n",
      "*****Validation Accuracy: 33.25%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 6/240*****\n",
      "*****Train Loss:  2.622394 Val Loss:  2.351434*****\n",
      "*****Validation Accuracy: 35.59%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 7/240*****\n",
      "*****Train Loss:  2.568667 Val Loss:  2.436075*****\n",
      "*****Validation Accuracy: 33.04%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 8/240*****\n",
      "*****Train Loss:  2.535881 Val Loss:  2.256840*****\n",
      "*****Validation Accuracy: 37.68%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 9/240*****\n",
      "*****Train Loss:  2.495550 Val Loss:  2.275010*****\n",
      "*****Validation Accuracy: 37.88%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 10/240*****\n",
      "*****Train Loss:  2.459619 Val Loss:  2.190971*****\n",
      "*****Validation Accuracy: 40.43%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 11/240*****\n",
      "*****Train Loss:  2.403540 Val Loss:  2.076430*****\n",
      "*****Validation Accuracy: 42.95%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 12/240*****\n",
      "*****Train Loss:  2.360690 Val Loss:  2.041436*****\n",
      "*****Validation Accuracy: 42.86%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 13/240*****\n",
      "*****Train Loss:  2.329874 Val Loss:  1.953692*****\n",
      "*****Validation Accuracy: 45.67%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 14/240*****\n",
      "*****Train Loss:  2.293178 Val Loss:  1.879885*****\n",
      "*****Validation Accuracy: 47.32%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 15/240*****\n",
      "*****Train Loss:  2.261333 Val Loss:  1.994657*****\n",
      "*****Validation Accuracy: 47.47%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 16/240*****\n",
      "*****Train Loss:  2.232436 Val Loss:  1.848849*****\n",
      "*****Validation Accuracy: 49.41%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 17/240*****\n",
      "*****Train Loss:  2.178093 Val Loss:  1.835918*****\n",
      "*****Validation Accuracy: 50.65%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 18/240*****\n",
      "*****Train Loss:  2.150956 Val Loss:  1.670328*****\n",
      "*****Validation Accuracy: 53.95%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 19/240*****\n",
      "*****Train Loss:  2.121356 Val Loss:  1.651692*****\n",
      "*****Validation Accuracy: 53.95%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 20/240*****\n",
      "*****Train Loss:  2.078157 Val Loss:  1.662508*****\n",
      "*****Validation Accuracy: 55.84%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 21/240*****\n",
      "*****Train Loss:  2.053295 Val Loss:  1.609030*****\n",
      "*****Validation Accuracy: 56.10%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 22/240*****\n",
      "*****Train Loss:  2.013248 Val Loss:  1.454697*****\n",
      "*****Validation Accuracy: 59.08%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 23/240*****\n",
      "*****Train Loss:  1.977214 Val Loss:  1.505149*****\n",
      "*****Validation Accuracy: 60.30%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 24/240*****\n",
      "*****Train Loss:  1.935430 Val Loss:  1.376626*****\n",
      "*****Validation Accuracy: 61.45%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 25/240*****\n",
      "*****Train Loss:  1.927781 Val Loss:  1.283436*****\n",
      "*****Validation Accuracy: 63.48%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 26/240*****\n",
      "*****Train Loss:  1.876700 Val Loss:  1.282284*****\n",
      "*****Validation Accuracy: 64.61%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 27/240*****\n",
      "*****Train Loss:  1.849552 Val Loss:  1.200790*****\n",
      "*****Validation Accuracy: 65.13%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 28/240*****\n",
      "*****Train Loss:  1.814569 Val Loss:  1.123950*****\n",
      "*****Validation Accuracy: 68.93%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 29/240*****\n",
      "*****Train Loss:  1.779098 Val Loss:  1.053810*****\n",
      "*****Validation Accuracy: 70.84%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 30/240*****\n",
      "*****Train Loss:  1.741138 Val Loss:  1.017972*****\n",
      "*****Validation Accuracy: 72.37%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 31/240*****\n",
      "*****Train Loss:  1.511468 Val Loss:  0.788739*****\n",
      "*****Validation Accuracy: 78.89%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 32/240*****\n",
      "*****Train Loss:  1.446959 Val Loss:  0.726977*****\n",
      "*****Validation Accuracy: 80.34%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 33/240*****\n",
      "*****Train Loss:  1.420945 Val Loss:  0.766250*****\n",
      "*****Validation Accuracy: 80.28%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 34/240*****\n",
      "*****Train Loss:  1.413108 Val Loss:  0.681158*****\n",
      "*****Validation Accuracy: 82.13%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 35/240*****\n",
      "*****Train Loss:  1.395909 Val Loss:  0.659833*****\n",
      "*****Validation Accuracy: 82.88%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 36/240*****\n",
      "*****Train Loss:  1.384891 Val Loss:  0.629670*****\n",
      "*****Validation Accuracy: 83.23%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 37/240*****\n",
      "*****Train Loss:  1.376336 Val Loss:  0.632562*****\n",
      "*****Validation Accuracy: 83.46%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 38/240*****\n",
      "*****Train Loss:  1.342710 Val Loss:  0.616038*****\n",
      "*****Validation Accuracy: 83.96%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 39/240*****\n",
      "*****Train Loss:  1.344695 Val Loss:  0.641235*****\n",
      "*****Validation Accuracy: 84.33%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 40/240*****\n",
      "*****Train Loss:  1.319341 Val Loss:  0.578644*****\n",
      "*****Validation Accuracy: 85.38%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 41/240*****\n",
      "*****Train Loss:  1.308076 Val Loss:  0.585056*****\n",
      "*****Validation Accuracy: 85.87%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 42/240*****\n",
      "*****Train Loss:  1.314618 Val Loss:  0.537000*****\n",
      "*****Validation Accuracy: 86.71%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 43/240*****\n",
      "*****Train Loss:  1.292363 Val Loss:  0.554035*****\n",
      "*****Validation Accuracy: 86.65%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 44/240*****\n",
      "*****Train Loss:  1.277977 Val Loss:  0.621968*****\n",
      "*****Validation Accuracy: 86.71%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 45/240*****\n",
      "*****Train Loss:  1.283398 Val Loss:  0.534673*****\n",
      "*****Validation Accuracy: 87.69%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 46/240*****\n",
      "*****Train Loss:  1.275791 Val Loss:  0.601946*****\n",
      "*****Validation Accuracy: 87.84%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 47/240*****\n",
      "*****Train Loss:  1.269344 Val Loss:  0.490451*****\n",
      "*****Validation Accuracy: 89.23%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 48/240*****\n",
      "*****Train Loss:  1.245756 Val Loss:  0.537412*****\n",
      "*****Validation Accuracy: 88.82%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 49/240*****\n",
      "*****Train Loss:  1.224669 Val Loss:  0.473802*****\n",
      "*****Validation Accuracy: 90.18%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 50/240*****\n",
      "*****Train Loss:  1.207268 Val Loss:  0.521587*****\n",
      "*****Validation Accuracy: 89.17%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 51/240*****\n",
      "*****Train Loss:  1.215481 Val Loss:  0.555573*****\n",
      "*****Validation Accuracy: 88.97%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 52/240*****\n",
      "*****Train Loss:  1.204829 Val Loss:  0.480271*****\n",
      "*****Validation Accuracy: 90.30%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 53/240*****\n",
      "*****Train Loss:  1.170098 Val Loss:  0.377572*****\n",
      "*****Validation Accuracy: 91.72%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 54/240*****\n",
      "*****Train Loss:  1.186692 Val Loss:  0.509643*****\n",
      "*****Validation Accuracy: 90.67%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 55/240*****\n",
      "*****Train Loss:  1.162618 Val Loss:  0.473375*****\n",
      "*****Validation Accuracy: 91.40%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 56/240*****\n",
      "*****Train Loss:  1.155412 Val Loss:  0.464141*****\n",
      "*****Validation Accuracy: 91.78%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 57/240*****\n",
      "*****Train Loss:  1.136737 Val Loss:  0.425121*****\n",
      "*****Validation Accuracy: 92.85%*****\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [04:40<00:00,  3.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 288/288 [00:28<00:00, 10.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 58/240*****\n",
      "*****Train Loss:  1.122533 Val Loss:  0.445387*****\n",
      "*****Validation Accuracy: 91.80%*****\n",
      "\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Teacher\n"
     ]
    }
   ],
   "source": [
    "train_teacher(teacher_model, trainloader, criterion, teacher_optimizer, teacher_scheduler, device, num_epochs, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a6f99d-69f5-42b5-bac2-085153185387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "student weights and architecture saved and exported\n"
     ]
    }
   ],
   "source": [
    "## backup locally\n",
    "# Save the student and teacher model weights and architecture\n",
    "torch.save(teacher_model.state_dict(), 'weights/wider/wider_teacher_model_weights_resnet32_4.pth')\n",
    "torch.save(teacher_model, 'weights/wider/wider_teacher_model_resnet32_4.pth')\n",
    "print('student weights and architecture saved and exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04157a0f-8745-4b99-80a4-90854e944bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load model \n",
    "teacher_name = 'resnet32x4_wider'\n",
    "teacher_model = models_package.__dict__[teacher_name](num_class=30)\n",
    "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, 30)\n",
    "\n",
    "teacher_model.load_state_dict(torch.load('weights/wider/wider_teacher_model_weights_resnet32_4_v2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40bef11-f622-480a-84eb-c8c97a890f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher weights and architecture saved and exported to S3\n"
     ]
    }
   ],
   "source": [
    "###################### Saving weights and movel using s3 bucket ######################\n",
    "\n",
    "session = boto3.session.Session()\n",
    "s3 = session.client('s3')\n",
    "\n",
    "bucket_name = '210bucket' \n",
    "\n",
    "\n",
    "\n",
    "# Teacher Model\n",
    "#### IMPORTANT!!!!! Change the file name so that you do not overwrite the existing files\n",
    "teacher_model_weights_path = 'weights/teacher_model_resnet32x4_wider.pth'\n",
    "teacher_model_path = 'models/testing_teacher_model_resnet32x4_wider.pth'\n",
    "\n",
    "# Save state dict to buffer\n",
    "teacher_model_weights_buffer = io.BytesIO()\n",
    "torch.save(teacher_model.state_dict(), teacher_model_weights_buffer)\n",
    "teacher_model_weights_buffer.seek(0)\n",
    "\n",
    "# Save entire model to buffer\n",
    "teacher_model_buffer = io.BytesIO()\n",
    "torch.save(teacher_model, teacher_model_buffer)\n",
    "teacher_model_buffer.seek(0)\n",
    "\n",
    "# Upload to S3\n",
    "s3.put_object(Bucket=bucket_name, Key=teacher_model_weights_path, Body=teacher_model_weights_buffer)\n",
    "s3.put_object(Bucket=bucket_name, Key=teacher_model_path, Body=teacher_model_buffer)\n",
    "print('teacher weights and architecture saved and exported to S3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e335c279-3503-4295-8283-00f83bcc386d",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d381d9-c7d5-4785-892f-7e2ba5240c9e",
   "metadata": {},
   "source": [
    "### Pull Model from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e406b14-9b49-4209-892e-cc7ec2070229",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 Nov 2023 21:35:11 [line:1255] Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  (fc): Linear(in_features=12544, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a session using Boto3 again \n",
    "session = boto3.session.Session()\n",
    "\n",
    "s3 = session.client('s3')\n",
    "bucket_name = '210bucket'  \n",
    "\n",
    "teacher_model_weights_s3_path = 'weights/teacher_model_resnet32x4_wider.pth'\n",
    "# student_model_weights_s3_path = 'weights/testing_student_model_weights_rkd_prof.pth'\n",
    "\n",
    "# Read files directly into memory\n",
    "teacher_model_weights_buffer = io.BytesIO()\n",
    "# student_model_weights_buffer = io.BytesIO()\n",
    "\n",
    "s3.download_fileobj(bucket_name, teacher_model_weights_s3_path, teacher_model_weights_buffer)\n",
    "# s3.download_fileobj(bucket_name, student_model_weights_s3_path, student_model_weights_buffer)\n",
    "\n",
    "# Load the weights into the models\n",
    "teacher_model_weights_buffer.seek(0)  # Move to the beginning of the buffer\n",
    "# student_model_weights_buffer.seek(0)  \n",
    "\n",
    "######## MAKE SURE THAT YOU HAVE THE CORRECT MODELS FOR WEIGHTS ########\n",
    "# Teacher\n",
    "teacher_name = 'resnet32x4_wider'\n",
    "teacher_model = models_package.__dict__[teacher_name](num_class=30)\n",
    "teacher_model.fc = nn.Linear(teacher_model.fc.in_features, 30)\n",
    "teacher_model.load_state_dict(torch.load(teacher_model_weights_buffer))\n",
    "teacher_model.eval()\n",
    "# # Student\n",
    "# student_model = CustomResNet18()\n",
    "# student_model.load_state_dict(torch.load(student_model_weights_buffer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908c227-2346-46f5-ba51-cfe78a6c88f2",
   "metadata": {},
   "source": [
    "# Train with Norm and Direction Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a44c558-0689-435f-b703-a4d26d605c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "import models_package  \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_emb_fea(model, dataloader, batch_size):\n",
    "    ''' Used to extract the feature embeddings in a teacher model '''\n",
    "    model.eval()\n",
    "\n",
    "    EMB = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "\n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            images = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "        \n",
    "        # for images, labels in dataloader:\n",
    "        #     images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "            # compute output\n",
    "            emb_fea, logits = model(images, embed=True)\n",
    "\n",
    "            for emb, i in zip(emb_fea, labels):\n",
    "                i = i.item()\n",
    "                emb_size = len(emb) \n",
    "                if str(i) in EMB:\n",
    "                    for j in range(emb_size):\n",
    "                        EMB[str(i)][j].append(round(emb[j].item(), 4))\n",
    "                else:\n",
    "                    EMB[str(i)] = [[] for _ in range(emb_size)]\n",
    "                    for j in range(emb_size):\n",
    "                        EMB[str(i)][j].append(round(emb[j].item(), 4))\n",
    "\n",
    "    for key, value in EMB.items():\n",
    "        for i in range(emb_size):\n",
    "            EMB[key][i] = round(np.array(EMB[key][i]).mean(), 4)\n",
    "\n",
    "    return EMB\n",
    "\n",
    "\n",
    "def retrieve_teacher_class_weights(model_name, model_weight_path, num_class, data_name, dataloader, batch_size, bucket_name):\n",
    "    ''' Use the extracted feature embeddings to create a json of class means for teacher'''\n",
    "\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client('s3')\n",
    "\n",
    "    teacher_model_weights_buffer = io.BytesIO()\n",
    "    s3.download_fileobj(bucket_name, model_weight_path, teacher_model_weights_buffer)\n",
    "    teacher_model_weights_buffer.seek(0)  \n",
    "\n",
    "    # Load the model\n",
    "    model = models_package.__dict__[model_name](num_class=num_class)\n",
    "    checkpoint = torch.load(teacher_model_weights_buffer)\n",
    "    # print(\"Keys in checkpoint:\", checkpoint.keys())\n",
    "    print(\"model is loaded properly\")\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint.items():\n",
    "        name = k[7:] if k.startswith('module.') else k\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "    # emb = get_emb_fea(model=model, dataloader=dataloader, batch_size=batch_size)\n",
    "    # emb_json = json.dumps(emb, indent=4)\n",
    "    # with open(\"./class_means/{}_embedding_fea/{}.json\".format(data_name, model_name), 'w', encoding='utf-8') as f:\n",
    "    #     f.write(emb_json)\n",
    "\n",
    "    emb = get_emb_fea(model=model, dataloader=dataloader, batch_size=batch_size)\n",
    "    emb_json = json.dumps(emb, indent=4)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    output_dir = \"./class_means/{}_embedding_fea\".format(data_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(\"{}/{}.json\".format(output_dir, model_name), 'w', encoding='utf-8') as f:\n",
    "        f.write(emb_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77a182fe-3a58-4c0c-9488-a0b23ff3ec20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is loaded properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 861/861 [33:10<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "retrieve_teacher_class_weights(model_name = teacher_name, model_weight_path = teacher_model_weights_s3_path, num_class = 30, data_name = 'wider', dataloader = trainloader, batch_size = batch_size, bucket_name = bucket_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151735a9-3926-4dcc-a8c4-deb748879bd8",
   "metadata": {},
   "source": [
    "## KD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b943d887-bc00-4e2a-ad1b-74a23d260989",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training script\n",
    "\n",
    "def train(model, teacher, T_EMB, train_dataloader, optimizer, criterion, kd_loss, nd_loss, args, epoch):\n",
    "    train_loss = AverageMeter()\n",
    "    train_error = AverageMeter()\n",
    "\n",
    "    Cls_loss = AverageMeter()\n",
    "    Div_loss = AverageMeter()\n",
    "    Norm_Dir_loss = AverageMeter()\n",
    "\n",
    "    # Model on train mode\n",
    "    model.train()\n",
    "    teacher.eval()\n",
    "    step_per_epoch = len(train_dataloader)\n",
    "\n",
    "    for step, data in enumerate(train_dataloader):\n",
    "        start = time.time()\n",
    "        if torch.cuda.is_available():\n",
    "            # images, labels = images.cuda(), labels.cuda() \n",
    "            images = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            # compute output\n",
    "            s_emb, s_logits = model(images, embed=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                t_emb, t_logits = teacher(images, embed=True)\n",
    "    \n",
    "            # cls loss\n",
    "            cls_loss = criterion(s_logits, labels) * args.cls_loss_factor\n",
    "            # KD loss\n",
    "            div_loss = kd_loss(s_out = s_logits, t_out = t_logits) * min(1.0, epoch/args.warm_up)\n",
    "            # ND loss\n",
    "            norm_dir_loss = nd_loss(s_emb=s_emb, t_emb=t_emb, T_EMB=T_EMB, labels=labels)\n",
    "    \n",
    "            loss = cls_loss + div_loss + norm_dir_loss\n",
    "            # measure accuracy and record loss\n",
    "            batch_size = images.size(0)\n",
    "            _, pred = s_logits.data.cpu().topk(1, dim=1)\n",
    "            train_error.update(torch.ne(pred.squeeze(), labels.cpu()).float().sum().item() / batch_size, batch_size)\n",
    "            train_loss.update(loss.item(), batch_size)\n",
    "    \n",
    "            Cls_loss.update(cls_loss.item(), batch_size)\n",
    "            Div_loss.update(div_loss.item(), batch_size)\n",
    "            Norm_Dir_loss.update(norm_dir_loss.item(), batch_size)\n",
    "    \n",
    "            # compute gradient and do SGD step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "            s1 = '\\r{} [{}/{}]'.format(t, step+1, step_per_epoch)\n",
    "            s2 = ' - {:.2f}ms/step - nd_loss: {:.3f} - kd_loss: {:.3f} - cls_loss: {:.3f} - train_loss: {:.3f} - train_acc: {:.3f}'.format(\n",
    "                 1000 * (time.time() - start), norm_dir_loss.item(), div_loss.item(), cls_loss.item(), train_loss.val, 1-train_error.val)\n",
    "    \n",
    "            print(s1+s2, end='', flush=True)\n",
    "\n",
    "    print()\n",
    "    return Norm_Dir_loss.avg, Div_loss.avg, Cls_loss.avg, train_loss.avg, train_error.avg\n",
    "\n",
    "\n",
    "def test(model, test_dataloader, criterion):\n",
    "    test_loss = AverageMeter()\n",
    "    test_error = AverageMeter()\n",
    "\n",
    "    # Model on eval mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_dataloader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "            # compute logits\n",
    "            logits = model(images, embed=False)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            batch_size = images.size(0)\n",
    "            _, pred = logits.data.cpu().topk(1, dim=1)\n",
    "            test_error.update(torch.ne(pred.squeeze(), labels.cpu()).float().sum().item() / batch_size, batch_size)\n",
    "            test_loss.update(loss.item(), batch_size)\n",
    "\n",
    "    return test_loss.avg, test_error.avg\n",
    "\n",
    "\n",
    "def epoch_loop(model, teacher, train_loader, test_loader, num_class, args):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # model = nn.DataParallel(model, device_ids=args.gpus)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    # teacher = nn.DataParallel(teacher, device_ids=args.gpus)\n",
    "    teacher = nn.DataParallel(teacher)\n",
    "    teacher.to(device)\n",
    "\n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    kd_loss = KDLoss(kl_loss_factor=args.kd_loss_factor, T=args.t).to(device)\n",
    "    nd_loss = DirectNormLoss(num_class=num_class, nd_loss_factor=args.nd_loss_factor).to(device)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.SGD(params=model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=True)\n",
    "\n",
    "    # weights\n",
    "    save_dir = Path(args.save_dir)\n",
    "    weights = save_dir / 'weights'\n",
    "    weights.mkdir(parents=True, exist_ok=True)\n",
    "    last = weights / 'last'\n",
    "    best = weights / 'best'\n",
    "\n",
    "    # acc,loss\n",
    "    acc_loss = save_dir / 'acc_loss'\n",
    "    acc_loss.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_acc_savepath = acc_loss / 'train_acc.npy'\n",
    "    train_loss_savepath = acc_loss / 'train_loss.npy'\n",
    "    val_acc_savepath = acc_loss / 'val_acc.npy'\n",
    "    val_loss_savepath = acc_loss / 'val_loss.npy'\n",
    "\n",
    "    # tensorboard\n",
    "    logdir = save_dir / 'logs'\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "    summary_writer = SummaryWriter(logdir, flush_secs=120)\n",
    "\n",
    "    # resume\n",
    "    if args.resume:\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        best_error = checkpoint['best_error']\n",
    "        train_acc = checkpoint['train_acc']\n",
    "        train_loss = checkpoint['train_loss']\n",
    "        test_acc = checkpoint['test_acc']\n",
    "        test_loss = checkpoint['test_loss']\n",
    "        logger.info(colorstr('green', 'Resuming training from {} epoch'.format(start_epoch)))\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_error = 0\n",
    "        train_acc = []\n",
    "        train_loss = []\n",
    "        test_acc = []\n",
    "        test_loss = []\n",
    "\n",
    "    # Train model\n",
    "    best_error = 1\n",
    "    for epoch in range(start_epoch, args.epochs):\n",
    "        if epoch in [150, 180, 210]:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.1\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, args.epochs))\n",
    "        norm_dir_loss, div_loss, cls_loss, train_epoch_loss, train_error = train(model=model,\n",
    "                                                                                 teacher=teacher,\n",
    "                                                                                 T_EMB=T_EMB,\n",
    "                                                                                 train_dataloader=train_loader,\n",
    "                                                                                 optimizer=optimizer,\n",
    "                                                                                 criterion=criterion,\n",
    "                                                                                 kd_loss=kd_loss,\n",
    "                                                                                 nd_loss=nd_loss,\n",
    "                                                                                 args=args,\n",
    "                                                                                 epoch=epoch)\n",
    "        test_epoch_loss, test_error = test(model=model,\n",
    "                                           test_dataloader=test_loader,\n",
    "                                           criterion=criterion)\n",
    "\n",
    "        s = \"Train Loss: {:.3f}, Train Acc: {:.3f}, Test Loss: {:.3f}, Test Acc: {:.3f}, lr: {:.5f}\".format(\n",
    "            train_epoch_loss, 1-train_error, test_epoch_loss, 1-test_error, optimizer.param_groups[0]['lr'])\n",
    "        logger.info(colorstr('green', s))\n",
    "\n",
    "        # save acc,loss\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        train_acc.append(1-train_error)\n",
    "        test_loss.append(test_epoch_loss)\n",
    "        test_acc.append(1-test_error)\n",
    "\n",
    "        # save model\n",
    "        is_best = test_error < best_error\n",
    "        best_error = min(best_error, test_error)\n",
    "        state = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_error': best_error,\n",
    "                'train_acc': train_acc,\n",
    "                'train_loss': train_loss,\n",
    "                'test_acc': test_acc,\n",
    "                'test_loss': test_loss,\n",
    "            }\n",
    "\n",
    "        last_path = last / 'epoch_{}_loss_{:.3f}_acc_{:.3f}'.format(\n",
    "            epoch + 1, test_epoch_loss, 1-test_error)\n",
    "        best_path = best / 'epoch_{}_acc_{:.3f}'.format(\n",
    "                epoch + 1, 1-best_error)\n",
    "\n",
    "        Save_Checkpoint(state, last, last_path, best, best_path, is_best)\n",
    "\n",
    "        # tensorboard\n",
    "        if epoch == 1:\n",
    "            images, labels = next(iter(train_loader))\n",
    "            img_grid = torchvision.utils.make_grid(images)\n",
    "            summary_writer.add_image('Image', img_grid)\n",
    "        summary_writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "        summary_writer.add_scalar('train_loss', train_epoch_loss, epoch)\n",
    "        summary_writer.add_scalar('train_error', train_error, epoch)\n",
    "        summary_writer.add_scalar('val_loss', test_epoch_loss, epoch)\n",
    "        summary_writer.add_scalar('val_error', test_error, epoch)\n",
    "\n",
    "        summary_writer.add_scalar('nd_loss', norm_dir_loss, epoch)\n",
    "        summary_writer.add_scalar('kd_loss', div_loss, epoch)\n",
    "        summary_writer.add_scalar('cls_loss', cls_loss, epoch)\n",
    "\n",
    "    summary_writer.close()\n",
    "    import os\n",
    "    if not os.path.exists(train_acc_savepath) or not os.path.exists(train_loss_savepath):\n",
    "        np.save(train_acc_savepath, train_acc)\n",
    "        np.save(train_loss_savepath, train_loss)\n",
    "        np.save(val_acc_savepath, test_acc)\n",
    "        np.save(val_loss_savepath, test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a50c01e3-938d-4553-8b1c-6b616625de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 Nov 2023 21:50:17 [line:53] \u001b[32mDistribute train, total batch size:600, epoch:1\u001b[0m\n",
      "28 Nov 2023 21:50:17 [line:1255] Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Teacher Weights\n",
      "210bucket\n",
      "weights/teacher_model_resnet32x4_wider.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28 Nov 2023 21:50:17 [line:93] \u001b[32mUse resnet32x4_wider Training resnet8x4_wider ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n",
      "Could not load library libcudnn_cnn_train.so.8. Error: /usr/local/cuda/lib/libcudnn_cnn_train.so.8: undefined symbol: _ZN5cudnn3cnn34layerNormFwd_execute_internal_implERKNS_7backend11VariantPackEP11CUstream_stRNS0_18LayerNormFwdParamsERKNS1_20NormForwardOperationEmb, version libcudnn_cnn_infer.so.8\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(colorstr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m args\u001b[38;5;241m.\u001b[39mteacher \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Training \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m args\u001b[38;5;241m.\u001b[39mmodel_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[43mepoch_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 153\u001b[0m, in \u001b[0;36mepoch_loop\u001b[0;34m(model, teacher, train_loader, test_loader, num_class, args)\u001b[0m\n\u001b[1;32m    151\u001b[0m         param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mepochs))\n\u001b[0;32m--> 153\u001b[0m norm_dir_loss, div_loss, cls_loss, train_epoch_loss, train_error \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mteacher\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mT_EMB\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT_EMB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mkd_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkd_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mnd_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnd_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m                                                                         \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m test_epoch_loss, test_error \u001b[38;5;241m=\u001b[39m test(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    164\u001b[0m                                    test_dataloader\u001b[38;5;241m=\u001b[39mtest_loader,\n\u001b[1;32m    165\u001b[0m                                    criterion\u001b[38;5;241m=\u001b[39mcriterion)\n\u001b[1;32m    167\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, Train Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, Test Loss: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, Test Acc: \u001b[39m\u001b[38;5;132;01m{:.3f}\u001b[39;00m\u001b[38;5;124m, lr: \u001b[39m\u001b[38;5;132;01m{:.5f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    168\u001b[0m     train_epoch_loss, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mtrain_error, test_epoch_loss, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mtest_error, optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[17], line 49\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, teacher, T_EMB, train_dataloader, optimizer, criterion, kd_loss, nd_loss, args, epoch)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# compute gradient and do SGD step\u001b[39;00m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 49\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m, time\u001b[38;5;241m.\u001b[39mlocaltime(time\u001b[38;5;241m.\u001b[39mtime()))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_names = sorted(name for name in models_package.__dict__\n",
    "                         if name.islower() and not name.startswith(\"__\")\n",
    "                         and callable(models_package.__dict__[name]))\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='PyTorch Cifar Training')\n",
    "    parser.add_argument('-f') # added to make this run in collab\n",
    "    parser.add_argument(\"--model_name\", type=str, default=\"resnet8x4_wider\", choices=model_names, help=\"model architecture\")\n",
    "    parser.add_argument(\"--dataset\", type=str, default='wider')\n",
    "    parser.add_argument(\"--num_class\", type=int, default=30, help=\"number of classes in dataset\")\n",
    "\n",
    "    parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "    # parser.add_argument(\"--epochs\", type=int, default=4)\n",
    "    parser.add_argument(\"--batch_size\", type=int, default=300, help=\"batch size per gpu\")\n",
    "    parser.add_argument('--workers', default=8, type=int, help='number of data loading workers')\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.1)\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='SGD momentum')\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=5e-4)\n",
    "\n",
    "    parser.add_argument(\"--teacher\", type=str, default=\"resnet32x4_wider\", help=\"teacher architecture\")\n",
    "    parser.add_argument(\"--teacher_weights\", type=str, default=\"weights/teacher_model_resnet32x4_wider.pth\", help=\"teacher weights path\")\n",
    "    parser.add_argument(\"--cls_loss_factor\", type=float, default=1.0, help=\"cls loss weight factor\")\n",
    "    parser.add_argument(\"--kd_loss_factor\", type=float, default=1.0, help=\"KD loss weight factor\")\n",
    "    parser.add_argument(\"--t\", type=float, default=4.0, help=\"temperature\")\n",
    "    parser.add_argument(\"--nd_loss_factor\", type=float, default=1.0, help=\"ND loss weight factor\")\n",
    "    parser.add_argument(\"--warm_up\", type=float, default=20.0, help='loss weight warm up epochs')\n",
    "\n",
    "    parser.add_argument(\"--gpus\", type=list, default=[0, 1])\n",
    "    parser.add_argument('--seed', default=None, type=int, help='seed for initializing training.')\n",
    "    parser.add_argument(\"--resume\", type=str, help=\"best ckpt's path to resume most recent training\")\n",
    "    parser.add_argument(\"--save_dir\", type=str, default=\"./run/WIDER/KD++\", help=\"save path, eg, acc_loss, weights, tensorboard, and so on\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.seed is not None:\n",
    "        random.seed(args.seed)\n",
    "        torch.manual_seed(args.seed)\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = False\n",
    "        warnings.warn('You have chosen to seed training. '\n",
    "                      'This will turn on the CUDNN deterministic setting, '\n",
    "                      'which can slow down your training considerably! '\n",
    "                      'You may see unexpected behavior when restarting '\n",
    "                      'from checkpoints.')\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s [line:%(lineno)d] %(message)s',\n",
    "                        datefmt='%d %b %Y %H:%M:%S')\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    args.batch_size = args.batch_size * len(args.gpus)\n",
    "    # args.batch_size = args.batch_size * 1\n",
    "\n",
    "    # logger.info(colorstr('green', \"Distribute train, gpus:{}, total batch size:{}, epoch:{}\".format(args.gpus, args.batch_size, args.epochs)))\n",
    "    logger.info(colorstr('green', \"Distribute train, total batch size:{}, epoch:{}\".format(args.batch_size, args.epochs)))\n",
    "\n",
    "\n",
    "    # train_set, test_set, num_class = IDENPROF(name=args.dataset)\n",
    "    model = models_package.__dict__[args.model_name](num_class=args.num_class)\n",
    "\n",
    "    # if args.model_name in ['wrn40_1_cifar', 'mobilenetv2', 'shufflev1_cifar', 'shufflev2_cifar']:\n",
    "    #     model = EmbTrans(student=model, model_name=args.model_name)\n",
    "\n",
    "    teacher = models_package.__dict__[args.teacher](num_class=args.num_class)\n",
    "\n",
    "    if args.teacher_weights:\n",
    "        print('Load Teacher Weights')\n",
    "        session = boto3.session.Session()\n",
    "        s3 = session.client('s3')\n",
    "        bucket_name = '210bucket'  \n",
    "        \n",
    "        teacher_model_weights_buffer = io.BytesIO()\n",
    "        print(bucket_name)\n",
    "        print(teacher_model_weights_s3_path)\n",
    "        s3.download_fileobj(bucket_name, args.teacher_weights, teacher_model_weights_buffer)\n",
    "        teacher_model_weights_buffer.seek(0)  \n",
    "\n",
    "        # Load the model\n",
    "        # model = models_package.__dict__[model_name](num_class=num_class)\n",
    "        teacher_ckpt = torch.load(teacher_model_weights_buffer)\n",
    "        teacher.load_state_dict(teacher_ckpt)\n",
    "        \n",
    "        for param in teacher.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # res56    ./ckpt/teacher/resnet56/center_emb_train.json\n",
    "    # res32x4  ./ckpt/teacher/resnet32x4/center_emb_train.json\n",
    "    # wrn40_2  ./ckpt/teacher/wrn_40_2/center_emb_train.json\n",
    "    # res50    ./ckpt/teacher/resnet50/center_emb_train.json\n",
    "    # class-mean\n",
    "    with open(\"./class_means/wider_embedding_fea/resnet32x4_wider.json\", 'r') as f:\n",
    "        T_EMB = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    logger.info(colorstr('green', 'Use ' + args.teacher + ' Training ' + args.model_name + ' ...'))\n",
    "    # Train the model\n",
    "    epoch_loop(model=model, teacher=teacher, train_loader = trainloader, test_loader = testloader, num_class = num_class, args=args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cd0a8d-afab-4366-91b7-54db91d9bebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n",
      "True\n",
      "12.1\n",
      "8905\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118422d0-413c-4b76-96cb-3ed3518e62a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
