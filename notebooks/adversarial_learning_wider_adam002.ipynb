{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f79206-feac-4302-abb1-d699b6354a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet34_Weights\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils.loss_functions import tkd_kdloss\n",
    "# from models_package.models import Teacher, Student\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3c0ec8-98dc-4933-b9a3-e96fce39c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001379 # 0.096779\n",
    "epochs = 1 #300\n",
    "epochs_pretrain = 1 #3\n",
    "epochs_optimal_lr = 1 #5\n",
    "patience_teacher = 3\n",
    "patience_student = 10\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "lmda = 3\n",
    "batch_size = 256 #384\n",
    "num_workers = 4\n",
    "\n",
    "# set to true to use stratified sampling\n",
    "stratified_sampling_flag = False\n",
    "\n",
    "# list of lambda values to loop through for grid search\n",
    "lmda_list = [0,5]\n",
    "\n",
    "# labels used including for plotting\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "class_names_new = [f\"Class {label}\" for label in range(30)]\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# Create directory and file path to save all outputs\n",
    "output_dir = f'./runs_{datetime.now().strftime(\"%Y_%m_%d_%H_%M\")}'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2770eac-10b7-47de-ba06-9aa63cd7ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46265942-58a1-4c1a-a7ea-82d919a7e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your JSON file is named 'your_file.json'\n",
    "file_path = './WIDER/Annotations/wider_attribute_trainval.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    data = json.load(file)\n",
    "\n",
    "class_idx = data['scene_id_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c922f94-bf69-40d5-bc88-1e6fab4b4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedBatchSampler:\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits=n_batches, shuffle=shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c84514-66c9-4543-8448-cafa751730ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "\n",
    "        # Create a mapping from old labels to new labels\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        # Initialize transformations directly\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ] \n",
    "        )\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                ] \n",
    "            )        \n",
    "\n",
    "        self.anns = []\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs:\n",
    "            t.append(transforms.RandAugment())\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "\n",
    "        return transforms.Compose(t)\n",
    "    \n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            json_data = json.load(open(ann_file, \"r\"))\n",
    "            self.anns += json_data['images']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure the index is within bounds\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            img = Image.open(f'WIDER/Image/{ann[\"file_name\"]}').convert(\"RGB\")\n",
    "\n",
    "            # If this is the wider dataset, proceed with specific processing\n",
    "            # x, y, w, h = ann['bbox']\n",
    "            # img_area = img.crop([x, y, x+w, y+h])\n",
    "            img_area = self.augment(img)\n",
    "            img_area = self.transform(img_area)\n",
    "            attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "            num_people = len(attributes_list)\n",
    "            attributes_distribution = [max(sum(attribute), 0)/num_people for attribute in zip(*attributes_list)]\n",
    "            # Extract label from image path\n",
    "            img_path = f'WIDER/Image/{ann[\"file_name\"]}'\n",
    "            label = self.extract_label(img_path)  # You might need to implement this method\n",
    "            \n",
    "            return {\n",
    "                \"label\": label,\n",
    "                \"target\": torch.tensor([attributes_distribution[0]], dtype=torch.float32),\n",
    "                \"img\": img_area\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during the processing of an image, log the error and the index\n",
    "            print(f\"Error processing image at index {idx}: {e}\")\n",
    "            # Instead of returning None, raise the exception\n",
    "            raise\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            return remapped_label\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea2490c2-046a-4a19-9717-642adbabb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "012d6bd8-61d5-4a20-845b-689234718508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe2adb5-687d-4055-a108-a9c041836b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DataSet(train_file, augs = ['RandAugment'], img_size = 226, dataset = 'wider')\n",
    "test_dataset = DataSet(test_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "\n",
    "\n",
    "if stratified_sampling_flag:\n",
    "    trainloader = DataLoader(train_dataset, \n",
    "                             batch_sampler=StratifiedBatchSampler(torch.tensor([train_dataset[i]['label'] for i in range(len(train_dataset))]), \n",
    "                             batch_size=batch_size), num_workers=num_workers, collate_fn=custom_collate)\n",
    "else:\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=num_workers, collate_fn=custom_collate)\n",
    "\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d18d4b-a3c0-4c5b-ad75-e74b6b1b7296",
   "metadata": {},
   "source": [
    "# Start Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c37c867-c1d1-438c-ac22-755904ce121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def calculate_recall_multiclass(conf_matrix):\n",
    "    recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    recalls[np.isnan(recalls)] = 0  # Replace NaN with 0\n",
    "    return recalls\n",
    "\n",
    "def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes=30):\n",
    "    predictions = pred.cpu()\n",
    "    true_labels = label.cpu()\n",
    "    gender = gender.cpu()\n",
    "\n",
    "    # Identify male and female indices based on the gender threshold\n",
    "    male_indices = np.where(gender >= 0.5)[0]\n",
    "    female_indices = np.where(gender < 0.5)[0]\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot_labels = one_hot_encode(true_labels, num_classes=num_classes)\n",
    "    one_hot_preds = one_hot_encode(predictions, num_classes=num_classes)\n",
    "    # Initialize recall arrays\n",
    "    male_recall = np.zeros(num_classes)\n",
    "    female_recall = np.zeros(num_classes)\n",
    "\n",
    "    # Extract predictions and labels for male and female indices\n",
    "    male_predictions = np.argmax(one_hot_preds[male_indices], axis=1)\n",
    "    female_predictions = np.argmax(one_hot_preds[female_indices], axis=1)\n",
    "    male_labels = np.argmax(one_hot_labels[male_indices], axis=1)\n",
    "    female_labels = np.argmax(one_hot_labels[female_indices], axis=1)\n",
    "\n",
    "    # Check if the class labels are within the expected range\n",
    "    assert (0 <= male_predictions.min() < num_classes) and (0 <= male_predictions.max() < num_classes), \"Invalid class indices in male predictions\"\n",
    "    assert (0 <= female_predictions.min() < num_classes) and (0 <= female_predictions.max() < num_classes), \"Invalid class indices in female predictions\"\n",
    "    assert (0 <= male_labels.min() < num_classes) and (0 <= male_labels.max() < num_classes), \"Invalid class indices in male labels\"\n",
    "    assert (0 <= female_labels.min() < num_classes) and (0 <= female_labels.max() < num_classes), \"Invalid class indices in female labels\"\n",
    "\n",
    "    # Calculate confusion matrices for each gender\n",
    "    male_conf_matrix = confusion_matrix(male_labels, male_predictions, labels=np.arange(num_classes))\n",
    "    female_conf_matrix = confusion_matrix(female_labels, female_predictions, labels=np.arange(num_classes))\n",
    "\n",
    "    # Calculate recall for each class and gender\n",
    "    male_recall[:len(male_conf_matrix)] = calculate_recall_multiclass(male_conf_matrix)\n",
    "    female_recall[:len(female_conf_matrix)] = calculate_recall_multiclass(female_conf_matrix)\n",
    "\n",
    "    return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c6b93cb-37c9-448f-a8d9-424d3c4d40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "###################### Testing 1 ######################\n",
    "# Create instances of your models\n",
    "# teacher_model = torchvision.models.resnet34(weights=ResNet34_Weights.IMAGENET1K_V1).to(device)\n",
    "# teacher_model.fc = nn.Linear(512, num_clasess)\n",
    "student_model = torchvision.models.resnet18(weights=None)\n",
    "student_model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "# Load teacher\n",
    "teacher_model = torch.load('teacher_model_ckd_wider.pth')\n",
    "teacher_model.load_state_dict(torch.load('teacher_model_weights_ckd_wider.pth'))\n",
    "torch.save(teacher_model.state_dict(), 'teacher_model_weights_ckd_wider.pth')\n",
    "# # Load the studnet\n",
    "# student_model = torch.load('student_model_ckd_prof.pth')\n",
    "# student_model.load_state_dict(torch.load('student_model_weights_ckd_prof_checkpoint.pth'))\n",
    "# student_model = student_model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcd643-ac9d-4e22-821a-4c784c86e4a5",
   "metadata": {},
   "source": [
    "This is the initialization of the 2-layer Adversary Perceptron. It is initialized with the number of classes*2, which represents the predicted labels (y_hat) and the true labels (y). The output of the final layer is a regression output, which is intended to predict the strength of gender (continuous number where anything past 0.5 is more male).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836f2993-0505-47c6-85ee-2ad2f45db946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(nn.Module):\n",
    "    def __init__(self, input_size=30):\n",
    "        super(Adversary, self).__init__()\n",
    "\n",
    "        self.a1 = nn.Linear(input_size*2, 16)\n",
    "        self.a2 = nn.Linear(16, 1)  # Output size 1 for regression\n",
    "        nn.init.xavier_normal_(self.a1.weight)\n",
    "        nn.init.kaiming_normal_(self.a2.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        adversary = F.relu(self.a1(input_ids))\n",
    "        adversary_output = F.sigmoid(self.a2(adversary))  # Linear activation for regression\n",
    "        return adversary_output\n",
    "\n",
    "# Instantiate the Adversary\n",
    "adv = Adversary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a761874d-cc14-482e-9c8c-6342adea3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_student(student, teacher, trainloader, criterion, optimizer, device, alpha, temperature, epochs_pretrain, patience=patience_student):\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs_pretrain):\n",
    "        student.train()\n",
    "        student.to(device)\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "            \n",
    "            # If not scalar, sum up to make sure the loss is scalar\n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "                \n",
    "            # Now combine the losses\n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        print(f'*******Epoch {epoch}: loss - {epoch_loss}')\n",
    "        student_epoch_losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f4630d-f0d5-4d83-b61f-8707df8800a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_teacher(teacher, trainloader, criterion, optimizer, device, epochs_pretrain, patience=patience_student):\n",
    "    teacher.to(device)\n",
    "    teacher.train()  # Set the model to training mode\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    teacher_epoch_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs_pretrain):\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            teacher_outputs = teacher(inputs)\n",
    "\n",
    "            ce_loss = criterion(teacher_outputs, labels)\n",
    "                \n",
    "            loss = ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        print(f'*******Epoch {epoch}: loss - {epoch_loss}')\n",
    "        teacher_epoch_losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005d66e3-f169-4d59-bc29-b5c0e05816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adversary(adv, student, adversary_optimizer, trainloader, adv_criterion, device, epochs_pretrain):\n",
    "\n",
    "  for epoch in range(epochs_pretrain):\n",
    "    epoch_loss = 0\n",
    "    epoch_batches = 0\n",
    "    for i, data in enumerate(tqdm(trainloader)): # starting from the 0th batch\n",
    "        # get the inputs and labels\n",
    "        adv.train()\n",
    "        adv.to(device)\n",
    "        inputs = data['img'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        targets = data['target'].to(device)\n",
    "        student = student.to(device)\n",
    "        adversary_optimizer.zero_grad()\n",
    "        student_output = student(inputs)\n",
    "        one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "        concatenated_output = torch.cat((student_output, one_hot_labels), dim=1)\n",
    "        adversary_output = adv(concatenated_output)\n",
    "        adversary_loss = adv_criterion(adversary_output, targets) # compute loss\n",
    "        adversary_loss.backward() # back prop\n",
    "        adversary_optimizer.step()\n",
    "        epoch_loss += adversary_loss.item()\n",
    "        epoch_batches += 1\n",
    "\n",
    "    print(\"Average Pretrain Adversary epoch loss: \", epoch_loss/epoch_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7b4731c-f105-4192-9650-6587c46f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler for the student model\n",
    "student_optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Optimizer and scheduler for the teacher model\n",
    "teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "optimizer_adv = optim.Adam(adv.parameters(), lr=learning_rate)\n",
    "\n",
    "# Instantiate the model and the loss function\n",
    "criterion_clf = nn.CrossEntropyLoss()\n",
    "adv_criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b7719f-4d65-4601-8e1d-1015de2201cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [01:56<00:00,  2.85s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Learning Rate Teacher: 0.09999999999999999\n",
      "0.09999999999999999\n"
     ]
    }
   ],
   "source": [
    "#### finding the optimal learning rate\n",
    "def train_teacher_optimal_lr(model, trainloader, criterion, optimizer, scheduler, device, epochs_optimal_lr=5, lr_range=(1e-4, 1e-1), plot_loss=True):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    lr_values = np.logspace(np.log10(lr_range[0]), np.log10(lr_range[1]), epochs_optimal_lr * len(trainloader))  # Generate learning rates for each batch\n",
    "    lr_iter = iter(lr_values)\n",
    "    losses = []\n",
    "    lrs = []\n",
    "    \n",
    "    for epoch in range(epochs_optimal_lr):\n",
    "        for i, batch in enumerate(tqdm(trainloader)):\n",
    "            lr = next(lr_iter)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr  # Set new learning rate\n",
    "            \n",
    "            inputs, labels = batch['img'].to(device), batch['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            lrs.append(lr)\n",
    "    \n",
    "    # Calculate the derivative of the loss\n",
    "    loss_derivative = np.gradient(losses)\n",
    "    \n",
    "    # Find the learning rate corresponding to the minimum derivative (steepest decline)\n",
    "    best_lr_index = np.argmin(loss_derivative)\n",
    "    best_lr = lrs[best_lr_index]\n",
    "    \n",
    "    if plot_loss:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure()\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate Range Test - Teacher')\n",
    "        plt.axvline(x=best_lr, color='red', linestyle='--', label=f'Best LR: {best_lr}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    print(f'Best Learning Rate Teacher: {best_lr}')\n",
    "    return best_lr\n",
    "\n",
    "############# input ############## \n",
    "best_lr_teacher = train_teacher_optimal_lr(teacher_model, trainloader, criterion_clf, teacher_optimizer, teacher_scheduler, device, epochs_optimal_lr)  \n",
    "print(best_lr_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997f6f4-9e71-41f1-964e-02d7b98e9b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████▋                                                                                                   | 4/41 [00:13<01:23,  2.27s/it]"
     ]
    }
   ],
   "source": [
    "#### finding the optimal learning rate\n",
    "def train_student_optimal_lr(model, trainloader, criterion, optimizer, device, epochs_optimal_lr=5, lr_range=(1e-4, 1e-1), plot_loss=True):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    lr_values = np.logspace(np.log10(lr_range[0]), np.log10(lr_range[1]), epochs_optimal_lr * len(trainloader))  # Generate learning rates for each batch\n",
    "    lr_iter = iter(lr_values)\n",
    "    losses = []\n",
    "    lrs = []\n",
    "    \n",
    "    for epoch in range(epochs_optimal_lr):\n",
    "        for i, batch in enumerate(tqdm(trainloader)):\n",
    "            lr = next(lr_iter)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr  # Set new learning rate\n",
    "            \n",
    "            inputs, labels = batch['img'].to(device), batch['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            lrs.append(lr)\n",
    "    \n",
    "    # Calculate the derivative of the loss\n",
    "    loss_derivative = np.gradient(losses)\n",
    "    \n",
    "    # Find the learning rate corresponding to the minimum derivative (steepest decline)\n",
    "    best_lr_index = np.argmin(loss_derivative)\n",
    "    best_lr = lrs[best_lr_index]\n",
    "    \n",
    "    if plot_loss:\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure()\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate Range Test - Student')\n",
    "        plt.axvline(x=best_lr, color='red', linestyle='--', label=f'Best LR: {best_lr}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    print(f'Best Learning Rate Student: {best_lr}')\n",
    "    return best_lr\n",
    "\n",
    "############# input ############## \n",
    "best_lr_student = train_student_optimal_lr(student_model, trainloader, criterion_clf, student_optimizer, device, epochs_optimal_lr)  \n",
    "print(best_lr_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089466e-31b2-4546-a48c-940f32d08dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #delete this - for testing\n",
    "# best_lr_teacher = learning_rate\n",
    "# best_lr_student = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411c4f7a-d0b4-478f-9fa5-5e152e08ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(losses):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    plt.plot(epochs, losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Val Loss Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab786c-a8ad-4aac-ad3b-35356a8701c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_size(teacher, student):\n",
    "    teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "    student_params = sum(p.numel() for p in student.parameters())\n",
    "    return teacher_params, student_params\n",
    "\n",
    "def compare_inference_time(teacher, student, dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    data = next(dataiter)\n",
    "    inputs = data['img']\n",
    "    \n",
    "    teacher = teacher.to(device)\n",
    "    student = student.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        teacher_outputs = teacher(inputs)\n",
    "    teacher_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        student_outputs = student(inputs)\n",
    "    student_time = time.time() - start_time\n",
    "    \n",
    "    return teacher_time, student_time\n",
    "\n",
    "def compare_performance_metrics(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_teacher_preds = []\n",
    "    all_student_preds = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "            \n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1).cpu().numpy()\n",
    "        student_preds = torch.argmax(student_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_teacher_preds.append(teacher_preds)\n",
    "        all_student_preds.append(student_preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_teacher_preds = np.concatenate(all_teacher_preds)\n",
    "    all_student_preds = np.concatenate(all_student_preds)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': (accuracy_score(all_labels, all_teacher_preds), accuracy_score(all_labels, all_student_preds)),\n",
    "        'precision': (precision_score(all_labels, all_teacher_preds, average='weighted', zero_division=0), precision_score(all_labels, all_student_preds, average='weighted', zero_division=0)),\n",
    "        'recall': (recall_score(all_labels, all_teacher_preds, average='weighted'), recall_score(all_labels, all_student_preds, average='weighted')),\n",
    "        'f1': (f1_score(all_labels, all_teacher_preds, average='weighted'), f1_score(all_labels, all_student_preds, average='weighted'))\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'all_labels': all_labels,\n",
    "        'all_teacher_preds': all_teacher_preds,\n",
    "        'all_student_preds': all_student_preds\n",
    "    }\n",
    "    \n",
    "def plot_comparison(labels, teacher_values, student_values, title, ylabel):\n",
    "    # Convert parameter count to millions\n",
    "    if 'Parameter Count' in title or 'Parameter Count' in ylabel:\n",
    "        teacher_values = [value / 1e6 for value in teacher_values]\n",
    "        student_values = [value / 1e6 for value in student_values]\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, teacher_values, width, label='Teacher')\n",
    "    rects2 = ax.bar(x + width/2, student_values, width, label='Student')\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def get_model_size(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    num_params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return num_params\n",
    "\n",
    "def get_inference_time(model, dataloader):\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch['img'].to(device)\n",
    "            outputs = model(inputs)\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    avg_time = total_time / len(dataloader.dataset)\n",
    "    return avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c98aee-9c82-46f8-910b-4ca2ae4b9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the adversary training function, where we input the student outputs, \n",
    "# with the true labels into the adversary model created previously.\n",
    "def train_adversary(adv, student, optimizer, trainloader, criterion, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_batches = 0\n",
    "        for i, data in enumerate(tqdm(trainloader)):\n",
    "            # get the inputs and labels\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            student.eval()\n",
    "            student.to(device)\n",
    "            adv.train()\n",
    "            adv.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # output the student model, join with ohe labels. \n",
    "            student_output = student(inputs)\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((student_output, one_hot_labels), dim=1)\n",
    "            adversary_output = adv(concatenated_output)\n",
    "\n",
    "            adversary_loss = criterion(adversary_output, targets)\n",
    "            adversary_loss.backward()\n",
    "            epoch_loss += adversary_loss.item()\n",
    "            epoch_batches += 1\n",
    "            optimizer.step()\n",
    "        epoch_loss/=epoch_batches\n",
    "        print(\"Average Adversary epoch loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286386b2-d6e9-447e-95b5-b3dd8f18010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the teacher model\n",
    "def train_teacher(model, adv, trainloader, criterion, adv_criterion, optimizer, optimizer_adv, \n",
    "                  scheduler, device, epochs, lambda_val, patience=patience_teacher):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    epoch_losses = [] \n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    best_total_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        adv.train()\n",
    "        model.to(device)\n",
    "        adv.to(device)\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "        \n",
    "            # Forward pass for teacher model\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            classification_loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Forward pass for adversary model\n",
    "            optimizer_adv.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs_detached = outputs.detach()\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((teacher_outputs_detached, one_hot_labels), dim=1)\n",
    "            adversary_output = adv(concatenated_output)\n",
    "            adversary_loss = adv_criterion(adversary_output, targets)\n",
    "        \n",
    "            # Calculate the total loss by combining classification and adversary loss\n",
    "            total_loss = classification_loss + lmda * adversary_loss\n",
    "            total_loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            optimizer_adv.step()\n",
    "        \n",
    "            running_loss += total_loss.item()\n",
    "            epoch_loss += total_loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches  \n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "                val_targets = val_data['target'].to(device)\n",
    "                \n",
    "                val_outputs = model(val_inputs)\n",
    "\n",
    "                # Compute validation loss\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "\n",
    "                # Compute recall differences for gender\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(predicted, val_labels, val_targets, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "\n",
    "            total_val_loss /= num_batches\n",
    "            val_losses.append(total_val_loss)\n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "            epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            non_zero_abs_values = np.abs(epoch_disparity[epoch_disparity != 0])\n",
    "            mean_non_zero_abs_disparity = np.mean(non_zero_abs_values)\n",
    "            val_disparities.append(mean_non_zero_abs_disparity)\n",
    "        \n",
    "        accuracy = total_correct / total_samples\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}| Validation Accuracy: {accuracy * 100:.2f}%')\n",
    "            \n",
    "        # Check for early stopping\n",
    "        if abs(total_val_loss) < abs(best_total_val_loss):\n",
    "            best_total_val_loss = total_val_loss\n",
    "            patience_counter = 0 \n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(val_labels.cpu(), predicted.cpu(), average='weighted')\n",
    "            best_epoch_metrics = {\n",
    "            'teacher_accuracy': accuracy,\n",
    "            'teacher_precision': precision,\n",
    "            'teacher_recall': recall,\n",
    "            'teacher_f1_score': f1,\n",
    "            'teacher_model_size': get_model_size(model),\n",
    "            'teacher_inference_time': get_inference_time(model, testloader)\n",
    "            }\n",
    "            best_epoch_mean_abs_disparity = mean_non_zero_abs_disparity\n",
    "            torch.save(model.state_dict(), f'teacher_model_weights_ckd_prof_checkpoint.pth')\n",
    "            torch.save(model, f'teacher_model_ckd_prof_checkpoint.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print('Early stopping')\n",
    "            break  \n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "    plot_loss_curve(val_losses)\n",
    "    print(\"Finished Training Teacher\")\n",
    "    return best_epoch_metrics, val_disparities\n",
    "\n",
    "# Function to train the student model with knowledge distillation\n",
    "def train_student_with_distillation_disparity(student, teacher, adv, trainloader, testloader, criterion, adv_criterion, optimizer, \n",
    "                                              device, alpha, temperature, epochs, lmda, patience=patience_student, optimizer_adv=None):\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    num_classes = len(class_labels)\n",
    "    best_val_accuracy = 0\n",
    "    best_total_val_loss = float('inf')\n",
    "    best_epoch_accuracy = 0.0\n",
    "    best_epoch_disparity = 0.0\n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train the adversary at the start of each epoch\n",
    "        train_adversary(adv, student, optimizer_adv, trainloader, adv_criterion, 1)\n",
    "\n",
    "        student.train()\n",
    "        student.to(device)\n",
    "        adv.eval()\n",
    "        adv.to(device)\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0 \n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "\n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student(inputs)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "\n",
    "            # detach student_outputs to avoid exploding gradients by passing same inputs (with gradience) into two different models. \n",
    "            studentached = student_outputs.detach()\n",
    "            # One-hot encode labels and concatenate with student's predictions\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((studentached, one_hot_labels), dim=1)\n",
    "\n",
    "            # Run the adversarial model on concatenated true labels, and predicted labels\n",
    "            with torch.no_grad():\n",
    "                adversary_output = adv(concatenated_output)\n",
    "\n",
    "            # Calc adversary loss, which is an MSE loss, because this is a regression output. \n",
    "            adversary_loss = adv_criterion(adversary_output, targets)\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "            \n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "\n",
    "            # Now combine the losses, subtract weighted adversary loss because we need to maximize that loss \n",
    "            # goal of the model is to have the adversary not predict gender. \n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss - lmda * adversary_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches\n",
    "        # print(f'*******Epoch {epoch}: running_recall_with - {running_recall_with/num_batches}  |  running_recall_without - {running_recall_without/num_batches}  |  disparity - {epoch_disparity/num_batches}******')\n",
    "        student_epoch_losses.append(epoch_loss)\n",
    "\n",
    "        student.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        # Validation after each epoch\n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "                val_targets = val_data['target'].to(device)\n",
    "                \n",
    "                # Forward pass for validation\n",
    "                val_student_outputs = student(val_inputs)\n",
    "                val_teacher_outputs = teacher(val_inputs)\n",
    "\n",
    "                val_studentached = val_student_outputs.detach()   \n",
    "                val_one_hot_labels = F.one_hot(val_labels, num_classes=num_classes).to(torch.float32)\n",
    "                val_concatenated_output = torch.cat((val_studentached, val_one_hot_labels), dim=1)\n",
    "                \n",
    "                val_adversary_output = adv(val_concatenated_output)\n",
    "                val_adversary_loss = adv_criterion(val_adversary_output, val_targets)\n",
    "                val_ce_loss = criterion(val_student_outputs, val_labels)\n",
    "                val_kd_loss = tkd_kdloss(val_student_outputs, val_teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "                \n",
    "                if val_kd_loss.ndim != 0:\n",
    "                    val_kd_loss = val_kd_loss.sum()\n",
    "                \n",
    "                val_loss = alpha * val_kd_loss + (1 - alpha) * val_ce_loss - lmda * val_adversary_loss\n",
    "                total_val_loss += val_loss.item()\n",
    "    \n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_student_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(predicted, val_labels, val_targets)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "    \n",
    "            total_val_loss /= num_batches\n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "\n",
    "            epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_losses.append(total_val_loss)\n",
    "            non_zero_abs_values = np.abs(epoch_disparity[epoch_disparity != 0])\n",
    "            mean_non_zero_abs_disparity = np.mean(non_zero_abs_values)\n",
    "            val_disparities.append(mean_non_zero_abs_disparity)\n",
    "            accuracy = total_correct / total_samples\n",
    "            val_accuracies.append(accuracy)\n",
    "            print(f'*****Epoch {epoch + 1}/{epochs}*****\\n' \n",
    "            f'*****Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}*****\\n'\n",
    "            f'*****Validation Accuracy: {accuracy * 100:.2f}%*****\\n'\n",
    "            f'*****Total Avg Disparity: {mean_non_zero_abs_disparity}*****\\n')\n",
    "            class_recall_mapping = {class_name: epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "            \n",
    "            # Print disparities by class label\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                print(f\"Class {class_label}: Recall Difference = {recall_diff}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if abs(total_val_loss) < abs(best_total_val_loss):\n",
    "            best_total_val_loss = total_val_loss\n",
    "            patience_counter = 0\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(val_labels.cpu(), predicted.cpu(), average='weighted')\n",
    "            best_epoch_metrics = {\n",
    "            'student_accuracy': accuracy,\n",
    "            'student_precision': precision,\n",
    "            'student_recall': recall,\n",
    "            'student_f1_score': f1,\n",
    "            'student_model_size': get_model_size(student),  # Define this function to calculate model size\n",
    "            'student_inference_time': get_inference_time(student, testloader)  # Define this function to calculate inference time\n",
    "        }\n",
    "            best_epoch_mean_abs_disparity = mean_non_zero_abs_disparity\n",
    "            torch.save(student.state_dict(), f'student_model_weights_ckd_wider_checkpoint_lambda{lmda}.pth')\n",
    "            torch.save(student, f'student_model_ckd_wider_checkpoint_lambda{lmda}.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "    \n",
    "        file_path = os.path.join(output_dir, f'validation_{lmda}.txt')\n",
    "        \n",
    "        # Append data to the text file\n",
    "        with open(file_path, 'a') as file:\n",
    "            file.write(f'********Epoch: {epochs}***********')\n",
    "            \n",
    "            file.write(\"Val Accuracies:\\n\")\n",
    "            for accuracy in val_accuracies:\n",
    "                file.write(f\"{accuracy}\\n\")\n",
    "        \n",
    "            file.write(\"\\nVal Disparities:\\n\")\n",
    "            for disparity in val_disparities:\n",
    "                file.write(f\"{disparity}\\n\")\n",
    "\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                file.write(f\"Class {class_label}: Recall Difference = {recall_diff}\\n\")\n",
    "        \n",
    "        \n",
    "        print(f\"Data has been appended to {file_path}\")\n",
    "    plot_loss_curve(val_losses)\n",
    "                \n",
    "    return best_epoch_metrics, best_epoch_mean_abs_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a06902-9ad4-47a6-9a67-181e2dc43218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=best_lr_teacher, momentum=momentum)\n",
    "# teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "    \n",
    "# train_teacher(teacher_model, trainloader, criterion_clf, teacher_optimizer, teacher_scheduler, device, epochs, patience=patience_teacher)\n",
    "\n",
    "# torch.save(teacher_model.state_dict(), 'teacher_model_weights_ckd_wider.pth')\n",
    "# torch.save(teacher_model, 'teacher_model_ckd_wider.pth')\n",
    "# print('teacher weights and architecture saved and exported')\n",
    "\n",
    "# Initialize the dictionary\n",
    "lambda_results = {}\n",
    "\n",
    "# Loop for training teacher with adversarial loss\n",
    "for i in lmda_list:\n",
    "    \n",
    "    # Reset the teacher model for each lambda\n",
    "    teacher_model = torchvision.models.resnet34(weights=None).to(device)\n",
    "    teacher_model.fc = nn.Linear(512, num_classes)\n",
    "    teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=best_lr_teacher, momentum=momentum)\n",
    "    teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "    \n",
    "    # Initialize the adversary for the teacher\n",
    "    adv = Adversary()\n",
    "    teacher_optimizer_adv = optim.Adam(adv.parameters(), lr=best_lr_teacher)\n",
    "\n",
    "    pretrain_teacher(teacher_model, trainloader, criterion_clf, teacher_optimizer, device, epochs_pretrain)\n",
    "    pretrain_adversary(adv, student_model, optimizer_adv, trainloader, adv_criterion, device, epochs_pretrain)\n",
    "    \n",
    "    # Train the teacher model with adversarial training\n",
    "    teacher_performance_metrics, teacher_mean_abs_val_disparity = train_teacher(teacher_model, adv, trainloader, criterion_clf, adv_criterion, teacher_optimizer, teacher_optimizer_adv, teacher_scheduler, device, epochs, i, patience=patience_teacher)\n",
    "\n",
    "    # Save the teacher model and its state\n",
    "    torch.save(teacher_model.state_dict(), f'teacher_model_weights_ckd_wider_lambda{i}.pth')\n",
    "    torch.save(teacher_model, f'teacher_model_ckd_wider_lambda{i}.pth')\n",
    "    print('Teacher weights and architecture saved and exported for lambda:', i)\n",
    "\n",
    "# Loop for training student with adversarial loss\n",
    "for i in lmda_list:\n",
    "    student_model = torchvision.models.resnet18(weights=None).to(device)\n",
    "    student_model.fc = nn.Linear(512, num_classes)\n",
    "    student_optimizer = optim.SGD(student_model.parameters(), lr=best_lr_student, momentum=momentum)\n",
    "    student_scheduler = torch.optim.lr_scheduler.StepLR(student_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    adv = Adversary()\n",
    "    student_optimizer_adv = optim.Adam(adv.parameters(), lr=best_lr_student)\n",
    "\n",
    "    pretrain_student(student_model, teacher_model, trainloader, criterion_clf, student_optimizer, device, alpha, temperature, epochs_pretrain)\n",
    "    pretrain_adversary(adv, teacher_model, optimizer_adv, trainloader, adv_criterion, device, epochs_pretrain)\n",
    "    \n",
    "    student_performance_metrics, student_mean_abs_val_disparity = train_student_with_distillation_disparity(student_model, teacher_model, adv, trainloader, testloader, criterion_clf, adv_criterion, student_optimizer, device, alpha, temperature, epochs, lmda=i, patience=patience_student, optimizer_adv=student_optimizer_adv)\n",
    "\n",
    "    torch.save(student_model.state_dict(), f'student_model_weights_ckd_wider_lambda{i}.pth')\n",
    "    torch.save(student_model, f'student_model_ckd_wider_lambda{i}.pth')\n",
    "    print('Student weights and architecture saved and exported for lambda:', i)\n",
    "\n",
    "    # Store the results in the dictionary\n",
    "    lambda_results[i] = {\n",
    "        'teacher_performance_metrics': teacher_performance_metrics,\n",
    "        'teacher_mean_abs_val_disparity': teacher_mean_abs_val_disparity,\n",
    "        'student_performance_metrics': student_performance_metrics,\n",
    "        'student_mean_abs_val_disparity': student_mean_abs_val_disparity\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c941e9-954c-4d7b-932e-06d3297c02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance_metrics(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_teacher_preds = []\n",
    "    all_student_preds = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "            \n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1).cpu().numpy()\n",
    "        student_preds = torch.argmax(student_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_teacher_preds.append(teacher_preds)\n",
    "        all_student_preds.append(student_preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_teacher_preds = np.concatenate(all_teacher_preds)\n",
    "    all_student_preds = np.concatenate(all_student_preds)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': (accuracy_score(all_labels, all_teacher_preds), accuracy_score(all_labels, all_student_preds)),\n",
    "        'precision': (precision_score(all_labels, all_teacher_preds, average='weighted', zero_division=0), precision_score(all_labels, all_student_preds, average='weighted', zero_division=0)),\n",
    "        'recall': (recall_score(all_labels, all_teacher_preds, average='weighted'), recall_score(all_labels, all_student_preds, average='weighted')),\n",
    "        'f1': (f1_score(all_labels, all_teacher_preds, average='weighted'), f1_score(all_labels, all_student_preds, average='weighted'))\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'all_labels': all_labels,\n",
    "        'all_teacher_preds': all_teacher_preds,\n",
    "        'all_student_preds': all_student_preds\n",
    "    }\n",
    "    \n",
    "def plot_comparison(labels, teacher_values, student_values, title, ylabel):\n",
    "    # Convert parameter count to millions\n",
    "    if 'Parameter Count' in title or 'Parameter Count' in ylabel:\n",
    "        teacher_values = [value / 1e6 for value in teacher_values]\n",
    "        student_values = [value / 1e6 for value in student_values]\n",
    "\n",
    "    x = np.arange(len(labels))  # the label locations\n",
    "    width = 0.35  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, teacher_values, width, label='Teacher')\n",
    "    rects2 = ax.bar(x + width/2, student_values, width, label='Student')\n",
    "\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553968c-56b4-418e-9393-9e149db5b396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bias (disparity) and accuracy values from lambda_results\n",
    "bias_values = [result['student_mean_abs_val_disparity'] for result in lambda_results.values()]\n",
    "accuracy_values = [result['student_performance_metrics']['student_accuracy'] for result in lambda_results.values()]\n",
    "\n",
    "\n",
    "# Weight for the trade-off\n",
    "bias_weight = 1  # Adjust this weight based on your preference\n",
    "\n",
    "# Calculate the weighted ratio\n",
    "weighted_ratios = np.array(accuracy_values) / (1 - bias_weight * np.array(bias_values))\n",
    "closest_to_one_index = np.argmin(np.abs(weighted_ratios - 1))\n",
    "optimal_bias = bias_values[closest_to_one_index]\n",
    "optimal_accuracy = accuracy_values[closest_to_one_index]\n",
    "optimal_ratio = weighted_ratios[closest_to_one_index]\n",
    "\n",
    "# Plotting the bias-variance trade-off curve\n",
    "plt.plot(bias_values, accuracy_values, marker='o', linestyle='-', color='b', label='Trade-off Points')\n",
    "\n",
    "# Mark all points with their lambda values\n",
    "for i, (bias, acc, lmbda) in enumerate(zip(bias_values, accuracy_values, lmda_list)):\n",
    "    plt.annotate(f'λ={lmbda}', (bias, acc), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "# Highlight the optimal point\n",
    "plt.scatter(optimal_bias, optimal_accuracy, color='r', s=100, marker='X', label=f'Optimal Point (λ={lmda_list[closest_to_one_index]})')\n",
    "plt.xlabel('Disparity')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy-Fairness Trade-off Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print optimal values\n",
    "print(f\"Optimal Lambda: {lmda_list[closest_to_one_index]}\")\n",
    "print(f\"Optimal Bias/Disparity: {optimal_bias}\")\n",
    "print(f\"Optimal Accuracy: {optimal_accuracy}\")\n",
    "print(f\"Optimal Weighted Ratio: {optimal_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf98a1-0a7e-4d82-9e72-3d7fda729944",
   "metadata": {},
   "outputs": [],
   "source": [
    "[result for result in lambda_results.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3995827c-1726-44e2-89aa-5f346a3d4987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the comparison and plotting functions after training\n",
    "teacher_params, student_params = compare_model_size(teacher_model, student_model)\n",
    "teacher_time, student_time = compare_inference_time(teacher_model, student_model, testloader)\n",
    "performance_metrics = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "\n",
    "# Extracting the metric values for plotting\n",
    "performance_labels = ['accuracy', 'precision', 'recall', 'f1']\n",
    "teacher_performance_values = [performance_metrics['metrics'][metric][0] for metric in performance_labels]\n",
    "student_performance_values = [performance_metrics['metrics'][metric][1] for metric in performance_labels]\n",
    "\n",
    "# Plotting the comparison for performance metrics\n",
    "plot_comparison(performance_labels, teacher_performance_values, student_performance_values, 'Performance Comparison', 'Score')\n",
    "\n",
    "# Plotting the comparison for model size\n",
    "model_size_labels = ['Model Size']\n",
    "teacher_model_size_values = [teacher_params]\n",
    "student_model_size_values = [student_params]\n",
    "plot_comparison(model_size_labels, teacher_model_size_values, student_model_size_values, 'Model Size Comparison', 'Parameter Count (millions)')\n",
    "\n",
    "# Plotting the comparison for inference time\n",
    "inference_time_labels = ['Inference Time']\n",
    "teacher_inference_time_values = [teacher_time]\n",
    "student_inference_time_values = [student_time]\n",
    "plot_comparison(inference_time_labels, teacher_inference_time_values, student_inference_time_values, 'Inference Time Comparison', 'Time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4234e-92ab-4c09-9595-8cafffd77018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot distribution of predictions for both models side by side\n",
    "def plot_combined_distribution(teacher_preds, student_preds, class_names):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Plot for Teacher\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(x=teacher_preds)\n",
    "    plt.title('Teacher Model Predictions')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    # Plot for Student\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.countplot(x=student_preds)\n",
    "    plt.title('Student Model Predictions')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot combined confusion matrix for both Teacher and Student\n",
    "def plot_combined_confusion_matrix(all_labels, teacher_preds, student_preds, class_names):\n",
    "    cm_teacher = confusion_matrix(all_labels, teacher_preds)\n",
    "    cm_student = confusion_matrix(all_labels, student_preds)\n",
    "    # Combine both confusion matrices into one plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Confusion matrix for Teacher\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(pd.DataFrame(cm_teacher, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title('Teacher Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    # Confusion matrix for Student\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(pd.DataFrame(cm_student, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title('Student Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "performance_metrics_teacher = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "all_labels = performance_metrics_teacher['all_labels']\n",
    "all_teacher_preds = performance_metrics_teacher['all_teacher_preds']\n",
    "all_student_preds = performance_metrics_teacher['all_student_preds']\n",
    "\n",
    "# Plot combined distribution side by side for Teacher and Student\n",
    "plot_combined_distribution(all_teacher_preds, all_student_preds, class_names_new)\n",
    "\n",
    "# Plot combined confusion matrix for Teacher and Student\n",
    "plot_combined_confusion_matrix(all_labels, all_teacher_preds, all_student_preds, class_names_new)\n",
    "\n",
    "# Classification report for the Teacher model\n",
    "teacher_report = classification_report(all_labels, all_teacher_preds, target_names=class_names_new, zero_division=0)\n",
    "print('Classification Report - Teacher Model')\n",
    "print(teacher_report)\n",
    "\n",
    "# Classification report for the Student model\n",
    "student_report = classification_report(all_labels, all_student_preds, target_names=class_names_new, zero_division=0)\n",
    "print('Classification Report - Student Model')\n",
    "print(student_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8775a81-993d-40df-b9ec-392a255c3443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866146ed-4c18-4a41-b8cb-09c77a3508ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c6a61-d07a-40ad-beb7-4bb14bdc63af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
