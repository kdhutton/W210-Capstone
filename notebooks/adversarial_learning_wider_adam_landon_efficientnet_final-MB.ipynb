{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f79206-feac-4302-abb1-d699b6354a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision.models import EfficientNet\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils.loss_functions import tkd_kdloss\n",
    "# from models_package.models import Teacher, Student\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef77e605-d288-486a-9598-1e99c9868014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loss_functions import DKDLoss\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm\n",
    "from models_package.models import Teacher, Student\n",
    "from torchvision import datasets, transforms, models\n",
    "import models_package\n",
    "import time\n",
    "from datetime import datetime\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import warnings\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pdb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict\n",
    "import os, shutil\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import os\n",
    "# new libraries\n",
    "from data.data_loader import load_cifar10, load_cifar100, load_imagenet, load_prof\n",
    "import boto3\n",
    "import io\n",
    "import models_package\n",
    "from utils.loss_functions import DKDLoss, DirectNormLoss, KDLoss\n",
    "from utils.compare_tools import compare_model_size, compare_inference_time, compare_performance_metrics, plot_comparison\n",
    "from utils.misc_tools import colorstr, Save_Checkpoint, AverageMeter, epoch_loop_reviewkd\n",
    "from utils.misc_tools import best_LR, best_LR_nd, best_LR_wider, train_teacher, train_teacher_wider, train_teacher_efficientnet, train_teacher_efficientnet_wider, retrieve_teacher_class_weights, new_teacher_class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2770eac-10b7-47de-ba06-9aa63cd7ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc3c0ec8-98dc-4933-b9a3-e96fce39c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001 # 0.096779\n",
    "epochs = 300\n",
    "epochs_pretrain = 3\n",
    "epochs_optimal_lr = 5\n",
    "patience_teacher = 20\n",
    "patience_student = 10\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "# set to true to use stratified sampling\n",
    "stratified_sampling_flag = False\n",
    "\n",
    "# list of lambda values to loop through for grid search\n",
    "# lmda_list_student = [10,5,3,0.5,0]\n",
    "# lmda_list_teacher = [10,5,3,0.5,0]\n",
    "lmda_list_student = [4,0]\n",
    "lmda_list_teacher = [4,0]\n",
    "\n",
    "# labels used including for plotting\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "num_classes = 16\n",
    "class_names_new = [f\"Class {label}\" for label in range(num_classes)]\n",
    "\n",
    "# Create directory and file path to save all outputs\n",
    "output_dir = f'./runs_{datetime.now().strftime(\"%Y_%m_%d_%H_%M\")}'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46265942-58a1-4c1a-a7ea-82d919a7e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your JSON file is named 'your_file.json'\n",
    "file_path = './WIDER/Annotations/wider_attribute_trainval.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    data = json.load(file)\n",
    "\n",
    "class_idx = data['scene_id_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "312fa312-b347-4434-862b-d25e32a79108",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_mapping = {\n",
    "    0: \"Team_Sports\",\n",
    "    1: \"Celebration\",\n",
    "    2: \"Parade\",\n",
    "    3: \"Waiter_Or_Waitress\",\n",
    "    4: \"Individual_Sports\",\n",
    "    5: \"Surgeons\",\n",
    "    6: \"Spa\",\n",
    "    7: \"Law_Enforcement\",\n",
    "    8: \"Business\",\n",
    "    9: \"Dresses\",\n",
    "    10: \"Water_Activities\",\n",
    "    11: \"Picnic\",\n",
    "    12: \"Rescue\",\n",
    "    13: \"Cheering\",\n",
    "    14: \"Performance_And_Entertainment\",\n",
    "    15: \"Family\"\n",
    "}\n",
    "\n",
    "# Ensure that all 16 new classes are covered\n",
    "# If some classes are not explicitly mentioned in new_label_mapping, add them\n",
    "for i in range(num_classes):\n",
    "    if i not in new_label_mapping:\n",
    "        new_label_mapping[i] = \"Additional Category {}\".format(i)\n",
    "\n",
    "class_idx = new_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c922f94-bf69-40d5-bc88-1e6fab4b4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedBatchSampler:\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits=n_batches, shuffle=shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1c84514-66c9-4543-8448-cafa751730ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "\n",
    "        # Create a mapping from old labels to new labels\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "\n",
    "        self.new_label_mapping = {\n",
    "            0: 2,  # Parade\n",
    "            1: 8,  # Business\n",
    "            2: 7,  # Law Enforcement\n",
    "            3: 14,  # Performance and Entertainment\n",
    "            4: 1,  # Celebration\n",
    "            5: 13,  # Cheering\n",
    "            6: 8,  # Business\n",
    "            7: 8,  # Business\n",
    "            8: 1,  # Celebration\n",
    "            9: 14,  # Performance and Entertainment\n",
    "            10: 15, # Family\n",
    "            11: 15, # Family\n",
    "            12: 11, # Picnic\n",
    "            13: 7, # Law Enforcement\n",
    "            14: 6, # Spa\n",
    "            15: 13, # Cheering\n",
    "            16: 5, # Surgeons\n",
    "            17: 3, # Waiter or Waitress\n",
    "            18: 4, # Individual Sports\n",
    "            19: 0, # Team Sports\n",
    "            20: 0, # Team Sports\n",
    "            21: 0, # Team Sports\n",
    "            22: 4, # Individual Sports\n",
    "            23: 10, # Water Activities\n",
    "            24: 4, # Individual Sports\n",
    "            25: 1, # Celebration\n",
    "            26: 9, # Dresses\n",
    "            27: 12, # Rescue\n",
    "            28: 10,# Water Activities\n",
    "            29: 0  # Team Sports\n",
    "        }\n",
    "\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        # Initialize transformations directly\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ] \n",
    "        )\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                ] \n",
    "            )        \n",
    "\n",
    "        self.anns = []\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs:\n",
    "            t.append(transforms.RandAugment())\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "\n",
    "        return transforms.Compose(t)\n",
    "    \n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            json_data = json.load(open(ann_file, \"r\"))\n",
    "            self.anns += json_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure the index is within bounds\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            img = Image.open(f'WIDER/Image/{ann[\"file_name\"]}').convert(\"RGB\")\n",
    "\n",
    "            # If this is the wider dataset, proceed with specific processing\n",
    "            # x, y, w, h = ann['bbox']\n",
    "            # img_area = img.crop([x, y, x+w, y+h])\n",
    "            img_area = self.augment(img)\n",
    "            img_area = self.transform(img_area)\n",
    "            attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "            num_people = len(attributes_list)\n",
    "            attributes_distribution = [max(sum(attribute), 0)/num_people for attribute in zip(*attributes_list)]\n",
    "            # Extract label from image path\n",
    "            img_path = f'WIDER/Image/{ann[\"file_name\"]}'\n",
    "            label = self.extract_label(img_path)  # You might need to implement this method\n",
    "            \n",
    "            return {\n",
    "                \"label\": label,\n",
    "                \"target\": torch.tensor([attributes_distribution[0]], dtype=torch.float32),\n",
    "                \"img\": img_area\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during the processing of an image, log the error and the index\n",
    "            print(f\"Error processing image at index {idx}: {e}\")\n",
    "            # Instead of returning None, raise the exception\n",
    "            raise\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            new_label_mapping = self.new_label_mapping[remapped_label]\n",
    "            return new_label_mapping\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2490c2-046a-4a19-9717-642adbabb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "012d6bd8-61d5-4a20-845b-689234718508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe2adb5-687d-4055-a108-a9c041836b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = DataSet(train_file, augs = ['RandAugment'], img_size = 226, dataset = 'wider')\n",
    "train_dataset = DataSet(train_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "test_dataset = DataSet(test_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "\n",
    "if stratified_sampling_flag:\n",
    "    trainloader = DataLoader(train_dataset, \n",
    "                             batch_sampler=StratifiedBatchSampler(torch.tensor([train_dataset[i]['label'] for i in range(len(train_dataset))]), \n",
    "                             batch_size=batch_size), num_workers=num_workers, collate_fn=custom_collate)\n",
    "    testloader = DataLoader(test_dataset, batch_sampler=StratifiedBatchSampler(torch.tensor([test_dataset[i]['label'] for i in range(len(test_dataset))]), \n",
    "                             batch_size=batch_size), num_workers=num_workers, collate_fn=custom_collate)\n",
    "else:\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=num_workers, collate_fn=custom_collate)\n",
    "    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff90b9a-9e51-4fb9-a343-da49cdc713da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10324"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f155c74-dfca-45a3-baa6-42a26437d47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_batch_class_counts(data_loader, label_mapping, num_batches=5):\n",
    "#     for i, batch in enumerate(data_loader):\n",
    "#         if i >= num_batches:\n",
    "#             break\n",
    "\n",
    "#         # Extract labels from the batch\n",
    "#         labels = batch['label']\n",
    "\n",
    "#         # Count occurrences of each class\n",
    "#         class_counts = torch.bincount(labels)\n",
    "\n",
    "#         # Map class counts to class names\n",
    "#         class_counts_with_names = {label_mapping.get(j, f\"Unknown Class {j}\"): class_counts[j].item() for j in range(len(class_counts))}\n",
    "\n",
    "#         # Print class counts and total observations\n",
    "#         print(f\"Batch {i + 1}:\")\n",
    "#         for class_name, count in class_counts_with_names.items():\n",
    "#             print(f\"    {class_name}: {count}\")\n",
    "#         print(f\"Total Observations: {len(labels)}\\n\")\n",
    "\n",
    "# print_batch_class_counts(trainloader, new_label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d18d4b-a3c0-4c5b-ad75-e74b6b1b7296",
   "metadata": {},
   "source": [
    "# Start Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c37c867-c1d1-438c-ac22-755904ce121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def calculate_recall_multiclass(conf_matrix):\n",
    "    recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    recalls[np.isnan(recalls)] = 0  # Replace NaN with 0\n",
    "    return recalls\n",
    "\n",
    "def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes):\n",
    "    predictions = pred.cpu()\n",
    "    true_labels = label.cpu()\n",
    "    gender = gender.cpu()\n",
    "\n",
    "    # Identify male and female indices based on the gender threshold\n",
    "    male_indices = np.where(gender >= 0.5)[0]\n",
    "    female_indices = np.where(gender < 0.5)[0]\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot_labels = one_hot_encode(true_labels, num_classes=num_classes)\n",
    "    one_hot_preds = one_hot_encode(predictions, num_classes=num_classes)\n",
    "    # Initialize recall arrays\n",
    "    male_recall = np.zeros(num_classes)\n",
    "    female_recall = np.zeros(num_classes)\n",
    "\n",
    "    # Extract predictions and labels for male and female indices\n",
    "    male_predictions = np.argmax(one_hot_preds[male_indices], axis=1)\n",
    "    female_predictions = np.argmax(one_hot_preds[female_indices], axis=1)\n",
    "    male_labels = np.argmax(one_hot_labels[male_indices], axis=1)\n",
    "    female_labels = np.argmax(one_hot_labels[female_indices], axis=1)\n",
    "\n",
    "    # Check if the class labels are within the expected range\n",
    "    assert (0 <= male_predictions.min() < num_classes) and (0 <= male_predictions.max() < num_classes), \"Invalid class indices in male predictions\"\n",
    "    assert (0 <= female_predictions.min() < num_classes) and (0 <= female_predictions.max() < num_classes), \"Invalid class indices in female predictions\"\n",
    "    assert (0 <= male_labels.min() < num_classes) and (0 <= male_labels.max() < num_classes), \"Invalid class indices in male labels\"\n",
    "    assert (0 <= female_labels.min() < num_classes) and (0 <= female_labels.max() < num_classes), \"Invalid class indices in female labels\"\n",
    "\n",
    "    # Calculate confusion matrices for each gender\n",
    "    male_conf_matrix = confusion_matrix(male_labels, male_predictions, labels=np.arange(num_classes))\n",
    "    female_conf_matrix = confusion_matrix(female_labels, female_predictions, labels=np.arange(num_classes))\n",
    "\n",
    "    # Calculate recall for each class and gender\n",
    "    male_recall[:len(male_conf_matrix)] = calculate_recall_multiclass(male_conf_matrix)\n",
    "    female_recall[:len(female_conf_matrix)] = calculate_recall_multiclass(female_conf_matrix)\n",
    "\n",
    "    return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21dd5209-bc09-46fa-a635-4e281ab92190",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### HELPER FUNCTION FOR FEATURE EXTRACTION\n",
    "\n",
    "def get_features(name):\n",
    "    def hook(model, input, output):\n",
    "        features[name] = output.detach()\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c6b93cb-37c9-448f-a8d9-424d3c4d40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "###################### Testing 1 ######################\n",
    "# Create instances of your models\n",
    "teacher_model = torchvision.models.efficientnet_b3(weights='DEFAULT')\n",
    "teacher_model.classifier = nn.Linear(1536, num_classes)\n",
    "student_model = torchvision.models.efficientnet_b0(weights='DEFAULT')\n",
    "student_model.classifier = nn.Linear(1280, num_classes)\n",
    "\n",
    "# Load teacher\n",
    "# teacher_model = torch.load('teacher_model_ckd_wider.pth')\n",
    "# teacher_model.load_state_dict(torch.load('teacher_model_weights_ckd_wider.pth'))\n",
    "# torch.save(teacher_model.state_dict(), 'teacher_model_weights_ckd_wider.pth')\n",
    "# # Load the studnet\n",
    "# student_model = torch.load('student_model_ckd_prof.pth')\n",
    "# student_model.load_state_dict(torch.load('student_model_weights_ckd_prof_checkpoint.pth'))\n",
    "# student_model = student_model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcd643-ac9d-4e22-821a-4c784c86e4a5",
   "metadata": {},
   "source": [
    "This is the initialization of the 2-layer Adversary Perceptron. It is initialized with the number of classes*2, which represents the predicted labels (y_hat) and the true labels (y). The output of the final layer is a regression output, which is intended to predict the strength of gender (continuous number where anything past 0.5 is more male).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "836f2993-0505-47c6-85ee-2ad2f45db946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(nn.Module):\n",
    "    def __init__(self, input_size=num_classes):\n",
    "        super(Adversary, self).__init__()\n",
    "\n",
    "        self.a1 = nn.Linear(input_size*2, 16)\n",
    "        self.a2 = nn.Linear(16, 1)  # Output size 1 for regression\n",
    "        nn.init.xavier_normal_(self.a1.weight)\n",
    "        nn.init.kaiming_normal_(self.a2.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        adversary = F.relu(self.a1(input_ids))\n",
    "        adversary_output = F.sigmoid(self.a2(adversary))  # Linear activation for regression\n",
    "        return adversary_output\n",
    "\n",
    "# Instantiate the Adversary\n",
    "adv = Adversary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a761874d-cc14-482e-9c8c-6342adea3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_student(student, teacher, trainloader, criterion, optimizer, device, alpha, temperature, epochs_pretrain, patience=patience_student):\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs_pretrain):\n",
    "        student.train()\n",
    "        student.to(device)\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "            \n",
    "            # If not scalar, sum up to make sure the loss is scalar\n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "                \n",
    "            # Now combine the losses\n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        print(f'*******Epoch {epoch}: loss - {epoch_loss}')\n",
    "        student_epoch_losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16f4630d-f0d5-4d83-b61f-8707df8800a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_teacher(teacher, trainloader, criterion, optimizer, device, epochs_pretrain, patience=patience_student):\n",
    "    teacher.to(device)\n",
    "    teacher.train()  # Set the model to training mode\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    teacher_epoch_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs_pretrain):\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            teacher_outputs = teacher(inputs)\n",
    "\n",
    "            ce_loss = criterion(teacher_outputs, labels)\n",
    "                \n",
    "            loss = ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        print(f'*******Epoch {epoch}: loss - {epoch_loss}')\n",
    "        teacher_epoch_losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "005d66e3-f169-4d59-bc29-b5c0e05816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adversary(adv, student, adversary_optimizer, trainloader, adv_criterion, device, epochs_pretrain):\n",
    "\n",
    "  for epoch in range(epochs_pretrain):\n",
    "    epoch_loss = 0\n",
    "    epoch_batches = 0\n",
    "    for i, data in enumerate(tqdm(trainloader)): # starting from the 0th batch\n",
    "        # get the inputs and labels\n",
    "        adv.train()\n",
    "        adv.to(device)\n",
    "        inputs = data['img'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        targets = data['target'].to(device)\n",
    "        student = student.to(device)\n",
    "        adversary_optimizer.zero_grad()\n",
    "        student_output = student(inputs)\n",
    "        one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "        concatenated_output = torch.cat((student_output, one_hot_labels), dim=1)\n",
    "        adversary_output = adv(concatenated_output)\n",
    "        adversary_loss = adv_criterion(adversary_output, targets) # compute loss\n",
    "        adversary_loss.backward() # back prop\n",
    "        adversary_optimizer.step()\n",
    "        epoch_loss += adversary_loss.item()\n",
    "        epoch_batches += 1\n",
    "\n",
    "    print(\"Average Pretrain Adversary epoch loss: \", epoch_loss/epoch_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b4731c-f105-4192-9650-6587c46f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler for the student model\n",
    "student_optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Optimizer and scheduler for the teacher model\n",
    "teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "optimizer_adv = optim.Adam(adv.parameters(), lr=learning_rate)\n",
    "\n",
    "# Instantiate the model and the loss function\n",
    "criterion_clf = nn.CrossEntropyLoss()\n",
    "adv_criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2037b64-dba1-4c4b-a586-0a0ac3373d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_student = 0.09999999999999999\n",
    "best_lr_teacher = 9.999999999999999e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "411c4f7a-d0b4-478f-9fa5-5e152e08ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(losses):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    plt.plot(epochs, losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Val Loss Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4c98aee-9c82-46f8-910b-4ca2ae4b9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the adversary training function, where we input the student outputs, \n",
    "# with the true labels into the adversary model created previously.\n",
    "def train_adversary(adv, model, optimizer, trainloader, criterion, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_batches = 0\n",
    "        for i, data in enumerate(tqdm(trainloader)):\n",
    "            # get the inputs and labels\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            adv.train()\n",
    "            adv.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # output the student model, join with ohe labels. \n",
    "            model_output = model(inputs)\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((model_output, one_hot_labels), dim=1)\n",
    "            adversary_output = adv(concatenated_output)\n",
    "\n",
    "            adversary_loss = criterion(adversary_output, targets)\n",
    "            adversary_loss.backward()\n",
    "            epoch_loss += adversary_loss.item()\n",
    "            epoch_batches += 1\n",
    "            optimizer.step()\n",
    "        epoch_loss/=epoch_batches\n",
    "        print(\"Average Adversary epoch loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "286386b2-d6e9-447e-95b5-b3dd8f18010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the teacher model\n",
    "def train_teacher(model_name, dataset, model, adv, trainloader, criterion, adv_criterion, optimizer, optimizer_adv, device, \n",
    "                  epochs, lmda, patience=patience_teacher):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    epoch_losses = [] \n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    val_accuracies = []\n",
    "    best_total_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        adv.train()\n",
    "        model.to(device)\n",
    "        adv.to(device)\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "        \n",
    "            # Forward pass for teacher model\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            classification_loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Forward pass for adversary model\n",
    "            optimizer_adv.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs_detached = outputs.detach()\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((teacher_outputs_detached, one_hot_labels), dim=1)\n",
    "            adversary_output = adv(concatenated_output)\n",
    "            adversary_loss = adv_criterion(adversary_output, targets)\n",
    "        \n",
    "            # Calculate the total loss by combining classification and adversary loss\n",
    "            if lmda != 0:\n",
    "                total_loss = classification_loss + classification_loss/adversary_loss - lmda * adversary_loss\n",
    "            else:\n",
    "                total_loss = classification_loss\n",
    "                \n",
    "            total_loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            optimizer_adv.step()\n",
    "        \n",
    "            running_loss += total_loss.item()\n",
    "            epoch_loss += total_loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches  \n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "                val_targets = val_data['target'].to(device)\n",
    "                \n",
    "                val_outputs = model(val_inputs)\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs_detached_val = val_outputs.detach()                \n",
    "                one_hot_labels_val = F.one_hot(val_labels, num_classes=num_classes).to(torch.float32)\n",
    "                concatenated_output_val = torch.cat((teacher_outputs_detached_val, one_hot_labels_val), dim=1)\n",
    "                adversary_output_val = adv(concatenated_output_val)\n",
    "                adversary_loss_val = adv_criterion(adversary_output_val, val_targets)\n",
    "                \n",
    "                # Compute validation loss\n",
    "                val_ce_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "                if lmda !=0:\n",
    "                    val_loss = val_ce_loss + val_ce_loss/adversary_loss_val - lmda * adversary_loss_val\n",
    "                else:\n",
    "                    val_loss = val_ce_loss\n",
    "                    \n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "\n",
    "                # Compute recall differences for gender\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(predicted, val_labels, val_targets, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "\n",
    "            total_val_loss /= num_batches\n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "            \n",
    "            epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_losses.append(total_val_loss)\n",
    "            non_zero_abs_values = np.abs(epoch_disparity[epoch_disparity != 0])\n",
    "            mean_non_zero_abs_disparity = np.mean(non_zero_abs_values)\n",
    "            val_disparities.append(mean_non_zero_abs_disparity)\n",
    "            accuracy = total_correct / total_samples\n",
    "            val_accuracies.append(accuracy)\n",
    "            print(f'*****Epoch {epoch + 1}/{epochs}*****\\n' \n",
    "            f'*****Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}*****\\n'\n",
    "            f'*****Validation Accuracy: {accuracy * 100:.2f}%*****\\n'\n",
    "            f'*****Total Avg Disparity: {mean_non_zero_abs_disparity}*****\\n')\n",
    "            class_recall_mapping = {class_name: epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "            \n",
    "            # Print disparities by class label\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                print(f\"Class {class_label}: Recall Difference = {recall_diff}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if abs(total_val_loss) < abs(best_total_val_loss):\n",
    "            best_total_val_loss = total_val_loss\n",
    "            patience_counter = 0 \n",
    "\n",
    "            # checkpoint\n",
    "            save_path = './weights/'\n",
    "\n",
    "            # save locally\n",
    "            model_save_path = os.path.join(save_path, model_name)\n",
    "            \n",
    "            os.makedirs(model_save_path, exist_ok=True)\n",
    "        \n",
    "            model_save_name = os.path.join(model_save_path, f'checkpoint_lmda_{lmda}.pth')\n",
    "            mode_weights_name = os.path.join(model_save_path, f'weights_lmda_{lmda}.pth')\n",
    "            \n",
    "            best_epoch_mean_abs_disparity = mean_non_zero_abs_disparity\n",
    "\n",
    "            torch.save(model.state_dict(), mode_weights_name)\n",
    "            torch.save(model, model_save_name)\n",
    "\n",
    "            # push to s3\n",
    "            session = boto3.session.Session()\n",
    "            s3 = session.client('s3')\n",
    "            \n",
    "            bucket_name = '210bucket' \n",
    "            \n",
    "            # Teacher Model\n",
    "            #### IMPORTANT!!!!! Change the file name so that you do not overwrite the existing files\n",
    "            teacher_model_weights_path = f'weights/teacher_model_weights_{model_name}_{dataset}_{lmda}.pth'\n",
    "            teacher_model_path = f'models/testing_teacher_model_{model_name}_{dataset}_{lmda}.pth'\n",
    "            \n",
    "            # Save state dict to buffer\n",
    "            teacher_model_weights_buffer = io.BytesIO()\n",
    "            torch.save(teacher_model.state_dict(), teacher_model_weights_buffer)\n",
    "            teacher_model_weights_buffer.seek(0)\n",
    "            \n",
    "            # Save entire model to buffer\n",
    "            teacher_model_buffer = io.BytesIO()\n",
    "            torch.save(teacher_model, teacher_model_buffer)\n",
    "            teacher_model_buffer.seek(0)\n",
    "            \n",
    "            # Upload to S3\n",
    "            s3.put_object(Bucket=bucket_name, Key=teacher_model_weights_path, Body=teacher_model_weights_buffer)\n",
    "            s3.put_object(Bucket=bucket_name, Key=teacher_model_path, Body=teacher_model_buffer)\n",
    "            print('teacher weights and architecture saved and exported to S3')\n",
    "\n",
    "\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print('Early stopping')\n",
    "            break  \n",
    "\n",
    "        file_path = os.path.join(output_dir, f'teacher_validation_{lmda}.txt')\n",
    "        \n",
    "        # Append data to the text file\n",
    "        with open(file_path, 'a') as file:\n",
    "            file.write(f'********Epoch: {epochs}***********')\n",
    "            \n",
    "            file.write(\"Teacher Val Accuracies:\\n\")\n",
    "            for accuracy in val_accuracies:\n",
    "                file.write(f\"{accuracy}\\n\")\n",
    "        \n",
    "            file.write(\"\\nTeacher Val Disparities:\\n\")\n",
    "            for disparity in val_disparities:\n",
    "                file.write(f\"{disparity}\\n\")\n",
    "\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                file.write(f\"Class {class_label}: Recall Difference = {recall_diff}\\n\")\n",
    "        \n",
    "        print(f\"Data has been appended to {file_path}\")\n",
    "    \n",
    "    plot_loss_curve(val_losses)\n",
    "    print(\"Finished Training Teacher\")\n",
    "    return val_disparities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5da9d5-04d8-438d-949e-17ddb79a09c1",
   "metadata": {},
   "source": [
    "## Extract Teacher Class Mean Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e314f5-ac79-4962-8be7-0c97405a8301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_fea(model, dataloader, batch_size):\n",
    "    ''' Used to extract the feature embeddings in a teacher model '''\n",
    "    \n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    model.avgpool.register_forward_hook(get_features('feats'))\n",
    "\n",
    "    EMB = {}\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            FEATS = []\n",
    "            features = {}\n",
    "            \n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            curr_batch_size = len(inputs)\n",
    "\n",
    "            # compute output\n",
    "            # emb_fea, logits = model(images, embed=True)\n",
    "            outputs = model(inputs)\n",
    "            # feats = features['feats'].cpu().numpy()\n",
    "            # emb_fea = feats.flatten()\n",
    "            FEATS.append(features['feats'].cpu().numpy())\n",
    "            emb_fea = np.concatenate(FEATS)\n",
    "            # reshape embedding features to flatten \n",
    "            emb_fea = emb_fea.reshape((curr_batch_size, emb_fea.shape[1]))\n",
    "\n",
    "\n",
    "            for emb, i in zip(emb_fea, labels):\n",
    "                i = i.item()\n",
    "                emb_size = len(emb) \n",
    "                if str(i) in EMB:\n",
    "                    for j in range(emb_size):\n",
    "                        EMB[str(i)][j].append(round(emb[j].item(), 4))\n",
    "                else:\n",
    "                    EMB[str(i)] = [[] for _ in range(emb_size)]\n",
    "                    for j in range(emb_size):\n",
    "                        EMB[str(i)][j].append(round(emb[j].item(), 4))\n",
    "\n",
    "    for key, value in EMB.items():\n",
    "        for i in range(emb_size):\n",
    "            EMB[key][i] = round(np.array(EMB[key][i]).mean(), 4)\n",
    "\n",
    "    return EMB\n",
    "\n",
    "\n",
    "def retrieve_teacher_class_weights(model_name, model, model_weight_path, num_class, data_name, dataloader, batch_size, bucket_name, lmda):\n",
    "    ''' Use the extracted feature embeddings to create a json of class means for teacher'''\n",
    "\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client('s3')\n",
    "\n",
    "    teacher_model_weights_buffer = io.BytesIO()\n",
    "    s3.download_fileobj(bucket_name, model_weight_path, teacher_model_weights_buffer)\n",
    "    teacher_model_weights_buffer.seek(0)  \n",
    "\n",
    "    # Load the model\n",
    "    # model = models_package.__dict__[model_name](num_class=num_class)\n",
    "    checkpoint = torch.load(teacher_model_weights_buffer)\n",
    "    # print(\"Keys in checkpoint:\", checkpoint.keys())\n",
    "    print(\"model is loaded properly\")\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in checkpoint.items():\n",
    "        name = k[7:] if k.startswith('module.') else k\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "    # emb = get_emb_fea(model=model, dataloader=dataloader, batch_size=batch_size)\n",
    "    # emb_json = json.dumps(emb, indent=4)\n",
    "    # with open(\"./class_means/{}_embedding_fea/{}.json\".format(data_name, model_name), 'w', encoding='utf-8') as f:\n",
    "    #     f.write(emb_json)\n",
    "\n",
    "    emb = get_emb_fea(model=model, dataloader=dataloader, batch_size=batch_size)\n",
    "    emb_json = json.dumps(emb, indent=4)\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    output_dir = \"./class_means/{}_embedding_fea\".format(data_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(\"{}/{}_lmda{}.json\".format(output_dir, model_name, lmda), 'w', encoding='utf-8') as f:\n",
    "        f.write(emb_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a852fc09-026e-47e5-8750-01fd6ff1ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SET VARIABLES ####\n",
    "data_name = 'WIDER'\n",
    "model_name = 'efficientnetb3'\n",
    "save_dir = './run/WIDER/disparity/KD++'\n",
    "bucket_name = '210bucket' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17a06902-9ad4-47a6-9a67-181e2dc43218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 1/300*****\n",
      "*****Train Loss:  2.704193 Val Loss:  1.226652*****\n",
      "*****Validation Accuracy: 52.84%*****\n",
      "*****Total Avg Disparity: 0.1994175531311332*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.07063783116838596\n",
      "Class Celebration: Recall Difference = -0.06638736706413151\n",
      "Class Parade: Recall Difference = 0.02850105559465177\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.14410163339382936\n",
      "Class Individual_Sports: Recall Difference = -0.11274987810823989\n",
      "Class Surgeons: Recall Difference = 0.05128205128205129\n",
      "Class Spa: Recall Difference = 0.8775510204081632\n",
      "Class Law_Enforcement: Recall Difference = 0.28162593389894897\n",
      "Class Business: Recall Difference = -0.05775788576300084\n",
      "Class Dresses: Recall Difference = -0.6144781144781145\n",
      "Class Water_Activities: Recall Difference = 0.14613299979153627\n",
      "Class Picnic: Recall Difference = -0.19642857142857145\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = -0.054266734798160424\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.20043572984749447\n",
      "Class Family: Recall Difference = -0.08892648994171834\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 2/300*****\n",
      "*****Train Loss: -0.693440 Val Loss: -0.489576*****\n",
      "*****Validation Accuracy: 61.88%*****\n",
      "*****Total Avg Disparity: 0.17742693102378432*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.11682718122722224\n",
      "Class Celebration: Recall Difference = -0.08153399935546252\n",
      "Class Parade: Recall Difference = 0.05465634529673946\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.033756805807622414\n",
      "Class Individual_Sports: Recall Difference = -0.1810092637737689\n",
      "Class Surgeons: Recall Difference = 0.05860805860805868\n",
      "Class Spa: Recall Difference = 0.4693877551020408\n",
      "Class Law_Enforcement: Recall Difference = 0.20868684310497654\n",
      "Class Business: Recall Difference = 0.004475703324808067\n",
      "Class Dresses: Recall Difference = -0.6206509539842875\n",
      "Class Water_Activities: Recall Difference = 0.16322701688555352\n",
      "Class Picnic: Recall Difference = -0.5357142857142857\n",
      "Class Rescue: Recall Difference = -0.03317901234567905\n",
      "Class Cheering: Recall Difference = 0.009504343382728653\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.08976034858387799\n",
      "Class Family: Recall Difference = -0.17785297988343685\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 3/300*****\n",
      "*****Train Loss: -2.169476 Val Loss: -1.274889*****\n",
      "*****Validation Accuracy: 64.68%*****\n",
      "*****Total Avg Disparity: 0.17696709227947782*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.11982040648455972\n",
      "Class Celebration: Recall Difference = -0.058545493608336\n",
      "Class Parade: Recall Difference = 0.02334037063101102\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.04428312159709624\n",
      "Class Individual_Sports: Recall Difference = -0.15053632374451487\n",
      "Class Surgeons: Recall Difference = -0.00439560439560438\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.2921362542737749\n",
      "Class Business: Recall Difference = -0.020460358056266004\n",
      "Class Dresses: Recall Difference = -0.6453423120089787\n",
      "Class Water_Activities: Recall Difference = 0.16812591202835114\n",
      "Class Picnic: Recall Difference = -0.6428571428571428\n",
      "Class Rescue: Recall Difference = 0.07793209876543217\n",
      "Class Cheering: Recall Difference = 0.002963719979560575\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.08671023965141605\n",
      "Class Family: Recall Difference = -0.20830983267531483\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 4/300*****\n",
      "*****Train Loss: -3.115644 Val Loss: -1.398070*****\n",
      "*****Validation Accuracy: 65.28%*****\n",
      "*****Total Avg Disparity: 0.16542587301407222*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09951902754452702\n",
      "Class Celebration: Recall Difference = -0.05816951337415416\n",
      "Class Parade: Recall Difference = 0.06040347173352101\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.015607985480943887\n",
      "Class Individual_Sports: Recall Difference = -0.14196326994961805\n",
      "Class Surgeons: Recall Difference = -0.11575091575091578\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.17892870710396358\n",
      "Class Business: Recall Difference = -0.052003410059676014\n",
      "Class Dresses: Recall Difference = -0.548260381593715\n",
      "Class Water_Activities: Recall Difference = 0.1424848863873256\n",
      "Class Picnic: Recall Difference = -0.6071428571428571\n",
      "Class Rescue: Recall Difference = 0.0524691358024692\n",
      "Class Cheering: Recall Difference = 0.008584568216658095\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.07450980392156858\n",
      "Class Family: Recall Difference = -0.20530174844895654\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 5/300*****\n",
      "*****Train Loss: -3.729601 Val Loss: -1.322326*****\n",
      "*****Validation Accuracy: 65.31%*****\n",
      "*****Total Avg Disparity: 0.17349585002437196*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.11069221190206902\n",
      "Class Celebration: Recall Difference = -0.04452680201955106\n",
      "Class Parade: Recall Difference = -0.021932911095472796\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.030852994555354063\n",
      "Class Individual_Sports: Recall Difference = -0.15220217779944745\n",
      "Class Surgeons: Recall Difference = -0.06446886446886457\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.2153982525009498\n",
      "Class Business: Recall Difference = -0.022591645353793766\n",
      "Class Dresses: Recall Difference = -0.6268237934904601\n",
      "Class Water_Activities: Recall Difference = 0.13393787784031674\n",
      "Class Picnic: Recall Difference = -0.6428571428571428\n",
      "Class Rescue: Recall Difference = -0.0015432098765432167\n",
      "Class Cheering: Recall Difference = -0.052120592743996\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.0980392156862745\n",
      "Class Family: Recall Difference = -0.2722316224854296\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 6/300*****\n",
      "*****Train Loss: -4.229210 Val Loss: -1.213882*****\n",
      "*****Validation Accuracy: 65.80%*****\n",
      "*****Total Avg Disparity: 0.17448858728576438*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.0981709337263369\n",
      "Class Celebration: Recall Difference = -0.04237834353851122\n",
      "Class Parade: Recall Difference = -0.0059817030260379545\n",
      "Class Waiter_Or_Waitress: Recall Difference = 0.00834845735027212\n",
      "Class Individual_Sports: Recall Difference = -0.15220217779944734\n",
      "Class Surgeons: Recall Difference = -0.14432234432234436\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.2099531467645942\n",
      "Class Business: Recall Difference = -0.05093776641091219\n",
      "Class Dresses: Recall Difference = -0.542087542087542\n",
      "Class Water_Activities: Recall Difference = 0.1632270168855534\n",
      "Class Picnic: Recall Difference = -0.5714285714285713\n",
      "Class Rescue: Recall Difference = -0.04706790123456778\n",
      "Class Cheering: Recall Difference = -0.13306080735820136\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.050980392156862786\n",
      "Class Family: Recall Difference = -0.28595600676818944\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 7/300*****\n",
      "*****Train Loss: -4.566689 Val Loss: -1.066718*****\n",
      "*****Validation Accuracy: 65.89%*****\n",
      "*****Total Avg Disparity: 0.16196482117960898*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08644937222241267\n",
      "Class Celebration: Recall Difference = -0.06789128800085942\n",
      "Class Parade: Recall Difference = 0.001055594651653724\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.02323049001814903\n",
      "Class Individual_Sports: Recall Difference = -0.14029741589468547\n",
      "Class Surgeons: Recall Difference = -0.08424908424908423\n",
      "Class Spa: Recall Difference = 0.2448979591836734\n",
      "Class Law_Enforcement: Recall Difference = 0.2099531467645942\n",
      "Class Business: Recall Difference = -0.0390025575447569\n",
      "Class Dresses: Recall Difference = -0.505050505050505\n",
      "Class Water_Activities: Recall Difference = 0.151031894934334\n",
      "Class Picnic: Recall Difference = -0.6428571428571428\n",
      "Class Rescue: Recall Difference = -0.013888888888888895\n",
      "Class Cheering: Recall Difference = -0.11364333163004597\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.013943355119825696\n",
      "Class Family: Recall Difference = -0.2539951118631321\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 8/300*****\n",
      "*****Train Loss: -4.732870 Val Loss: -0.776570*****\n",
      "*****Validation Accuracy: 65.37%*****\n",
      "*****Total Avg Disparity: 0.17260901313366578*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09093921010841866\n",
      "Class Celebration: Recall Difference = -0.04919969921581263\n",
      "Class Parade: Recall Difference = 0.03553835327234334\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.05480943738656996\n",
      "Class Individual_Sports: Recall Difference = -0.10633024540874358\n",
      "Class Surgeons: Recall Difference = -0.1186813186813187\n",
      "Class Spa: Recall Difference = 0.2448979591836734\n",
      "Class Law_Enforcement: Recall Difference = 0.1885526149170571\n",
      "Class Business: Recall Difference = -0.020460358056266004\n",
      "Class Dresses: Recall Difference = -0.542087542087542\n",
      "Class Water_Activities: Recall Difference = 0.11444652908067565\n",
      "Class Picnic: Recall Difference = -0.6428571428571429\n",
      "Class Rescue: Recall Difference = -0.14197530864197533\n",
      "Class Cheering: Recall Difference = -0.10873786407766994\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.02135076252723317\n",
      "Class Family: Recall Difference = -0.2808798646362099\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_10.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 9/300*****\n",
      "*****Train Loss: -4.881103 Val Loss: -0.713829*****\n",
      "*****Validation Accuracy: 65.45%*****\n",
      "*****Total Avg Disparity: 0.17425131289082202*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.10510561972329824\n",
      "Class Celebration: Recall Difference = -0.016489418841980852\n",
      "Class Parade: Recall Difference = 0.05207600281491909\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.0021778584392015965\n",
      "Class Individual_Sports: Recall Difference = -0.1368844466114092\n",
      "Class Surgeons: Recall Difference = -0.06739926739926738\n",
      "Class Spa: Recall Difference = 0.22448979591836737\n",
      "Class Law_Enforcement: Recall Difference = 0.17221729770799044\n",
      "Class Business: Recall Difference = -0.1042199488491049\n",
      "Class Dresses: Recall Difference = -0.5173961840628507\n",
      "Class Water_Activities: Recall Difference = 0.2010631644777987\n",
      "Class Picnic: Recall Difference = -0.6607142857142856\n",
      "Class Rescue: Recall Difference = -0.0015432098765432167\n",
      "Class Cheering: Recall Difference = -0.1840572304547778\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.10849673202614385\n",
      "Class Family: Recall Difference = -0.23369054333521344\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Teacher\n",
      "model is loaded properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:08<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher weights and architecture saved and exported for lambda: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 1/300*****\n",
      "*****Train Loss:  8.116145 Val Loss:  5.951139*****\n",
      "*****Validation Accuracy: 53.85%*****\n",
      "*****Total Avg Disparity: 0.13715943953840548*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08670071174783789\n",
      "Class Celebration: Recall Difference = -0.05172413793103453\n",
      "Class Parade: Recall Difference = -0.024395965282664855\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.21778584392014516\n",
      "Class Individual_Sports: Recall Difference = -0.1247359011864132\n",
      "Class Surgeons: Recall Difference = 0.025641025641025644\n",
      "Class Spa: Recall Difference = -0.08163265306122448\n",
      "Class Law_Enforcement: Recall Difference = 0.23553248068886934\n",
      "Class Business: Recall Difference = -0.0598891730605286\n",
      "Class Dresses: Recall Difference = -0.6453423120089788\n",
      "Class Water_Activities: Recall Difference = 0.1729205753595997\n",
      "Class Picnic: Recall Difference = -0.10714285714285715\n",
      "Class Rescue: Recall Difference = -0.016975308641975308\n",
      "Class Cheering: Recall Difference = -0.0016351558507920298\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.21089324618736383\n",
      "Class Family: Recall Difference = -0.1316036849031773\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 2/300*****\n",
      "*****Train Loss:  2.833772 Val Loss:  2.202385*****\n",
      "*****Validation Accuracy: 61.62%*****\n",
      "*****Total Avg Disparity: 0.19455835207840808*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.10306062994824683\n",
      "Class Celebration: Recall Difference = -0.0006982490063379698\n",
      "Class Parade: Recall Difference = -0.00023457658925640779\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.09509981851179672\n",
      "Class Individual_Sports: Recall Difference = -0.17085161709735097\n",
      "Class Surgeons: Recall Difference = -0.06373626373626373\n",
      "Class Spa: Recall Difference = 0.6326530612244898\n",
      "Class Law_Enforcement: Recall Difference = 0.207420539445359\n",
      "Class Business: Recall Difference = 0.013213981244671769\n",
      "Class Dresses: Recall Difference = -0.7300785634118968\n",
      "Class Water_Activities: Recall Difference = 0.2083593912862206\n",
      "Class Picnic: Recall Difference = -0.4642857142857143\n",
      "Class Rescue: Recall Difference = -0.0532407407407407\n",
      "Class Cheering: Recall Difference = 0.07020950434338266\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.03921568627450994\n",
      "Class Family: Recall Difference = -0.26057529610829105\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 3/300*****\n",
      "*****Train Loss:  0.732235 Val Loss:  1.303528*****\n",
      "*****Validation Accuracy: 64.79%*****\n",
      "*****Total Avg Disparity: 0.16373321094910237*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.10729912830882782\n",
      "Class Celebration: Recall Difference = -0.052476098399398596\n",
      "Class Parade: Recall Difference = 0.012549847525216928\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.11324863883847547\n",
      "Class Individual_Sports: Recall Difference = -0.15719973996424508\n",
      "Class Surgeons: Recall Difference = -0.09597069597069596\n",
      "Class Spa: Recall Difference = 0.30612244897959184\n",
      "Class Law_Enforcement: Recall Difference = 0.23135367861213119\n",
      "Class Business: Recall Difference = -0.03687127024722936\n",
      "Class Dresses: Recall Difference = -0.7053872053872053\n",
      "Class Water_Activities: Recall Difference = 0.10100062539086929\n",
      "Class Picnic: Recall Difference = -0.3392857142857142\n",
      "Class Rescue: Recall Difference = -0.012345679012345678\n",
      "Class Cheering: Recall Difference = 0.016760347470618275\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.013943355119825807\n",
      "Class Family: Recall Difference = -0.31791690167324693\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:50<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 4/300*****\n",
      "*****Train Loss: -0.446927 Val Loss:  0.959955*****\n",
      "*****Validation Accuracy: 65.60%*****\n",
      "*****Total Avg Disparity: 0.15842539239080394*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09258434154756601\n",
      "Class Celebration: Recall Difference = -0.08695885702008815\n",
      "Class Parade: Recall Difference = -0.029556650246305383\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.1237749546279493\n",
      "Class Individual_Sports: Recall Difference = -0.16069397042093303\n",
      "Class Surgeons: Recall Difference = -0.12161172161172173\n",
      "Class Spa: Recall Difference = 0.26530612244897966\n",
      "Class Law_Enforcement: Recall Difference = 0.13574775231100433\n",
      "Class Business: Recall Difference = 0.007672634271099654\n",
      "Class Dresses: Recall Difference = -0.7239057239057238\n",
      "Class Water_Activities: Recall Difference = 0.11319574734208881\n",
      "Class Picnic: Recall Difference = -0.3392857142857142\n",
      "Class Rescue: Recall Difference = 0.04012345679012347\n",
      "Class Cheering: Recall Difference = -0.06908533469596312\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.016993464052287688\n",
      "Class Family: Recall Difference = -0.208309832675315\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:50<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:19<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 5/300*****\n",
      "*****Train Loss: -1.128767 Val Loss:  0.803894*****\n",
      "*****Validation Accuracy: 65.63%*****\n",
      "*****Total Avg Disparity: 0.15426862262265678*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09093921010841877\n",
      "Class Celebration: Recall Difference = -0.06069395208937595\n",
      "Class Parade: Recall Difference = -0.012315270935960632\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.06823956442831236\n",
      "Class Individual_Sports: Recall Difference = -0.1623598244758655\n",
      "Class Surgeons: Recall Difference = -0.1186813186813187\n",
      "Class Spa: Recall Difference = 0.22448979591836737\n",
      "Class Law_Enforcement: Recall Difference = 0.1655058883120173\n",
      "Class Business: Recall Difference = 0.0415601023017903\n",
      "Class Dresses: Recall Difference = -0.7547699214365882\n",
      "Class Water_Activities: Recall Difference = 0.14488221805294976\n",
      "Class Picnic: Recall Difference = -0.3392857142857143\n",
      "Class Rescue: Recall Difference = 0.04012345679012347\n",
      "Class Cheering: Recall Difference = -0.031067961165048563\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.009586056644880159\n",
      "Class Family: Recall Difference = -0.20379770633577737\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:19<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 6/300*****\n",
      "*****Train Loss: -1.756179 Val Loss:  0.887863*****\n",
      "*****Validation Accuracy: 64.88%*****\n",
      "*****Total Avg Disparity: 0.17454976531676358*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.0812626383795454\n",
      "Class Celebration: Recall Difference = -0.03808142657643154\n",
      "Class Parade: Recall Difference = 0.04058174994135588\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.12087114337568072\n",
      "Class Individual_Sports: Recall Difference = -0.13838777831951898\n",
      "Class Surgeons: Recall Difference = -0.15018315018315032\n",
      "Class Spa: Recall Difference = 0.26530612244897966\n",
      "Class Law_Enforcement: Recall Difference = 0.17095099404837288\n",
      "Class Business: Recall Difference = 0.03388746803069054\n",
      "Class Dresses: Recall Difference = -0.6806958473625139\n",
      "Class Water_Activities: Recall Difference = 0.1534292265999585\n",
      "Class Picnic: Recall Difference = -0.5892857142857143\n",
      "Class Rescue: Recall Difference = 0.02314814814814814\n",
      "Class Cheering: Recall Difference = -0.08124680633622894\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.0004357298474945148\n",
      "Class Family: Recall Difference = -0.2250423011844332\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 7/300*****\n",
      "*****Train Loss: -2.124312 Val Loss:  0.888982*****\n",
      "*****Validation Accuracy: 64.91%*****\n",
      "*****Total Avg Disparity: 0.16094115400055983*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.10565399686968047\n",
      "Class Celebration: Recall Difference = -0.06321839080459768\n",
      "Class Parade: Recall Difference = 0.02850105559465177\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.08929219600725957\n",
      "Class Individual_Sports: Recall Difference = -0.1452949780594831\n",
      "Class Surgeons: Recall Difference = -0.09010989010989012\n",
      "Class Spa: Recall Difference = 0.2857142857142858\n",
      "Class Law_Enforcement: Recall Difference = 0.14790426744333285\n",
      "Class Business: Recall Difference = 0.005541346973572003\n",
      "Class Dresses: Recall Difference = -0.6992143658810325\n",
      "Class Water_Activities: Recall Difference = 0.10954763393787792\n",
      "Class Picnic: Recall Difference = -0.5714285714285715\n",
      "Class Rescue: Recall Difference = 0.02391975308641975\n",
      "Class Cheering: Recall Difference = -0.0027593254982115623\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.005228758169934622\n",
      "Class Family: Recall Difference = -0.20172964843015606\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 8/300*****\n",
      "*****Train Loss: -2.394066 Val Loss:  0.930838*****\n",
      "*****Validation Accuracy: 64.91%*****\n",
      "*****Total Avg Disparity: 0.16748893859338246*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.06859284139333488\n",
      "Class Celebration: Recall Difference = -0.061445912557739846\n",
      "Class Parade: Recall Difference = 0.03741496598639471\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.08929219600725968\n",
      "Class Individual_Sports: Recall Difference = -0.14704209328782714\n",
      "Class Surgeons: Recall Difference = -0.14432234432234436\n",
      "Class Spa: Recall Difference = 0.26530612244897955\n",
      "Class Law_Enforcement: Recall Difference = 0.11979232619982283\n",
      "Class Business: Recall Difference = 0.043691389599318065\n",
      "Class Dresses: Recall Difference = -0.6498316498316498\n",
      "Class Water_Activities: Recall Difference = 0.1534292265999585\n",
      "Class Picnic: Recall Difference = -0.6071428571428571\n",
      "Class Rescue: Recall Difference = 0.0524691358024692\n",
      "Class Cheering: Recall Difference = -0.020541645375574902\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.021350762527233058\n",
      "Class Family: Recall Difference = -0.19815754841135547\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:19<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 9/300*****\n",
      "*****Train Loss: -2.553827 Val Loss:  1.087625*****\n",
      "*****Validation Accuracy: 65.28%*****\n",
      "*****Total Avg Disparity: 0.1577417071509487*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08535261792964777\n",
      "Class Celebration: Recall Difference = -0.03593296809539159\n",
      "Class Parade: Recall Difference = 0.03870513722730473\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.1237749546279493\n",
      "Class Individual_Sports: Recall Difference = -0.12839265398992372\n",
      "Class Surgeons: Recall Difference = -0.001465201465201571\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.09421299227554769\n",
      "Class Business: Recall Difference = 0.010017050298380292\n",
      "Class Dresses: Recall Difference = -0.6683501683501685\n",
      "Class Water_Activities: Recall Difference = 0.1497811131957475\n",
      "Class Picnic: Recall Difference = -0.6249999999999999\n",
      "Class Rescue: Recall Difference = 0.05787037037037035\n",
      "Class Cheering: Recall Difference = -0.021359223300970842\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.023093681917211395\n",
      "Class Family: Recall Difference = -0.17484489565707834\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 10/300*****\n",
      "*****Train Loss: -2.711892 Val Loss:  1.013850*****\n",
      "*****Validation Accuracy: 65.08%*****\n",
      "*****Total Avg Disparity: 0.16259268250470152*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.07048931235790745\n",
      "Class Celebration: Recall Difference = -0.11891717692555598\n",
      "Class Parade: Recall Difference = 0.022753929157870112\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.07876588021778597\n",
      "Class Individual_Sports: Recall Difference = -0.1623598244758655\n",
      "Class Surgeons: Recall Difference = 0.02124542124542106\n",
      "Class Spa: Recall Difference = 0.26530612244897966\n",
      "Class Law_Enforcement: Recall Difference = 0.07534506774724581\n",
      "Class Business: Recall Difference = 0.08503836317135538\n",
      "Class Dresses: Recall Difference = -0.6868686868686869\n",
      "Class Water_Activities: Recall Difference = 0.15217844486137178\n",
      "Class Picnic: Recall Difference = -0.6071428571428571\n",
      "Class Rescue: Recall Difference = 0.014660493827160503\n",
      "Class Cheering: Recall Difference = 0.007766990291262099\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.015686274509803977\n",
      "Class Family: Recall Difference = -0.21695807482609514\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 11/300*****\n",
      "*****Train Loss: -2.790962 Val Loss:  1.121312*****\n",
      "*****Validation Accuracy: 65.11%*****\n",
      "*****Total Avg Disparity: 0.15685210284008963*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08644937222241256\n",
      "Class Celebration: Recall Difference = -0.0887313352669461\n",
      "Class Parade: Recall Difference = 0.009383063570255645\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.06061705989110722\n",
      "Class Individual_Sports: Recall Difference = -0.15561514708272373\n",
      "Class Surgeons: Recall Difference = -0.06153846153846154\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.07116626567050777\n",
      "Class Business: Recall Difference = 0.03069053708439906\n",
      "Class Dresses: Recall Difference = -0.5589225589225589\n",
      "Class Water_Activities: Recall Difference = 0.1155930790077132\n",
      "Class Picnic: Recall Difference = -0.5892857142857142\n",
      "Class Rescue: Recall Difference = 0.07716049382716056\n",
      "Class Cheering: Recall Difference = -0.02943280531425646\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.06579520697167757\n",
      "Class Family: Recall Difference = -0.22353825907125396\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 12/300*****\n",
      "*****Train Loss: -2.839905 Val Loss:  1.206191*****\n",
      "*****Validation Accuracy: 65.60%*****\n",
      "*****Total Avg Disparity: 0.15496895199498578*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.0869977493687949\n",
      "Class Celebration: Recall Difference = -0.0955526909442474\n",
      "Class Parade: Recall Difference = -0.02509969505043408\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.05480943738656996\n",
      "Class Individual_Sports: Recall Difference = -0.08585242970908491\n",
      "Class Surgeons: Recall Difference = -0.01611721611721606\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.05900975053817914\n",
      "Class Business: Recall Difference = 0.026214833759590994\n",
      "Class Dresses: Recall Difference = -0.6083052749719415\n",
      "Class Water_Activities: Recall Difference = 0.13633520950594125\n",
      "Class Picnic: Recall Difference = -0.5892857142857142\n",
      "Class Rescue: Recall Difference = 0.07716049382716045\n",
      "Class Cheering: Recall Difference = -0.037506387327542245\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.00958605664488027\n",
      "Class Family: Recall Difference = -0.2859560067681895\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Teacher\n",
      "model is loaded properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:07<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher weights and architecture saved and exported for lambda: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:50<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 1/300*****\n",
      "*****Train Loss:  6.782962 Val Loss:  8.616423*****\n",
      "*****Validation Accuracy: 54.89%*****\n",
      "*****Total Avg Disparity: 0.15862799288181437*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.11927202933817727\n",
      "Class Celebration: Recall Difference = -0.07218820496293904\n",
      "Class Parade: Recall Difference = -0.0014074595355383357\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.15063520871143365\n",
      "Class Individual_Sports: Recall Difference = -0.12298878595806928\n",
      "Class Surgeons: Recall Difference = 0.09963369963369961\n",
      "Class Spa: Recall Difference = -0.1836734693877551\n",
      "Class Law_Enforcement: Recall Difference = 0.3030264657464861\n",
      "Class Business: Recall Difference = -0.04241261722080131\n",
      "Class Dresses: Recall Difference = -0.771604938271605\n",
      "Class Water_Activities: Recall Difference = 0.1497811131957475\n",
      "Class Picnic: Recall Difference = -0.1785714285714286\n",
      "Class Rescue: Recall Difference = 0.0038580246913580245\n",
      "Class Cheering: Recall Difference = 0.030659172202350524\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.08235294117647063\n",
      "Class Family: Recall Difference = -0.22598232750517014\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 2/300*****\n",
      "*****Train Loss:  3.485911 Val Loss:  6.118249*****\n",
      "*****Validation Accuracy: 62.86%*****\n",
      "*****Total Avg Disparity: 0.18738124855540061*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08739760770469895\n",
      "Class Celebration: Recall Difference = -0.06461488881727373\n",
      "Class Parade: Recall Difference = 0.018883415435139494\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.1477313974591653\n",
      "Class Individual_Sports: Recall Difference = -0.17942467089224767\n",
      "Class Surgeons: Recall Difference = 0.07545787545787541\n",
      "Class Spa: Recall Difference = 0.44897959183673464\n",
      "Class Law_Enforcement: Recall Difference = 0.2598455109535267\n",
      "Class Business: Recall Difference = 0.037084398976982125\n",
      "Class Dresses: Recall Difference = -0.7839506172839508\n",
      "Class Water_Activities: Recall Difference = 0.12174275588909744\n",
      "Class Picnic: Recall Difference = -0.3928571428571428\n",
      "Class Rescue: Recall Difference = 0.017746913580246937\n",
      "Class Cheering: Recall Difference = -0.009913132345426706\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.02440087145969516\n",
      "Class Family: Recall Difference = -0.3280691859372062\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 3/300*****\n",
      "*****Train Loss:  2.167794 Val Loss:  5.829748*****\n",
      "*****Validation Accuracy: 64.56%*****\n",
      "*****Total Avg Disparity: 0.1799250924557559*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08834584318698524\n",
      "Class Celebration: Recall Difference = -0.06359437103877968\n",
      "Class Parade: Recall Difference = 0.04632887637813754\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.09219600725952803\n",
      "Class Individual_Sports: Recall Difference = -0.13164310092637732\n",
      "Class Surgeons: Recall Difference = -0.06739926739926738\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.16677219197163473\n",
      "Class Business: Recall Difference = 0.01321398124467188\n",
      "Class Dresses: Recall Difference = -0.771604938271605\n",
      "Class Water_Activities: Recall Difference = 0.13883677298311448\n",
      "Class Picnic: Recall Difference = -0.6249999999999999\n",
      "Class Rescue: Recall Difference = 0.054012345679012363\n",
      "Class Cheering: Recall Difference = -0.03914154317833424\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.07145969498910676\n",
      "Class Family: Recall Difference = -0.22353825907125413\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 4/300*****\n",
      "*****Train Loss:  1.209297 Val Loss:  5.649230*****\n",
      "*****Validation Accuracy: 65.60%*****\n",
      "*****Total Avg Disparity: 0.17559722704797742*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08889422033336758\n",
      "Class Celebration: Recall Difference = -0.0865828767859061\n",
      "Class Parade: Recall Difference = 0.06040347173352101\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.05771324863883853\n",
      "Class Individual_Sports: Recall Difference = -0.11482203803022906\n",
      "Class Surgeons: Recall Difference = -0.17289377289377295\n",
      "Class Spa: Recall Difference = 0.26530612244897966\n",
      "Class Law_Enforcement: Recall Difference = 0.12359123717867548\n",
      "Class Business: Recall Difference = 0.04475703324808189\n",
      "Class Dresses: Recall Difference = -0.6992143658810325\n",
      "Class Water_Activities: Recall Difference = 0.12174275588909744\n",
      "Class Picnic: Recall Difference = -0.6249999999999999\n",
      "Class Rescue: Recall Difference = 0.01620370370370361\n",
      "Class Cheering: Recall Difference = -0.04885028104241185\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.036165577342047894\n",
      "Class Family: Recall Difference = -0.2474149276179733\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 5/300*****\n",
      "*****Train Loss:  0.433494 Val Loss:  6.050241*****\n",
      "*****Validation Accuracy: 65.77%*****\n",
      "*****Total Avg Disparity: 0.16906158286245168*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09393243536575624\n",
      "Class Celebration: Recall Difference = -0.05210011816521637\n",
      "Class Parade: Recall Difference = 0.025920713112831395\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.012704174228675202\n",
      "Class Individual_Sports: Recall Difference = -0.08926539899236141\n",
      "Class Surgeons: Recall Difference = -0.1501831501831502\n",
      "Class Spa: Recall Difference = 0.30612244897959184\n",
      "Class Law_Enforcement: Recall Difference = 0.12777003925541341\n",
      "Class Business: Recall Difference = 0.01662404092071612\n",
      "Class Dresses: Recall Difference = -0.7530864197530864\n",
      "Class Water_Activities: Recall Difference = 0.1583281217427558\n",
      "Class Picnic: Recall Difference = -0.6071428571428572\n",
      "Class Rescue: Recall Difference = -0.009259259259259245\n",
      "Class Cheering: Recall Difference = -0.030250383239652567\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.018300653594771288\n",
      "Class Family: Recall Difference = -0.2539951118631322\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:50<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 6/300*****\n",
      "*****Train Loss: -0.070664 Val Loss:  6.480259*****\n",
      "*****Validation Accuracy: 65.34%*****\n",
      "*****Total Avg Disparity: 0.17156804336725046*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08520409911916915\n",
      "Class Celebration: Recall Difference = -0.10060156837469114\n",
      "Class Parade: Recall Difference = 0.025920713112831395\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.07876588021778586\n",
      "Class Individual_Sports: Recall Difference = -0.10791483829026494\n",
      "Class Surgeons: Recall Difference = -0.09890109890109888\n",
      "Class Spa: Recall Difference = 0.30612244897959184\n",
      "Class Law_Enforcement: Recall Difference = 0.08585538812207172\n",
      "Class Business: Recall Difference = 0.03069053708439895\n",
      "Class Dresses: Recall Difference = -0.7716049382716051\n",
      "Class Water_Activities: Recall Difference = 0.13883677298311436\n",
      "Class Picnic: Recall Difference = -0.6071428571428572\n",
      "Class Rescue: Recall Difference = -0.009259259259259356\n",
      "Class Cheering: Recall Difference = -0.03270311701584061\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.040522875816993376\n",
      "Class Family: Recall Difference = -0.2250423011844332\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 7/300*****\n",
      "*****Train Loss: -0.409331 Val Loss:  6.810941*****\n",
      "*****Validation Accuracy: 65.74%*****\n",
      "*****Total Avg Disparity: 0.17256744887325773*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.07063783116838596\n",
      "Class Celebration: Recall Difference = -0.10527446557095282\n",
      "Class Parade: Recall Difference = 0.043162092423176146\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.09219600725952826\n",
      "Class Individual_Sports: Recall Difference = -0.10283601495205597\n",
      "Class Surgeons: Recall Difference = -0.15311355311355312\n",
      "Class Spa: Recall Difference = 0.26530612244897966\n",
      "Class Law_Enforcement: Recall Difference = 0.07914397872609868\n",
      "Class Business: Recall Difference = 0.01982097186700771\n",
      "Class Dresses: Recall Difference = -0.7592592592592593\n",
      "Class Water_Activities: Recall Difference = 0.12049197415051072\n",
      "Class Picnic: Recall Difference = -0.625\n",
      "Class Rescue: Recall Difference = -0.026234567901234518\n",
      "Class Cheering: Recall Difference = -0.06663260091977524\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.08758169934640514\n",
      "Class Family: Recall Difference = -0.1443880428652003\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 8/300*****\n",
      "*****Train Loss: -0.641041 Val Loss:  6.746652*****\n",
      "*****Validation Accuracy: 64.88%*****\n",
      "*****Total Avg Disparity: 0.15896704702224315*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09079069129794037\n",
      "Class Celebration: Recall Difference = -0.0563970351272961\n",
      "Class Parade: Recall Difference = 0.04632887637813743\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.07876588021778597\n",
      "Class Individual_Sports: Recall Difference = -0.03823338209003735\n",
      "Class Surgeons: Recall Difference = -0.2300366300366301\n",
      "Class Spa: Recall Difference = 0.26530612244897966\n",
      "Class Law_Enforcement: Recall Difference = 0.0887678865391921\n",
      "Class Business: Recall Difference = -0.027067348678601943\n",
      "Class Dresses: Recall Difference = -0.7115600448933783\n",
      "Class Water_Activities: Recall Difference = 0.1046487387950803\n",
      "Class Picnic: Recall Difference = -0.6249999999999999\n",
      "Class Rescue: Recall Difference = -0.030864197530864168\n",
      "Class Cheering: Recall Difference = -0.03106796116504862\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.008278867102396559\n",
      "Class Family: Recall Difference = -0.11035909005452155\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 9/300*****\n",
      "*****Train Loss: -0.771160 Val Loss:  7.634789*****\n",
      "*****Validation Accuracy: 64.96%*****\n",
      "*****Total Avg Disparity: 0.1642565782964544*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.04420148290320003\n",
      "Class Celebration: Recall Difference = -0.06106993232355784\n",
      "Class Parade: Recall Difference = 0.078935022284776\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.10562613430127044\n",
      "Class Individual_Sports: Recall Difference = -0.04664391353811137\n",
      "Class Surgeons: Recall Difference = -0.12454212454212465\n",
      "Class Spa: Recall Difference = 0.30612244897959195\n",
      "Class Law_Enforcement: Recall Difference = 0.06445485627453473\n",
      "Class Business: Recall Difference = 0.01982097186700771\n",
      "Class Dresses: Recall Difference = -0.7469135802469137\n",
      "Class Water_Activities: Recall Difference = 0.1046487387950803\n",
      "Class Picnic: Recall Difference = -0.6249999999999999\n",
      "Class Rescue: Recall Difference = -0.0054012345679012586\n",
      "Class Cheering: Recall Difference = -0.1314256515074093\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.002178649237472907\n",
      "Class Family: Recall Difference = -0.16112051137431832\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 10/300*****\n",
      "*****Train Loss: -0.849056 Val Loss:  8.012077*****\n",
      "*****Validation Accuracy: 64.56%*****\n",
      "*****Total Avg Disparity: 0.165421748439537*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.07826941312220814\n",
      "Class Celebration: Recall Difference = -0.1350843269953808\n",
      "Class Parade: Recall Difference = 0.07447806708890448\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.11905626134301273\n",
      "Class Individual_Sports: Recall Difference = -0.08910287664553884\n",
      "Class Surgeons: Recall Difference = -0.12454212454212454\n",
      "Class Spa: Recall Difference = 0.24489795918367352\n",
      "Class Law_Enforcement: Recall Difference = 0.055210839559326375\n",
      "Class Business: Recall Difference = -0.029198635976129594\n",
      "Class Dresses: Recall Difference = -0.7222222222222222\n",
      "Class Water_Activities: Recall Difference = 0.10100062539086929\n",
      "Class Picnic: Recall Difference = -0.6607142857142856\n",
      "Class Rescue: Recall Difference = 0.00694444444444442\n",
      "Class Cheering: Recall Difference = -0.041594276954522225\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.020043572984749347\n",
      "Class Family: Recall Difference = -0.14438804286520018\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 11/300*****\n",
      "*****Train Loss: -0.904807 Val Loss:  8.019590*****\n",
      "*****Validation Accuracy: 64.91%*****\n",
      "*****Total Avg Disparity: 0.16715931681445168*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.10635089282654153\n",
      "Class Celebration: Recall Difference = -0.0959286711784294\n",
      "Class Parade: Recall Difference = 0.06427398545625129\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.03666061705989121\n",
      "Class Individual_Sports: Recall Difference = -0.061961644726149734\n",
      "Class Surgeons: Recall Difference = -0.17582417582417587\n",
      "Class Spa: Recall Difference = 0.326530612244898\n",
      "Class Law_Enforcement: Recall Difference = 0.05900975053817903\n",
      "Class Business: Recall Difference = 0.03282182438192671\n",
      "Class Dresses: Recall Difference = -0.7407407407407407\n",
      "Class Water_Activities: Recall Difference = 0.09735251198665829\n",
      "Class Picnic: Recall Difference = -0.6607142857142858\n",
      "Class Rescue: Recall Difference = -0.04243827160493835\n",
      "Class Cheering: Recall Difference = -0.028615227388860576\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.009586056644880159\n",
      "Class Family: Recall Difference = -0.13573980071442\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Teacher\n",
      "model is loaded properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:07<00:00,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher weights and architecture saved and exported for lambda: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.48it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 1/300*****\n",
      "*****Train Loss:  2.093331 Val Loss:  1.571533*****\n",
      "*****Validation Accuracy: 55.01%*****\n",
      "*****Total Avg Disparity: 0.147243008207756*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09502918965852103\n",
      "Class Celebration: Recall Difference = -0.10414652486840698\n",
      "Class Parade: Recall Difference = -0.007271874266948197\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.17568058076225052\n",
      "Class Individual_Sports: Recall Difference = -0.13148057857955464\n",
      "Class Surgeons: Recall Difference = 0.04249084249084249\n",
      "Class Spa: Recall Difference = -0.16326530612244897\n",
      "Class Law_Enforcement: Recall Difference = 0.3193617829555526\n",
      "Class Business: Recall Difference = -0.029411764705882304\n",
      "Class Dresses: Recall Difference = -0.6144781144781144\n",
      "Class Water_Activities: Recall Difference = 0.1656243485511779\n",
      "Class Picnic: Recall Difference = -0.1785714285714286\n",
      "Class Rescue: Recall Difference = -0.029320987654320986\n",
      "Class Cheering: Recall Difference = 0.021768012263668854\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.09411764705882358\n",
      "Class Family: Recall Difference = -0.18386914833615342\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:19<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 2/300*****\n",
      "*****Train Loss:  1.313434 Val Loss:  1.248845*****\n",
      "*****Validation Accuracy: 62.91%*****\n",
      "*****Total Avg Disparity: 0.16467817666938492*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08480424078326543\n",
      "Class Celebration: Recall Difference = -0.03732946610806759\n",
      "Class Parade: Recall Difference = 0.050785831574008844\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.09219600725952826\n",
      "Class Individual_Sports: Recall Difference = -0.15561514708272373\n",
      "Class Surgeons: Recall Difference = 0.038827838827838856\n",
      "Class Spa: Recall Difference = 0.4897959183673469\n",
      "Class Law_Enforcement: Recall Difference = 0.23553248068886923\n",
      "Class Business: Recall Difference = 0.0002131287297527651\n",
      "Class Dresses: Recall Difference = -0.7592592592592594\n",
      "Class Water_Activities: Recall Difference = 0.13393787784031697\n",
      "Class Picnic: Recall Difference = -0.2678571428571429\n",
      "Class Rescue: Recall Difference = 0.0015432098765432445\n",
      "Class Cheering: Recall Difference = 0.060500766479304996\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.021350762527233058\n",
      "Class Family: Recall Difference = -0.2053017484489566\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 3/300*****\n",
      "*****Train Loss:  0.935686 Val Loss:  1.154036*****\n",
      "*****Validation Accuracy: 65.19%*****\n",
      "*****Total Avg Disparity: 0.15999997546194777*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09747403776947594\n",
      "Class Celebration: Recall Difference = -0.02911161241808996\n",
      "Class Parade: Recall Difference = 0.028501055594651548\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.18983666061705995\n",
      "Class Individual_Sports: Recall Difference = -0.07386640663091182\n",
      "Class Surgeons: Recall Difference = -0.06739926739926738\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.16132708623527914\n",
      "Class Business: Recall Difference = -0.009590792838874762\n",
      "Class Dresses: Recall Difference = -0.6144781144781144\n",
      "Class Water_Activities: Recall Difference = 0.13028976443610596\n",
      "Class Picnic: Recall Difference = -0.3571428571428572\n",
      "Class Rescue: Recall Difference = 0.06944444444444448\n",
      "Class Cheering: Recall Difference = -0.09095554420030666\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.07755991285403041\n",
      "Class Family: Recall Difference = -0.27730776461740936\n",
      "teacher weights and architecture saved and exported to S3\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 4/300*****\n",
      "*****Train Loss:  0.665525 Val Loss:  1.165579*****\n",
      "*****Validation Accuracy: 65.54%*****\n",
      "*****Total Avg Disparity: 0.188346304830752*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09857079206224084\n",
      "Class Celebration: Recall Difference = 0.06284241057041573\n",
      "Class Parade: Recall Difference = 0.008092892329345625\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.07876588021778608\n",
      "Class Individual_Sports: Recall Difference = -0.08410531448074099\n",
      "Class Surgeons: Recall Difference = -0.20146520146520153\n",
      "Class Spa: Recall Difference = 0.36734693877551017\n",
      "Class Law_Enforcement: Recall Difference = 0.19108522223629232\n",
      "Class Business: Recall Difference = -0.03900255754475701\n",
      "Class Dresses: Recall Difference = -0.6391694725028059\n",
      "Class Water_Activities: Recall Difference = 0.08515739003543898\n",
      "Class Picnic: Recall Difference = -0.6071428571428572\n",
      "Class Rescue: Recall Difference = 0.16435185185185192\n",
      "Class Cheering: Recall Difference = -0.01808891159938686\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.11285403050108922\n",
      "Class Family: Recall Difference = -0.25549915397631123\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 5/300*****\n",
      "*****Train Loss:  0.448679 Val Loss:  1.195538*****\n",
      "*****Validation Accuracy: 66.06%*****\n",
      "*****Total Avg Disparity: 0.1744252656020419*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.1265037529560955\n",
      "Class Celebration: Recall Difference = 0.024062734987646328\n",
      "Class Parade: Recall Difference = 0.015130190007037303\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.09981851179673329\n",
      "Class Individual_Sports: Recall Difference = -0.07386640663091149\n",
      "Class Surgeons: Recall Difference = -0.1186813186813187\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.16677219197163484\n",
      "Class Business: Recall Difference = -0.0824808184143222\n",
      "Class Dresses: Recall Difference = -0.6391694725028059\n",
      "Class Water_Activities: Recall Difference = 0.10589952053366702\n",
      "Class Picnic: Recall Difference = -0.6428571428571429\n",
      "Class Rescue: Recall Difference = 0.07716049382716045\n",
      "Class Cheering: Recall Difference = -0.06182933060807355\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.02701525054466236\n",
      "Class Family: Recall Difference = -0.2438428275991728\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:19<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 6/300*****\n",
      "*****Train Loss:  0.309800 Val Loss:  1.309082*****\n",
      "*****Validation Accuracy: 65.51%*****\n",
      "*****Total Avg Disparity: 0.16090798591554578*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09637728347671104\n",
      "Class Celebration: Recall Difference = -0.024062734987646328\n",
      "Class Parade: Recall Difference = 0.025334271639690487\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.16588021778584383\n",
      "Class Individual_Sports: Recall Difference = -0.08243946042580841\n",
      "Class Surgeons: Recall Difference = -0.09304029304029315\n",
      "Class Spa: Recall Difference = 0.34693877551020413\n",
      "Class Law_Enforcement: Recall Difference = 0.19108522223629232\n",
      "Class Business: Recall Difference = 0.03069053708439895\n",
      "Class Dresses: Recall Difference = -0.5482603815937149\n",
      "Class Water_Activities: Recall Difference = 0.08025849489264136\n",
      "Class Picnic: Recall Difference = -0.6071428571428572\n",
      "Class Rescue: Recall Difference = -0.0007716049382716084\n",
      "Class Cheering: Recall Difference = -0.03515585079202865\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.0017429193899780593\n",
      "Class Family: Recall Difference = -0.24534686971235192\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 7/300*****\n",
      "*****Train Loss:  0.209924 Val Loss:  1.351125*****\n",
      "*****Validation Accuracy: 65.11%*****\n",
      "*****Total Avg Disparity: 0.16441574171538476*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09692566062309349\n",
      "Class Celebration: Recall Difference = 0.007895584917821608\n",
      "Class Parade: Recall Difference = 0.07764485104386576\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.11324863883847558\n",
      "Class Individual_Sports: Recall Difference = -0.07561352185925552\n",
      "Class Surgeons: Recall Difference = -0.12161172161172173\n",
      "Class Spa: Recall Difference = 0.36734693877551017\n",
      "Class Law_Enforcement: Recall Difference = 0.17095099404837277\n",
      "Class Business: Recall Difference = -0.018329070758738464\n",
      "Class Dresses: Recall Difference = -0.5235690235690236\n",
      "Class Water_Activities: Recall Difference = 0.05586825099020243\n",
      "Class Picnic: Recall Difference = -0.6428571428571429\n",
      "Class Rescue: Recall Difference = 0.06095679012345678\n",
      "Class Cheering: Recall Difference = -0.07235564639754727\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.00043572984749473687\n",
      "Class Family: Recall Difference = -0.2250423011844332\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 8/300*****\n",
      "*****Train Loss:  0.152271 Val Loss:  1.400558*****\n",
      "*****Validation Accuracy: 65.40%*****\n",
      "*****Total Avg Disparity: 0.15267132936358538*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08221087386183179\n",
      "Class Celebration: Recall Difference = 0.005747126436781547\n",
      "Class Parade: Recall Difference = 0.01196340605207602\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.13720508166969148\n",
      "Class Individual_Sports: Recall Difference = -0.060377051844628604\n",
      "Class Surgeons: Recall Difference = -0.14432234432234436\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.1466379637837153\n",
      "Class Business: Recall Difference = -0.019394714407502067\n",
      "Class Dresses: Recall Difference = -0.5173961840628508\n",
      "Class Water_Activities: Recall Difference = 0.06316447779862422\n",
      "Class Picnic: Recall Difference = -0.6785714285714285\n",
      "Class Rescue: Recall Difference = 0.014660493827160503\n",
      "Class Cheering: Recall Difference = -0.019724067450178906\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.0422657952069716\n",
      "Class Family: Recall Difference = -0.2133859748072947\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 9/300*****\n",
      "*****Train Loss:  0.121392 Val Loss:  1.471518*****\n",
      "*****Validation Accuracy: 64.73%*****\n",
      "*****Total Avg Disparity: 0.14714166634825032*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09882213158766617\n",
      "Class Celebration: Recall Difference = -0.005747126436781602\n",
      "Class Parade: Recall Difference = 0.017006802721088454\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.012704174228675202\n",
      "Class Individual_Sports: Recall Difference = -0.07727937591418821\n",
      "Class Surgeons: Recall Difference = -0.14432234432234436\n",
      "Class Spa: Recall Difference = 0.2857142857142857\n",
      "Class Law_Enforcement: Recall Difference = 0.19779663163226546\n",
      "Class Business: Recall Difference = 0.02408354646206312\n",
      "Class Dresses: Recall Difference = -0.5235690235690237\n",
      "Class Water_Activities: Recall Difference = 0.08150927663122798\n",
      "Class Picnic: Recall Difference = -0.5892857142857143\n",
      "Class Rescue: Recall Difference = -0.03858024691358025\n",
      "Class Cheering: Recall Difference = -0.042411854879918276\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.049237472766884616\n",
      "Class Family: Recall Difference = -0.16619665350629825\n",
      "Data has been appended to ./runs_2023_12_05_06_26/teacher_validation_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:49<00:00,  1.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 55/55 [00:18<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 10/300*****\n",
      "*****Train Loss:  0.091898 Val Loss:  1.502901*****\n",
      "*****Validation Accuracy: 65.17%*****\n",
      "*****Total Avg Disparity: 0.14880386857002906*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.09951902754452713\n",
      "Class Celebration: Recall Difference = -0.026963153937050177\n",
      "Class Parade: Recall Difference = 0.03237156931738194\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.04428312159709635\n",
      "Class Individual_Sports: Recall Difference = -0.0806923451974646\n",
      "Class Surgeons: Recall Difference = -0.0871794871794872\n",
      "Class Spa: Recall Difference = 0.36734693877551017\n",
      "Class Law_Enforcement: Recall Difference = 0.17892870710396358\n",
      "Class Business: Recall Difference = 0.0012787723785165905\n",
      "Class Dresses: Recall Difference = -0.511223344556678\n",
      "Class Water_Activities: Recall Difference = 0.09370439858244739\n",
      "Class Picnic: Recall Difference = -0.6071428571428572\n",
      "Class Rescue: Recall Difference = 0.00694444444444442\n",
      "Class Cheering: Recall Difference = -0.050485436893203894\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.004793028322440107\n",
      "Class Family: Recall Difference = -0.18800526414739616\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRkklEQVR4nO3dd3hUVeLG8e9MyqQnBEhIIECogQRCE6UoIhZQUQQEFRXb2rCtioquiq6K2BURxQKLCiqo2FAUQRBEihgg9BIgpFGTSS8z9/dHSJQfRUqSO+X9PM88a2buJO8wS+bl3HPPsRiGYSAiIiLiIaxmBxARERGpSSo3IiIi4lFUbkRERMSjqNyIiIiIR1G5EREREY+iciMiIiIeReVGREREPIrKjYiIiHgUlRsRERHxKCo3InLSduzYgcViYerUqWZHERE5gsqNiIe77LLLCAoKIj8//5jHjBgxAn9/f/bv31+jP/uXX37BYrEwa9asGv2+tWXbtm3cdttttGjRgoCAAMLCwujVqxevv/46xcXFZscTkROkciPi4UaMGEFxcTFffvnlUR8vKiriq6++on///tSvX7+O07mO7777jg4dOvDZZ58xcOBAJkyYwLhx42jatCmjR4/m3nvvNTuiiJwgX7MDiEjtuuyyywgNDWX69Olcf/31Rzz+1VdfUVhYyIgRI0xI5xrS0tK46qqraNasGfPnzycmJqb6sVGjRrF161a+++67GvlZhYWFBAcH18j3EpGj08iNiIcLDAxk8ODB/Pzzz+zZs+eIx6dPn05oaCiXXXYZBw4c4MEHH6RDhw6EhIQQFhbGgAEDWL16da1m3L59O1deeSWRkZEEBQVx1llnHbVMTJgwgcTERIKCgqhXrx7dunVj+vTp1Y/n5+dz33330bx5c2w2G1FRUVxwwQWsWrXquD//hRdeoKCggPfff/+wYlOlVatW1SM3x5tvZLFYGDt2bPXXY8eOxWKxsH79eq655hrq1atH7969eemll7BYLOzcufOI7zFmzBj8/f05ePBg9X3Lli2jf//+hIeHExQURJ8+fViyZMlxX5OIN1O5EfECI0aMoKKigs8+++yw+w8cOMDcuXO54oorCAwMZPv27cyePZtLL72UV155hdGjR7N27Vr69OlDZmZmrWTLycmhZ8+ezJ07lzvvvJNnn32WkpISLrvsssNOpb377rvcc889tG/fntdee42nnnqKTp06sWzZsupjbr/9diZNmsSQIUN46623ePDBBwkMDGTDhg3HzfDNN9/QokULevbsWSuv8corr6SoqIjnnnuOf/3rXwwbNgyLxXLE+wHw2WefceGFF1KvXj0A5s+fzznnnIPdbufJJ5/kueeeIzc3l/POO4/ly5fXSl4Rt2eIiMerqKgwYmJijB49ehx2/9tvv20Axty5cw3DMIySkhLD4XAcdkxaWpphs9mMp59++rD7AGPKlCnH/bkLFiwwAGPmzJnHPOa+++4zAOPXX3+tvi8/P9+Ij483mjdvXp3n8ssvNxITE4/788LDw41Ro0Yd95j/Ly8vzwCMyy+//ISOP95rB4wnn3yy+usnn3zSAIyrr776iGN79OhhdO3a9bD7li9fbgDGtGnTDMMwDKfTabRu3dq46KKLDKfTWX1cUVGRER8fb1xwwQUnlFnE22jkRsQL+Pj4cNVVV7F06VJ27NhRff/06dOJjo6mX79+ANhsNqzWyl8LDoeD/fv3ExISQtu2bf/x1M6pmjNnDt27d6d3797V94WEhHDrrbeyY8cO1q9fD0BERAS7d+9mxYoVx/xeERERLFu27KRGmex2OwChoaGn+Ar+2e23337EfcOHD+ePP/5g27Zt1fd9+umn2Gw2Lr/8cgBSUlLYsmUL11xzDfv372ffvn3s27ePwsJC+vXrx6JFi3A6nbWWW8RdqdyIeImqCcNVc1R2797Nr7/+ylVXXYWPjw8ATqeTV199ldatW2Oz2WjQoAENGzZkzZo15OXl1UqunTt30rZt2yPub9euXfXjAA8//DAhISF0796d1q1bM2rUqCPmnbzwwgukpqYSFxdH9+7dGTt2LNu3bz/uzw8LCwM47qXypys+Pv6I+6688kqsViuffvopAIZhMHPmTAYMGFCdacuWLQCMHDmShg0bHnZ77733KC0trbX3RcSdqdyIeImuXbuSkJDAjBkzAJgxYwaGYRx2ldRzzz3H/fffzznnnMNHH33E3Llz+emnn0hMTDR9hKBdu3Zs2rSJTz75hN69e/P555/Tu3dvnnzyyepjhg0bxvbt25kwYQKxsbG8+OKLJCYm8v333x/z+4aFhREbG0tqauoJ5bBYLEe93+FwHPM5gYGBR9wXGxvL2WefXT3v5vfff2fXrl0MHz68+piqP/MXX3yRn3766ai3kJCQE8ot4k10KbiIFxkxYgSPP/44a9asYfr06bRu3Zozzjij+vFZs2bRt29f3n///cOel5ubS4MGDWolU7Nmzdi0adMR92/cuLH68SrBwcEMHz6c4cOHU1ZWxuDBg3n22WcZM2YMAQEBAMTExHDnnXdy5513smfPHrp06cKzzz7LgAEDjpnh0ksvZfLkySxdupQePXocN2/VRN/c3NzD7j/alU//ZPjw4dx5551s2rSJTz/9lKCgIAYOHFj9eMuWLYHKAnb++eef9PcX8VYauRHxIlWjNE888QQpKSlHrG3j4+ODYRiH3Tdz5kwyMjJqLdPFF1/M8uXLWbp0afV9hYWFTJ48mebNm9O+fXuAI1ZP9vf3p3379hiGQXl5OQ6H44hTNFFRUcTGxlJaWnrcDA899BDBwcHccsst5OTkHPH4tm3beP3114HKotGgQQMWLVp02DFvvfXWib/oQ4YMGYKPjw8zZsxg5syZXHrppYetgdO1a1datmzJSy+9REFBwRHP37t370n/TBFvoJEbES8SHx9Pz549+eqrrwCOKDeXXnopTz/9NDfeeCM9e/Zk7dq1fPzxx7Ro0eK0fu7nn39ePRLzdyNHjuSRRx5hxowZDBgwgHvuuYfIyEj+97//kZaWxueff149wfnCCy+kUaNG9OrVi+joaDZs2MCbb77JJZdcQmhoKLm5uTRp0oShQ4eSnJxMSEgI8+bNY8WKFbz88svHzdeyZUumT5/O8OHDadeuHddffz1JSUmUlZXx22+/MXPmTG644Ybq42+55Raef/55brnlFrp168aiRYvYvHnzSf+5REVF0bdvX1555RXy8/MPOyUFYLVaee+99xgwYACJiYnceOONNG7cmIyMDBYsWEBYWBjffPPNSf9cEY9n7sVaIlLXJk6caABG9+7dj3ispKTEeOCBB4yYmBgjMDDQ6NWrl7F06VKjT58+Rp8+faqPO9lLwY91q7r8e9u2bcbQoUONiIgIIyAgwOjevbvx7bffHva93nnnHeOcc84x6tevb9hsNqNly5bG6NGjjby8PMMwDKO0tNQYPXq0kZycbISGhhrBwcFGcnKy8dZbb53wn83mzZuNf/3rX0bz5s0Nf39/IzQ01OjVq5cxYcIEo6SkpPq4oqIi4+abbzbCw8ON0NBQY9iwYcaePXuOeSn43r17j/kz3333XQMwQkNDjeLi4qMe8+effxqDBw+ufu3NmjUzhg0bZvz8888n/NpEvInFMP7fGLSIiIiIG9OcGxEREfEoKjciIiLiUVRuRERExKOo3IiIiIhHUbkRERERj6JyIyIiIh7F6xbxczqdZGZmEhoaesw9YkRERMS1GIZBfn4+sbGx1Yt7HovXlZvMzEzi4uLMjiEiIiKnID09nSZNmhz3GK8rN6GhoUDlH05YWJjJaURERORE2O124uLiqj/Hj8fryk3VqaiwsDCVGxERETdzIlNKNKFYREREPIrKjYiIiHgUlRsRERHxKCo3IiIi4lFUbkRERMSjqNyIiIiIR1G5EREREY+iciMiIiIeReVGREREPIrKjYiIiHgUlRsRERHxKCo3IiIi4lFUbmrQ/oJStuTkmx1DRETEq6nc1JB563Po+sw8/v1ZitlRREREvJrKTQ1pEx0KwKbsfMoqnCanERER8V4qNzUkLjKQ0ABfyh0GW/bo1JSIiIhZVG5qiMViITE2DIB1mXaT04iIiHgvlZsalBQbDsC6jDyTk4iIiHgvlZsalNhYIzciIiJmU7mpQYmHRm7WZ9lxOg2T04iIiHgnlZsa1KJBMAF+VorKHKTtLzQ7joiIiFdSualBvj5WEhrp1JSIiIiZVG5qWFLVvBtNKhYRETGFyk0Nq5p3o5EbERERc6jc1LC/1rrJwzA0qVhERKSuqdzUsDbRofhaLRwsKiczr8TsOCIiIl5H5aaGBfj50CoqBNC8GxERETOo3NSCpMaV825SNe9GRESkzqnc1IKqeTfrMzVyIyIiUtdUbmqBrpgSERExj8pNLWh/aOQmK6+E/QWlJqcRERHxLio3tSDE5kt8g2BAozciIiJ1TeWmlrSP1TYMIiIiZlC5qSVJsVVXTGlSsYiISF1Suaklf10xpZEbERGRuqRyU0uqyk3avkLyS8pNTiMiIuI9VG5qSf0QGzHhAQBsyMo3OY2IiIj3ULmpRX/fRFNERETqhspNLapazC81Q/NuRERE6orKTS3SyI2IiEjdU7mpRVUbaG7ZU0BJucPkNCIiIt5B5aYWxYQHUC/ID4fTYHOOJhWLiIjUBZWbWmSxWLSJpoiISB1TualliY0r592kZmjejYiISF1QuallGrkRERGpWyo3tSzp0BVTG7LsVDicJqcRERHxfCo3tax5/WCC/X0orXCyfV+h2XFEREQ8nspNLbNaLbSL0Xo3IiIidUXlpg5UrXejlYpFRERqn8pNHWivlYpFRETqjMpNHUj62xVThmGYnEZERMSzqdzUgdbRIfj7WMkvqSD9QLHZcURERDyayk0d8POx0qZRCKBTUyIiIrVN5aaOVJ2aSlW5ERERqVUqN3UksXpSsa6YEhERqU0qN3WkvbZhEBERqRMqN3WkXUwoVgvszS9lj73E7DgiIiIeS+WmjgT5+9KiYdWkYo3eiIiI1BaVmzpUtYlmaoYmFYuIiNQWlZs6lKh5NyIiIrVO5aYOVV8xlaWRGxERkdqiclOHqkZu0g8Uk1dUbnIaERERz6RyU4fCg/xoUi8Q0OiNiIhIbVG5qWNVKxWv17wbERGRWqFyU8cSdcWUiIhIrVK5qWOJjbUNg4iISG1SualjVaeltu0toLjMYXIaERERz2NquVm0aBEDBw4kNjYWi8XC7Nmzj3v8L7/8gsViOeKWnZ1dN4FrQFRYAA1CbDgN2JCt0RsREfEsZRVO8kvMvSLY1HJTWFhIcnIyEydOPKnnbdq0iaysrOpbVFRULSWsHUk6NSUiIh6m3OHkk+W76PvSL7z842ZTs/ia+cMHDBjAgAEDTvp5UVFRRERE1HygOpIYG8Yvm/ayTpOKRUTEzZU7nHy5KoMJC7aQfqAYgHkbcnj04nb4+5ozhmJquTlVnTp1orS0lKSkJMaOHUuvXr2OeWxpaSmlpaXVX9vt5o+WaBsGERFxdxUOJ1/+mcGE+VvZdaAIgAYhNu44tyUjzmxqWrEBNys3MTExvP3223Tr1o3S0lLee+89zj33XJYtW0aXLl2O+pxx48bx1FNP1XHS46uaVLwpO59yhxM/H83rFhER91DhcPJVSiYT5m9hx/7KUlM/2P9QqWlGoL+PyQnBYhiGYXYIAIvFwpdffsmgQYNO6nl9+vShadOmfPjhh0d9/GgjN3FxceTl5REWFnY6kU+ZYRh0fOpH8ksqmHPP2bSPNSeHiIjIiXI4Db5encEbP28lbV8hAJHB/tx2Tguu69GMIP/aHS+x2+2Eh4ef0Oe3W43cHE337t1ZvHjxMR+32WzYbLY6TPTPLBYL7WPCWJZ2gHWZeSo3IiLishxOg2/XZPL6z1vYvrey1NQL8uPWc1pyfY9mBNtcr0q4XqKTlJKSQkxMjNkxTlpS4/BD5cbOlWaHERER+X+cToNv12bxxs9b2LqnAICIID/+dXYLRvZsTogLlpoqpiYrKChg69at1V+npaWRkpJCZGQkTZs2ZcyYMWRkZDBt2jQAXnvtNeLj40lMTKSkpIT33nuP+fPn8+OPP5r1Ek5Z1TYM6zJ1xZSIiLgOp9NgTmoWr8/bwpZDpSY80I9/nR3PyJ7NCQ3wMznhPzO13KxcuZK+fftWf33//fcDMHLkSKZOnUpWVha7du2qfrysrIwHHniAjIwMgoKC6NixI/PmzTvse7iLpMZ/baDpdBpYrRaTE4mIiDdzOg1+WJfN6/O2sCknH4CwAF9uObsFN/RqTpgblJoqLjOhuK6czISk2lThcJL45FxKK5zMf6APLRqGmJZFRES8l9Np8OP6bF6bt4WN2ZWlJtTmy81nx3Njr3jCA12j1HjVhGJ35etjJSEmjNXpuazLtKvciIhInTIMg5/W5/DavC2sz6pcdy3E5stNvZpzc+8WhAe5Rqk5FSo3JkqKrSw3qZl5DEyONTuOiIh4AcMw+HnDHl77eTOpGZWlJtjfhxt7xXPL2fFEBPmbnPD0qdyYqGql4vVaqVhERGqZYRgs2LSH1+ZtYc3uyotZgv19GNmzOf86uwX1gt2/1FRRuTHR3zfQNAwDi0WTikVEpGYZhsEvm/fy2rwtrE7PBSDI34frezTn1nNaEOlBpaaKyo2J2kSH4mO1cKCwjKy8EmIjAs2OJCIiHsIwDBZt2cerP20m5VCpCfTz4foezbj1nBbUD3GtBW5rksqNiQL8fGgdFcLG7HzWZdpVbkRE5LQZhsHirZWlZtWuXAAC/Kxcd1YzbuvTkgYeXGqqqNyYLDE2nI3Z+aRm5HFB+2iz44iIiJsyDIPftu3ntXmbWbHjIAA2XyvXntWM2/q0ICo0wOSEdUflxmSJsWF8vqpy3o2IiMipWLptP6/O28zytAMA+PtaGXFmU+7o05KoMO8pNVVUbkz210rF2oZBREROzrLtlaXm9+2HSo2Plau7x3HHua1oFO59paaKyo3J2sWEApCZV8KBwjKPnLUuIiI1a8WOA7z602Z+27YfqCw1w8+I486+LYkJ1/xNlRuThQb40bx+EDv2F7EuM4+zWzc0O5KIiLioP3Ye4NWftrB46z4A/HwsDOsWx6i+rXRRyt+o3LiAxMbhh8qNXeVGRESOsGrXQV79aTO/bqksNb5WC1d2i2NU35Y0qRdkcjrXo3LjAhJjw/huTRapGZp3IyIif0lJz+XVnzazcPNeoLLUDO3ahFF9WxEXqVJzLCo3LiBJ2zCIiMjfrNldWWoWbKosNT5WC0O6NOauvq1pWl+l5p+o3LiAxNjKbRi27yukoLSCEJveFhERb7R2dx6vzdvMzxv3AJWl5orOjbn7vFY0qx9scjr3oU9RF1A/xEajsACy7SVsyLJzRvNIsyOJiEgd2ldQyqNfrOXH9TkAWC0wqHNj7jmvNc0bqNScLJUbF5HUOIxsewnrMvJUbkREvEhRWQU3TV3Bmt15WC1weafKkZoWDUPMjua2VG5cRPvYcOZt2EOq5t2IiHiNCoeTu6f/yZrdedQL8mP6v86iXUyY2bHcntXsAFKpat6NtmEQEfEOhmHw5Nfr+HnjHmy+Vt4beYaKTQ1RuXERVdswbMnJp7TCYXIaERGpbW8v3M7Hy3ZhscDrV3Wia7N6ZkfyGCo3LiI2PICIID8qnAabswvMjiMiIrXoq5QMxv+wEYDHL2lP/6QYkxN5FpUbF2GxWKrXu1mnTTRFRDzW79v3M3rmGgBu7h3PTb3jTU7keVRuXEjVvJtUlRsREY+0JSefW6etpMzhZEBSIx67uJ3ZkTySyo0Laa9JxSIiHivHXsINU1ZgL6mga7N6vDq8E1arxexYHknlxoVUTSrekGXH4TRMTiMiIjWloLRyLZuM3GLiGwTz3vXdCPDzMTuWx1K5cSHx9YMJ8vehpNzJ9r2aVCwi4gnKHU5GfbyKdZl26gf7M/XGM6gX7G92LI+mcuNCrFYL7WN0akpExFMYhsHjs1NZuHkvAX5W3r/hDO0RVQdUblxM9aTiDE0qFhFxd2/O38onK9KxWmDC1V3oFBdhdiSvoHLjYhKrLwfXyI2IiDv7/I/dvPzTZgCeuiyRC9pHm5zIe6jcuJjExlWnpfIwDE0qFhFxR0u27uPhzyvXsrmtTwuu69Hc3EBeRuXGxbSOCsXPx4K9pILdB4vNjiMiIidpY7ad2z/8gwqnwcDkWB6+KMHsSF5H5cbF+PtaadsoFNBKxSIi7iYrr5gbPlhBfmkF3eMjeenKjlrLxgQqNy4oMaZy3k1qhubdiIi4i/yScm6csoJsewktGwYz+bqu2Hy1lo0ZVG5c0N/n3YiIiOsrdzi546NVbMzOp2Gojak3diciSGvZmEXlxgXpiikREfdhGAaPfL6WxVv3EeTvwwcjzyAuMsjsWF5N5cYFtYsJxWKBPfml7MkvMTuOiIgcx6vztvD5qt34WC1MvKYLHZqEmx3J66ncuKAgf19aNKhcwVKjNyIiruuzFem88fMWAP57eRJ9E6JMTiSgcuOyqjbRXKeVikVEXNLCzXsZ8+VaAEb1bck1ZzY1OZFUUblxUVXbMGjkRkTE9azLzOPOj/7A4TS4onNjHrywrdmR5G9UblxUkiYVi4i4pIzcYm6csoLCMgc9WtRn/JCOWCxay8aVqNy4qPaHRm52HSgir7jc5DQiIgKQV1zOjVOWsye/lDbRIbx9XVf8ffVR6mr0jrioiCB/GkcEArBeozciIqYrrXBw+4d/sDmngOiwyrVswgP9zI4lR6Fy48KStJifiIhLMAyDh2etYen2/QT7+/DBDWcQe+gfoOJ6VG5cmBbzExFxDS/9uInZKZn4WC1MurZr9e9ncU0qNy5MIzciIuabvmwXExdsA2Dc4A6c06ahyYnkn6jcuLCqfxls3VNAcZnD5DQiIt5nwcY9/Gd25Vo29/ZrzbBucSYnkhOhcuPCokJtNAjxx2nAxmydmhIRqUtrd+cxavoqnAYM7dqE+85vbXYkOUEqNy7MYrFo3o2IiAnSDxRx49QVFJU5OLt1A8YN7qC1bNyIyo2L+2ulYs27ERGpC7lFZdwwZTn7CkpJaBTKWyO64Oejj0t3onfLxVXvMaWRGxGRWldS7uDWaX+wbW8hMeEBTL2xO6EBWsvG3ajcuLiqkZuNWfmUO5wmpxER8VxOp8GDM1ezfMcBQm2+TLnxDBqFB5gdS06Byo2Li6sXRKjNlzKHk617CsyOIyLiscb/sJFv12Th52Phneu6ktAozOxIcopUblyc1Wqp3mdKp6ZERGrHtKU7eGfRdgDGD+lIz1YNTE4kp0Plxg1UXTGVmqFJxSIiNe2n9TmM/XodAA9e2IbBXZqYnEhOl8qNG6haqVgbaIqI1Kw/dx3k7hmVa9lcdUYco/q2MjuS1ACVGzdQNXKzPsuO02mYnEZExDPs3F/ILf9bSUm5kz5tGvLMoCStZeMhVG7cQMuGwdh8rRSUVrDzQJHZcURE3N6BwjJumLKC/YVlJMaGMXFEF3y1lo3H0DvpBnx9rCTEaDE/EZGaUFLu4F/TVpK2r5DGEYFMueEMQmy+ZseSGqRy4yaq1rtJzdC8GxGRU+VwGvz70xT+2HmQsABfpt54BlFhWsvG06jcuAltwyAicvqe/W4D36dm4+9jZfL13WgdHWp2JKkFKjduIqlqUnGmHcPQpGIRkZP1/uI0PliSBsCLV3bkrBb1TU4ktUXlxk20bRSKj9XC/sIysu0lZscREXEr36/N4pnv1gPwcP8ELu/U2OREUptUbtxEgJ8PraNCAFineTciIifsj50HuO/TFAwDrj2rKbf3aWF2JKllKjdupGobhlTNuxEROSHb9xZwy/9WUlrh5Px2UYwdmKi1bLyAyo0bqVrMT3tMiYj8s30FpdwwZQUHi8pJbhLOG1d31lo2XkLvshtJitU2DCIiJ6K4zMHN/1vJrgNFxEUG8t7IMwjy11o23kLlxo1UnZbKyC3mYGGZyWlERFyTw2lwzyd/sjo9l4ggP6be2J2GoTazY0kdUrlxI6EBfjSvHwTo1JSIyNEYhsFT36zjp/U5+Ptaee/6brRsGGJ2LKljKjdu5q95N5pULCLy/73763amLd2JxQKvDe9Et+aRZkcSE6jcuJm/rpjSyI2IyN99uyaT5+ZsBOCxi9txcYcYkxOJWUwtN4sWLWLgwIHExsZisViYPXv2CT93yZIl+Pr60qlTp1rL54qSGmvkRkTk/1uedoD7P10NwA09m3Nz73iTE4mZTC03hYWFJCcnM3HixJN6Xm5uLtdffz39+vWrpWSuq2qPqbR9hRSWVpicRkTEfFv35POvaSspczi5KDGaxy9tr7VsvJyp18UNGDCAAQMGnPTzbr/9dq655hp8fHxOarTHEzQIsdEoLIBsewkbsuw6nywiXi3HXsINU1aQV1xO56YRvH5VZ3ysKjbezu3m3EyZMoXt27fz5JNPntDxpaWl2O32w27u7q8dwt3/tYiInKo/dh5k4ITF7D5YTPP6Qbx3fTcC/HzMjiUuwK3KzZYtW3jkkUf46KOP8PU9sUGncePGER4eXn2Li4ur5ZS1r6rcpGZo3o2IeB/DMPjo951cNXkpe/JLaR0VwrSbzqR+iNaykUpuU24cDgfXXHMNTz31FG3atDnh540ZM4a8vLzqW3p6ei2mrBuJjbUNg4h4p5JyBw9/vob/zE6l3GFwcYdGfDmqF00PrQEmAibPuTkZ+fn5rFy5kj///JO77roLAKfTiWEY+Pr68uOPP3Leeecd8TybzYbN5lltvmrkZnNOPqUVDmy+GoYVEc+XmVvMHR/9werdeVgtMPqiBG7v00KTh+UIblNuwsLCWLt27WH3vfXWW8yfP59Zs2YRH+89l/01jggkIsiP3KJytuQUVF8eLiLiqX7fvp9RH69if2EZEUF+vHFVZ85p09DsWOKiTC03BQUFbN26tfrrtLQ0UlJSiIyMpGnTpowZM4aMjAymTZuG1WolKSnpsOdHRUUREBBwxP2ezmKxkBgbxpKt+1mXmadyIyIeyzAMpizZwbNzNuBwGrSLCWPydV2Ji9RpKDk2U+fcrFy5ks6dO9O5c2cA7r//fjp37swTTzwBQFZWFrt27TIzosuq2oYhNUPzbkTEMxWXOfj3pyk8/e16HE6DQZ1i+eKOnio28o8shmEYZoeoS3a7nfDwcPLy8ggLCzM7zin7KiWDez9JoUvTCL64s5fZcUREalT6gSJu+/AP1mfZ8bFaePTidtzUq7nm13ixk/n8dps5N3K4qpGbDVn5OJyGFq0SEY+xaPNe7vnkT3KLyqkf7M+b13ShR8v6ZscSN6Jy46biGwQT6OdDcbmDtH0FtIoKNTuSiMhpMQyDtxdu58W5G3Ea0LFJOG9f25XYiECzo4mbcZt1buRwPlZL9Q7hWu9GRNxdYWkFo6avYvwPlcVmWLcmfHZbDxUbOSUqN25MKxWLiCdI21fIoIlLmLM2Gz8fC88MSmL8kI7aSkFOmU5LubGkWK1ULCLu7ecNOdz3aQr5JRVEhdqYdG0XujbThsByelRu3NjfT0sZhqGrCETEbTidBm/M38Jr87YA0LVZPSaN6EJUWIDJycQTqNy4sTbRofj5WMgrLmf3wWKt/SAibsFeUs79n6Ywb8MeAK47qxmPX9oef1/NlJCaoXLjxvx9rbSJDmVdpp11mXaVGxFxeVty8rntwz/Yvq8Qf18rzwxKYli3OLNjiYdRTXZzidWnpjSpWERc2/drsxg0cQnb9xUSGx7ArNt7qNhIrVC5cXNV+0ppUrGIuCqH0+CFHzZyx8erKCxzcFaLSL6+uzcdm0SYHU08lE5LuTmN3IiIK8stKuOeT1JYtHkvALf0jueRAQn4+ujf1lJ7TqncpKenY7FYaNKkCQDLly9n+vTptG/fnltvvbVGA8rxJTQKw2KBHHspe/NLaRhqMzuSiAgA6zPt3PbRStIPFBPgZ2X8kI5c3qmx2bHEC5xSdb7mmmtYsGABANnZ2VxwwQUsX76cxx57jKeffrpGA8rxBdt8adEgGNDojYi4jq9SMhg8aQnpB4qJiwzkizt6qdhInTmlcpOamkr37t0B+Oyzz0hKSuK3337j448/ZurUqTWZT05AohbzExEXUeFw8t9v13PvJymUlDs5u3UDvrmrd/W6XCJ14ZTKTXl5OTZb5emPefPmcdlllwGQkJBAVlZWzaWTE5LUWPNuRMR8+wpKufb9Zby/OA2AO89tydQbuxMR5G9yMvE2p1RuEhMTefvtt/n111/56aef6N+/PwCZmZnUr69t6euaRm5ExGyr03O5bMJift9+gGB/H96+tgsP9U/Ax6qV06XunVK5GT9+PO+88w7nnnsuV199NcnJyQB8/fXX1aerpO5UXTG1c38R9pJyk9OIiLf5bGU6V76zlMy8EuIbBDN7VC/6J8WYHUu82CldLXXuueeyb98+7HY79erVq77/1ltvJShIq+TWtYggfxpHBJKRW8z6TDtntdDomYjUvrKKyvk1H/6+E4Dz20XxyvBOhAX4mZxMvN0pjdwUFxdTWlpaXWx27tzJa6+9xqZNm4iKiqrRgHJiEv+2iaaISG3bYy/hmnd/ry42/z6/DZOv66ZiIy7hlMrN5ZdfzrRp0wDIzc3lzDPP5OWXX2bQoEFMmjSpRgPKiamed5OhScUiUrv+2HmASycsZuXOg4QG+PL+yG7ce35rrJpfIy7ilMrNqlWrOPvsswGYNWsW0dHR7Ny5k2nTpvHGG2/UaEA5MX9dMaWRGxGpHYZh8OHvO7lq8u/syS+ldVQIX9/Vm37tos2OJnKYU5pzU1RURGhoKAA//vgjgwcPxmq1ctZZZ7Fz584aDSgnpmrkZuveAkrKHQT4+ZicSEQ8SUm5gye+SuWzlbsBuLhDI14cmkywTbv4iOs5pZGbVq1aMXv2bNLT05k7dy4XXnghAHv27CEsTAs1mSE6zEaDEH8cToON2flmxxERD5KZW8zwd5by2crdWC3wcP8EJl7TRcVGXNYplZsnnniCBx98kObNm9O9e3d69OgBVI7idO7cuUYDyomxWCy0r17vRvNuRKRmLN22n4ETFrN6dx4RQX7876bu3HFuSywWza8R13VKtXvo0KH07t2brKys6jVuAPr168cVV1xRY+Hk5CTGhrFo815SMzTvRkROj2EYfLBkB8/N2YDDadA+Jox3rutKXKSW+xDXd8pjio0aNaJRo0bs3l15/rVJkyZawM9kSYdGbtZr5EZETkNxmYNHvljDVymZAAzqFMu4wR0J9NdcPnEPp3Rayul08vTTTxMeHk6zZs1o1qwZERER/Pe//8XpdNZ0RjlBVWvdbMjOp9yh90FETl76gSIGT/qNr1Iy8bFaeOLS9rw6vJOKjbiVUxq5eeyxx3j//fd5/vnn6dWrFwCLFy9m7NixlJSU8Oyzz9ZoSDkxTSODCLX5kl9awba9BSQ00uRuETlxizbv5Z5P/iS3qJz6wf68eU0XerTUiufifk6p3Pzvf//jvffeq94NHKBjx440btyYO++8U+XGJFarhXaxYSxPO8C6DLvKjYicEMMwmLRwGy/N3YTTgOQm4Uy6tiuxEYFmRxM5Jad0WurAgQMkJCQccX9CQgIHDhw47VBy6qpOTaVq3o2InICC0gpGTV/FCz9UFpth3Zrw6W09VGzErZ1SuUlOTubNN9884v4333yTjh07nnYoOXVJ1ZeD64opETm+7XsLuGLiEuaszcbPx8Izg5IYP6SjFgEVt3dKp6VeeOEFLrnkEubNm1e9xs3SpUtJT09nzpw5NRpQTk7ioW0YNmTacToN7fUiIkc1Z20WD89aQ35pBVGhNiZd25WuzeqZHUukRpzSyE2fPn3YvHkzV1xxBbm5ueTm5jJ48GDWrVvHhx9+WNMZ5SS0ahiCzddKfmkFuw4UmR1HRFzMwcIy7p7xJ3d+vIr80gq6NavHt3f3VrERj2IxDMOoqW+2evVqunTpgsPhqKlvWePsdjvh4eHk5eV57FYRl79ZuZroxGu6cEnHGLPjiIiLmLc+hzFfrmVvfik+Vgt39GnJPf1a4+97Sv/OFalTJ/P5rY1BPFD72HBW784jNTNP5UZEyCsu5+lv1vP5qspFV1tFhfDylckkx0WYG0yklqjceKCkQ/NuNKlYRH7ZtIdHPl9Ltr0EiwX+dXYL7r+gjSYNi0dTufFAiVVXTGXkYRiGNrgT8UIFpRU8+916ZixPB6B5/SBeHpZM12aRJicTqX0nVW4GDx583Mdzc3NPJ4vUkIRGofhYLewvLCPHXkqj8ACzI4lIHfpt6z5Gz1pDRm4xADf0bM7D/RO0hYJ4jZMqN+Hh4f/4+PXXX39ageT0Bfj50KphCJty8lmXmadyI+IlisoqeP77jUxbuhOAJvUCeXFosrZQEK9zUuVmypQptZVDalhibBibcvJJzbDTr1202XFEpJat2HGAB2euZuf+yiUgrjmzKY9e3I4Qm2YfiPfR/+s9VGLjcL74M4N12oZBxKOVlDt4ae4m3l+ShmFATHgA44d05Jw2Dc2OJmIalRsPVbXHlK6YEvFcf+46yIMzV7NtbyEAQ7s24fFL2xMe6GdyMhFzqdx4qPaHyk1GbjEHC8uoF+xvciIRqSmlFQ5en7eFtxduw2lAw1Abzw/uoFPQIoeo3HiosAA/mtUPYuf+ItZn2enVqoHZkUSkBqRm5PHgzNVszM4H4PJOsYwdmKh/wIj8jcqNB0uMDWPn/iLWZeap3Ii4uXKHk4kLtvLm/K1UOA3qB/vzzKAkBnTQKuQi/5/KjQdLjA1nztpsUjM070bEnW3KzueBmSnVf5cHJDXiv4OSaBBiMzmZiGtSufFgf00q1hVTIu6owuHknUXbeX3eFsocTsID/Xj68kQuS47VyuMix6Fy48GqtmHYvq+QwtIKgrXehYjb2LqngAdnriYlPReA89tF8dwVHYgK06KcIv9En3YerGGojegwGzn2UjZm27WnjIgbcDgNpixJ48W5myitcBIa4MuTAxMZ0qWxRmtETpDKjYdLjA0nx76HdZkqNyKubuf+Qh6cuZoVOw4CcHbrBrwwtCMx4YEmJxNxLyo3Hi4pNoz5G/eQmqF5NyKuyuk0+GjZTsbN2UhxuYNgfx8eu6Q9V3eP02iNyClQufFw7Q/Nu9FKxSKuKf1AEQ9/vobftu0H4KwWkbw4NJm4yCCTk4m4L5UbD1d1xdTmnHzKKpz4+1pNTiQiAIZh8MmKdJ75dj2FZQ4C/Kw80j+B63s0x2rVaI3I6VC58XBN6gUSHuhHXnE5m3PySWocbnYkEa+XlVfMI5+vZeHmvQB0bVaPl65MJr5BsMnJRDyDyo2Hs1gsJMaG8du2/azPtKvciJjIMAy+WJXB2G/WkV9Sgb+vldEXtuWm3vH4aLRGpMao3HiBpMbh/LZtP6mZeQwjzuw4Il5pT34Jj36RyrwNOQAkNwnn5WHJtIoKNTmZiOdRufECf61UrEnFImb4ZnUmj3+VSm5ROX4+Fu47vw23ndMCXx/NgROpDSo3XqCq3KzPtONwGhr+Fqkj+wtKeeKrdXy3NguA9jFhvDwsmXYxYSYnE/FsKjdeIL5BCIF+PhSXO0jbV0irqBCzI4l4vB9Ss/nP7LXsKyjD12phVN9W3HVeK/w0WiNS61RuvICP1UK7mFBW7cplXWaeyo1ILcorKufJr1OZnZIJQJvoEF4Z1kmT+UXqkP4J4SUStZifSK1bsHEPF7y6kNkpmVgtcMe5Lfnm7t4qNiJ1TCM3XiKpcdWkYm3DIFLT7CXlPPPtej5buRuAFg2DeenKZLo0rWdyMhHvpHLjJf4+cmMYhvarEakhi7fs46FZq8nMK8FigZt6xTP6orYE+PmYHU3Ea6nceInW0SH4+VjILSonI7eYJvW0b43I6SgsrWDc9xv46PddADSNDOKlK5PpHh9pcjIRUbnxEjZfH1pHhbI+y866TLvKjchpWLZ9P6NnrWHXgSIArjurGY8MSCDYpl+pIq5AE4q9SPVifhmadyNyqv732w6uevd3dh0oonFEIB/fcib/HZSkYiPiQlRuvEjVFRu6Ykrk1OTYSxj3/QYMA4Z1a8IP951Nr1YNzI4lIv+P/qnhRbQNg8jpeeXHzZSUO+narB7jh3TUxHwRF6WRGy/SLiYMiwWy7SXsKyg1O46IW9mUnc/MP9IBePTiBBUbERdmarlZtGgRAwcOJDY2FovFwuzZs497/OLFi+nVqxf169cnMDCQhIQEXn311boJ6wGCbb7ENwgGNHojcrLG/7ARpwH9ExvRtZmuiBJxZaaWm8LCQpKTk5k4ceIJHR8cHMxdd93FokWL2LBhA//5z3/4z3/+w+TJk2s5qeeoWu8mVZOKRU7Yb9v2MX/jHnytFh7q39bsOCLyD0ydczNgwAAGDBhwwsd37tyZzp07V3/dvHlzvvjiC3799VduvfXW2ojocZJiw/hmdSbrNXIjckKcToNxczYCcM2ZTWnRUHuzibg6t55z8+eff/Lbb7/Rp0+fYx5TWlqK3W4/7ObN/lqpWCM3IifimzWZrM3II8Tmyz39WpsdR0ROgFuWmyZNmmCz2ejWrRujRo3illtuOeax48aNIzw8vPoWFxdXh0ldT9UVUzv2F2EvKTc5jYhrK61w8OLcTQDc3qcFDUJsJicSkRPhluXm119/ZeXKlbz99tu89tprzJgx45jHjhkzhry8vOpbenp6HSZ1PfWC/WkcEQjABp2aEjmuD5fuZPfBYqLDbNzcu4XZcUTkBLnlOjfx8fEAdOjQgZycHMaOHcvVV1991GNtNhs2m/619XftY8PIyC1mXaadM1vUNzuOiEvKKypnwvytADxwQVsC/bURpoi7cMuRm79zOp2UlmrNlpORVHXFlObdiBzTxF+2kldcTpvoEIZ0bWJ2HBE5CaaO3BQUFLB169bqr9PS0khJSSEyMpKmTZsyZswYMjIymDZtGgATJ06kadOmJCQkAJXr5Lz00kvcc889puR3V1XzbnTFlMjRpR8oYuqSHQCMGdAOH6sW7BNxJ6aWm5UrV9K3b9/qr++//34ARo4cydSpU8nKymLXrl3VjzudTsaMGUNaWhq+vr60bNmS8ePHc9ttt9V5dndWtcfUlj0FlJQ7CPDTcLvI37384ybKHE56tqzPuW0bmh1HRE6SxTAMw+wQdclutxMeHk5eXh5hYWFmxzGFYRh0e2Ye+wvL+GpUL5LjIsyOJOIyUjPyuHTCYgC+uas3HZqEm5xIRODkPr/dfs6NnDyLxUJ7baIpcgTDMHhuzgYALu8Uq2Ij4qZUbrxU1akpTSoW+csvm/fy27b9+PtYefBCbbMg4q5UbrxUokZuRA7jcBo8f2ibhZE9mxEXGWRyIhE5VSo3XqpqG4aNWXYqHE6T04iY7/NVu9mUk09YgC+j+rYyO46InAaVGy/VLDKIEJsvpRVOtu0tNDuOiKmKyxy8/GPlNgt3n9eaiCB/kxOJyOlQufFSVquF9jFVp6Y070a82wdL0sixl9I4IpDrejQzO46InCaVGy+W2Liy3KRmaN6NeK99BaVM+mUbAKMvaqt1n0Q8gMqNF6uad6ORG/FmE37eQkFpBUmNw7gsOdbsOCJSA1RuvNjft2FwOr1qLUcRANL2FfLxsspV0B8d0A6rtlkQ8QgqN16sVVQI/r5W8ksrSD9YZHYckTr3wg8bqXAa9G3bkJ6tGpgdR0RqiMqNF/PzsZLQKBTQejfiff7YeZDvU7OxWuCRAe3MjiMiNUjlxstVzbtJzdC8G/EehmEw7tA2C0O7NqHtoZIvIp5B5cbLaaVi8UZz1+WwcudBAvys3H+BtlkQ8TQqN17ur3KTh5dtEC9eqtzh5IUfKrdZuKV3CxqFB5icSERqmsqNl2sXE4aP1cK+gjL25JeaHUek1n2yIp3t+wqpH+zPbX1amB1HRGqByo2XC/DzoWXDYEDr3YjnKyit4PV5mwG49/zWhAb4mZxIRGqDyo2QVD2pWPNuxLNNXriNfQVlxDcI5uruTc2OIyK1ROVGaB+rPabE8+XYS3j31zQAHrqoLX4++vUn4qn0t1v+tg2DRm7Ec73602aKyx10aRpB/6RGZscRkVqkciPVIze7DxaTW1RmchqRmrc5J5/PVqYD8OjF7bBYtM2CiCdTuRHCA/1oGhkEVO4zJeJpnv9+I04DLkqMplvzSLPjiEgtU7kRQIv5ief6bds+5m/cg4/VwsP9E8yOIyJ1QOVGAEhqfOiKKU0qFg/idBo8/33lgn3XdG9Ki4YhJicSkbqgciPA36+Y0siNeI5v1mSyZncewf4+3Ht+a7PjiEgdUbkR4K+1brbtLaCorMLkNCKnr7TCwYtzNwFwe5+WNAixmZxIROqKyo0A0DDURlSoDcOADVn5ZscROW0fLt3J7oPFRIXauPnseLPjiEgdUrmRalWTitdr3o24ubyicibM3wrAAxe2Icjf1+REIlKXVG6kWvWkYm3DIG7urV+2kldcTpvoEIZ0aWJ2HBGpYyo3Uq36cvAsjdyI+9p9sIgpv+0A4JEBCfhqmwURr6O/9VKtahuGTdn5lFU4TU4jcmpe/nEzZRVOerSoT9+2UWbHERETqNxItSb1AgkP9KPcYbBljyYVi/tJzcjjyz8zABhzcYK2WRDxUio3Us1isdA+RuvdiHsyDINx328A4LLkWDo2iTA3kIiYRuVGDpPU+FC5ydC8G3EvCzfvZcnW/fj7WBl9UVuz44iIiVRu5DBV8240ciPuxPG3bRau79GMuEMbwYqId1K5kcNUXQ6+JiOPXfuLTE4jcmI+X7Wbjdn5hAX4ctd5rcyOIyImU7mRw7RsGEyPFvUpq3Dy8OdrMAzD7Egix1Vc5uCVHzcDcNd5rYgI8jc5kYiYTeVGDmOxWBg/pCOBfj4s3b6fGcvTzY4kclwfLEkj215C44hAru/R3Ow4IuICVG7kCE3rB/FQ/8oJmc/N2UBmbrHJiUSObn9BKZN+2QbA6IvaEuDnY3IiEXEFKjdyVCN7NKdbs3oUlFYw5ou1Oj0lLmnC/K0UlFaQGBvGZcmxZscRERehciNHZbVaGD+0I/6+VhZu3svnqzLMjiRymB37Cvno950APHpxO6xWLdgnIpVUbuSYWjYM4f4L2gDw9Dfr2GMvMTmRyF9emLuRCqfBuW0b0qtVA7PjiIgLUbmR47qldzwdm4RjL6ngsdmpOj0lLmHVroPMWZuNxVK5OaaIyN+p3Mhx+fpYeWFoR/x8LPy0Podv12SZHUm8nGEYPPdd5TYLQ7s0IaFRmMmJRMTVqNzIP0poFMZdfVsD8OTX69hfUGpyIvFmP67PYeXOgwT4Wbn/wjZmxxERF6RyIyfkjnNbktAolAOFZYz9Zr3ZccRLlTucjD+0zcLNveOJCQ80OZGIuCKVGzkh/r5WXhyajI/VwjerM5m7LtvsSOKFPlmRzvZ9hUQG+3Nbn5ZmxxERF6VyIyesQ5NwbjunBQD/mZ1KXlG5yYnEmxSUVvD6vMptFu7t15qwAD+TE4mIq1K5kZNyT7/WtIoKYW9+Kf/9TqenpO5MXrSdfQVlNK8fxNXdm5odR0RcmMqNnJQAPx9eGNoRiwVm/bGbBZv2mB1JvECOvYR3F20H4KH+Cfj76leXiBybfkPISevStB4394oH4NEv1pJfotNTUrtem7eZ4nIHnZtGMCCpkdlxRMTFqdzIKXngwrY0qx9EVl4J4w5dvSJSG7bk5PPpisrd6R+7uB0Wi7ZZEJHjU7mRUxLo78P4IR0BmL5sF79t3WdyIvFUz3+/EacBFyVG0615pNlxRMQNqNzIKTurRX2uO6sZAA9/sYaisgqTE4mnWbptPz9v3IOP1cJD/bXNgoicGJUbOS0PD0igcUQg6QeKeXHuJrPjiAdxOg3GfV+5zcLV3eNo2TDE5EQi4i5UbuS0hNh8GTe4AwBTf9vByh0HTE4knuLbtVms2Z1HsL8P9/bTNgsicuJUbuS0ndOmIcO6NcEw4KFZaygpd5gdSdxcaYWDF+dWTlS/rU9LGobaTE4kIu5E5UZqxGOXtCcq1Mb2fYW8Nm+L2XHEzX24dCfpB4qJCrVxy9nxZscRETejciM1IjzQj+euqDw9NXnRNlan55obSNxWXlE5E+ZvBeD+C9oQ5O9rciIRcTcqN1Jjzm8fzaBOsTgPnZ4qrdDpKTl5by3cSl5xOa2jQhjatYnZcUTEDancSI16cmAiDUL82ZSTz8QF28yOI25m98EipizZAcAjAxLw9dGvKBE5efrNITWqXrA/T1+eBMBbC7ayPtNuciJxJ6/8uJmyCidntYjkvIQos+OIiJtSuZEad3GHGAYkNaLCaTB61mrKHU6zI4kbSM3I48uUDADGDNA2CyJy6lRupFY8dXkiEUF+rMu0M/nQbs4ix2IYBs9/vxHDgIHJsSTHRZgdSUTcmMqN1Iqo0ACeHNgegNfnbWHrnnyTE4krW7RlH4u37sPPx8JDF7U1O46IuDmVG6k1gzo15ryEKMocTkbPWoPDaZgdSVyQw2kwbk7lNgvX92hOXGSQyYlExN2p3EitsVgsPHtFEqE2X/7clcuUJWlmRxIX9MWq3WzMzicswJe7z2tldhwR8QAqN1KrYsIDeeySdgC89OMmduwrNDmRuJKScgcv/7gZgFF9WxER5G9yIhHxBCo3UuuGnxFH71YNKCl38vDna3Dq9JQc8v7iNLLtJTSOCGRkz+ZmxxERD6FyI7XOYrEwbnAHgvx9WJZ2gI+X7TQ7kriA/QWlTPqlcqHHBy9qQ4Cfj8mJRMRTqNxInYiLDOKRAQkAjPt+I+kHikxOJGabMH8rBaUVtI8J4/LkxmbHEREPYmq5WbRoEQMHDiQ2NhaLxcLs2bOPe/wXX3zBBRdcQMOGDQkLC6NHjx7MnTu3bsLKabv2zGZ0bx5JUZmDR79ci2Ho9JS32rGvkI9+rxzBe/TidlitWrBPRGqOqeWmsLCQ5ORkJk6ceELHL1q0iAsuuIA5c+bwxx9/0LdvXwYOHMiff/5Zy0mlJlitFsYP7YjN18qvW/Yxc+VusyOJSV6cu4kKp0GfNg3p3bqB2XFExMNYDBf557PFYuHLL79k0KBBJ/W8xMREhg8fzhNPPHFCx9vtdsLDw8nLyyMsLOwUksrpenfRdp6ds4HQAF9++ncfGoUHmB1J6tCfuw5yxVu/YbHAnHvOpl2M/h6KyD87mc9vt55z43Q6yc/PJzIy8pjHlJaWYrfbD7uJuW7qHU9yXAT5JRU8ptNTXsUwDJ47tGDfkC5NVGxEpFa4dbl56aWXKCgoYNiwYcc8Zty4cYSHh1ff4uLi6jChHI2P1cKLQzvi72Pl5417+Hp1ptmRpI78tD6HFTsOYvO18sCFbcyOIyIeym3LzfTp03nqqaf47LPPiIqKOuZxY8aMIS8vr/qWnp5ehynlWNpEh3JPv8rVaJ/8eh1780tNTiS1rdzh5PkfNgJwc+94YsIDTU4kIp7KLcvNJ598wi233MJnn33G+eeff9xjbTYbYWFhh93ENdzWpyXtY8LILSpn7NfrzI4jtcgwDN5fnMb2vYVEBvtz+7ktzY4kIh7M7crNjBkzuPHGG5kxYwaXXHKJ2XHkNPj5WHnxyo74Wi18tzaL79dmmR1JapjTaTBnbRaXTljM899Xjtrcc14rwgL8TE4mIp7M18wfXlBQwNatW6u/TktLIyUlhcjISJo2bcqYMWPIyMhg2rRpQOWpqJEjR/L6669z5plnkp2dDUBgYCDh4eGmvAY5PYmx4dx5bkvemL+Vx79K5awW9akXrP2F3F25w8nXKZm89ctWtu2t3E8syN+HG3o259qzmpmcTkQ8namXgv/yyy/07dv3iPtHjhzJ1KlTueGGG9ixYwe//PILAOeeey4LFy485vEnQpeCu57SCgcDJyxmc04BV3RuzKvDO5kdSU5RaYWDWX/sZtIv29h9sBiA0ABfbuzZnBt7xau4isgpO5nPb5dZ56auqNy4ppT0XAa/tQSnAe+P7Ea/dtFmR5KTUFRWwfRlu3j31+3k2Csnh9cP9uem3vFc16OZTkOJyGk7mc9vU09LiVTpFBfBv85uwTuLtvPol2v5sXkk4YH6QHR19pJyPly6k/cXp3GgsAyARmEB3HpOC67u3pRAf22GKSJ1T+VGXMa/L2jDj+tzSNtXyLg5G3h+SEezI8kxHCgs44PFafxv6Q7ySyoAaBoZxB3ntmRwl8bYfFVqRMQ8KjfiMgL8fHhhaEeGvbOUT1akc0nHGM5u3dDsWPI3OfYS3l20nY+X7aK43AFAq6gQRvVtycCOsfj6uN0FmCLigVRuxKWc0TySkT2aM/W3HTzy+Vp+/Pc5BNv0f1OzpR8o4u2F25i5cjdlDicASY3DuKtvKy5s30i7eouIS9Gnhric0Re1Zd6GHHYfLOaFHzby1OVJZkfyWlv3FPDWL1v5KiUTh7Py2oNuzeox6rxWnNumIRaLSo2IuB6VG3E5wTZfxg/pyIj3lvG/pTu5pGMs3eOPvTmq1Lx1mXm8tWAbc1KzqLqe8uzWDRjVtxVnxkeq1IiIS1O5EZfUq1UDru4ex4zl6Tw0azXf33uOrrypA3/sPMjEBVuZv3FP9X3nt4vmrvNa0SkuwrxgIiInQeVGXNaYi9vxy6a97NhfxCs/beKxS9qbHckjGYbB0m37mTB/K0u37wfAaoFLOsYyqm9LEhppPSgRcS8qN+KywgL8eO6KDtw4dQXvL05jQIcYujStZ3Ysj2EYBvM37uHNBVv5c1cuAL5WC4O7NOaOc1sR3yDY3IAiIqdI5UZcWt+EKAZ3acwXqzJ4aNYavrunt9ZQOU0Op8H3qVlMXLCNDVl2APx9rVx1Rhy3ntOCJvWCTE4oInJ6VG7E5T1xaXsWbd7H1j0FTPh5Kw9e1NbsSG6p3OHkq0ObWW4/tJllsL8P157VjJvPjicqNMDkhCIiNUPlRlxeRJA/zwxK4vaP/mDSwm30T2pEUmPtAn+iSsodzPxjN+8s/Gszy7AAX27sFc+NvZoTEaTNLEXEs6jciFvon9SISzrG8N2aLEbPWsPXd/XCT6vhHlfVZpaTF21nT37lZpYNQvy5uXcLrj2rKaHazFJEPJTKjbiNpy5L5Let+9iQZeftX7Zxd7/WZkdySXnF5Uz7bQcfLEnjYFE5ADHhAdx2TguGn6HNLEXE86nciNtoEGJj7GWJ3PtJCm/M38JFSY1oEx1qdiyXsb+glA+WpDHtt53kl1ZuZtmsfhB39GnJ4C5N8PfVSJeIeAeVG3ErlyXH8s3qLOZtyGH0zNV8fkdPr9+sMTuvhMmLtjNj+V+bWbaJDmFU31Zc0iHG6/98RMT7qNyIW7FYLDx7RRLL0vazenceHyxJ49ZzWpodyxTpB4qYtHAbs/62mWXHJuGM6tuKC9pFazNLEfFaKjfidqLDAnj80vY8NGsNL/+4mfPbRdOiYYjZserM1j35vLVgG1+t/mszy+7NIxl1XivOad1A+z6JiNdTuRG3dGXXJny7JotFm/fy8Odr+PTWHh4/UpGakcfEBVv5YV129WaW57RpyF19W2ljURGRv1G5EbdksVgYN7gDF76ykBU7DjJt6Q5u6BVvdqwaZRgGuw8Wsy4zj09XpLNg097qxy5sX7mZZccmEeYFFBFxUSo34rYaRwQy5uJ2/Gd2KuN/2ES/dtHERbrn1gEl5Q425+SzIcvO+kw7G7Iq/7vqqieo3MxyYHIsd57biraNdJWYiMixqNyIW7ume1O+XZPJ79sP8PDna/j4ljNdfs7J3vzSyhKTZa8uM9v3FVbPn/k7fx8rraJC6Na8Hjf1iqe5NrMUEflHKjfi1qxWC+OHdOSi1xbx27b9fLIinau7NzU7FgAVDic79hey7tBITFWZ2XtoteD/LzLYn3YxobSPCaNdTBjtY8No2TBEKzGLiJwklRtxe83qBzP6ogT+++16nv1uA33aNCQ2IrBOM+SXlLMxO//QKaXK28bsfEornEcca7FAfIPgygJz6NYuJozoMJvLjzqJiLgDlRvxCDf0bM53azJZtSuXx75cywc3nFErRcEwDDJyi6vnxazPymNDVj67DhQd9fggfx8SGoXSPjasusy0bRRKkL/+6omI1Bb9hhWP4GO18MLQZC5+41cWbNrLl39mMLhLk9P6nqUVDrbkFLC+epJv5c1eUnHU42PCAw47pdQuJoxmkUEef4m6iIirUbkRj9EqKoT7zm/NCz9s4qlv1tO7dQOiQgNO6Ln7C0oPG4lZn2ln294CKo4yydfPx0KrqKq5MX/NkakX7F/TL0lERE6Byo14lFvPbsH3a7NZm5HH47NTefvaroednnI4DdL2FR52tdKGLDs59qNP8o0I8vtrNObQ/7aKCtEmlCIiLkzlRjyKr4+VF6/syMAJi5m7Lod3f91OoJ8P6w9drbQp205J+dEn+TavH3zE1UqNwgI0yVdExM2o3IjHSWgUxqi+rXht3haem7PxiMcD/XxIiAml3d9GZBIahRJs018HERFPoN/m4pHuPLcVq3blsiUn/4irlZrVD8ZHk3xFRDyWyo14JH9fK9Nu6m52DBERMYFmRYqIiIhHUbkRERERj6JyIyIiIh5F5UZEREQ8isqNiIiIeBSVGxEREfEoKjciIiLiUVRuRERExKOo3IiIiIhHUbkRERERj6JyIyIiIh5F5UZEREQ8isqNiIiIeBSVGxEREfEovmYHqGuGYQBgt9tNTiIiIiInqupzu+pz/Hi8rtzk5+cDEBcXZ3ISEREROVn5+fmEh4cf9xiLcSIVyIM4nU4yMzMJDQ3FYrGYHccl2e124uLiSE9PJywszOw4Xk/vh2vR++F69J64ltp6PwzDID8/n9jYWKzW48+q8bqRG6vVSpMmTcyO4RbCwsL0i8KF6P1wLXo/XI/eE9dSG+/HP43YVNGEYhEREfEoKjciIiLiUVRu5Ag2m40nn3wSm81mdhRB74er0fvhevSeuBZXeD+8bkKxiIiIeDaN3IiIiIhHUbkRERERj6JyIyIiIh5F5UZEREQ8isqNVBs3bhxnnHEGoaGhREVFMWjQIDZt2mR2LAGef/55LBYL9913n9lRvFpGRgbXXnst9evXJzAwkA4dOrBy5UqzY3klh8PB448/Tnx8PIGBgbRs2ZL//ve/J7TvkJy+RYsWMXDgQGJjY7FYLMyePfuwxw3D4IknniAmJobAwEDOP/98tmzZUmf5VG6k2sKFCxk1ahS///47P/30E+Xl5Vx44YUUFhaaHc2rrVixgnfeeYeOHTuaHcWrHTx4kF69euHn58f333/P+vXrefnll6lXr57Z0bzS+PHjmTRpEm+++SYbNmxg/PjxvPDCC0yYMMHsaF6hsLCQ5ORkJk6ceNTHX3jhBd544w3efvttli1bRnBwMBdddBElJSV1kk+Xgssx7d27l6ioKBYuXMg555xjdhyvVFBQQJcuXXjrrbd45pln6NSpE6+99prZsbzSI488wpIlS/j111/NjiLApZdeSnR0NO+//371fUOGDCEwMJCPPvrIxGTex2Kx8OWXXzJo0CCgctQmNjaWBx54gAcffBCAvLw8oqOjmTp1KldddVWtZ9LIjRxTXl4eAJGRkSYn8V6jRo3ikksu4fzzzzc7itf7+uuv6datG1deeSVRUVF07tyZd9991+xYXqtnz578/PPPbN68GYDVq1ezePFiBgwYYHIySUtLIzs7+7DfW+Hh4Zx55pksXbq0TjJ43caZcmKcTif33XcfvXr1Iikpyew4XumTTz5h1apVrFixwuwoAmzfvp1JkyZx//338+ijj7JixQruuece/P39GTlypNnxvM4jjzyC3W4nISEBHx8fHA4Hzz77LCNGjDA7mtfLzs4GIDo6+rD7o6Ojqx+rbSo3clSjRo0iNTWVxYsXmx3FK6Wnp3Pvvffy008/ERAQYHYcobLwd+vWjeeeew6Azp07k5qayttvv61yY4LPPvuMjz/+mOnTp5OYmEhKSgr33XcfsbGxej9Ep6XkSHfddRfffvstCxYsoEmTJmbH8Up//PEHe/bsoUuXLvj6+uLr68vChQt544038PX1xeFwmB3R68TExNC+ffvD7mvXrh27du0yKZF3Gz16NI888ghXXXUVHTp04LrrruPf//4348aNMzua12vUqBEAOTk5h92fk5NT/VhtU7mRaoZhcNddd/Hll18yf/584uPjzY7ktfr168fatWtJSUmpvnXr1o0RI0aQkpKCj4+P2RG9Tq9evY5YGmHz5s00a9bMpETeraioCKv18I8wHx8fnE6nSYmkSnx8PI0aNeLnn3+uvs9ut7Ns2TJ69OhRJxl0WkqqjRo1iunTp/PVV18RGhpafW40PDycwMBAk9N5l9DQ0CPmOgUHB1O/fn3NgTLJv//9b3r27Mlzzz3HsGHDWL58OZMnT2by5MlmR/NKAwcO5Nlnn6Vp06YkJiby559/8sorr3DTTTeZHc0rFBQUsHXr1uqv09LSSElJITIykqZNm3LffffxzDPP0Lp1a+Lj43n88ceJjY2tvqKq1hkihwBHvU2ZMsXsaGIYRp8+fYx7773X7Bhe7ZtvvjGSkpIMm81mJCQkGJMnTzY7ktey2+3GvffeazRt2tQICAgwWrRoYTz22GNGaWmp2dG8woIFC476eTFy5EjDMAzD6XQajz/+uBEdHW3YbDajX79+xqZNm+osn9a5EREREY+iOTciIiLiUVRuRERExKOo3IiIiIhHUbkRERERj6JyIyIiIh5F5UZEREQ8isqNiIiIeBSVGxHxehaLhdmzZ5sdQ0RqiMqNiJjqhhtuwGKxHHHr37+/2dFExE1pbykRMV3//v2ZMmXKYffZbDaT0oiIu9PIjYiYzmaz0ahRo8Nu9erVAypPGU2aNIkBAwYQGBhIixYtmDVr1mHPX7t2Leeddx6BgYHUr1+fW2+9lYKCgsOO+eCDD0hMTMRmsxETE8Ndd9112OP79u3jiiuuICgoiNatW/P111/X7osWkVqjciMiLu/xxx9nyJAhrF69mhEjRnDVVVexYcMGAAoLC7nooouoV68eK1asYObMmcybN++w8jJp0iRGjRrFrbfeytq1a/n6669p1arVYT/jqaeeYtiwYaxZs4aLL76YESNGcODAgTp9nSJSQ+psi04RkaMYOXKk4ePjYwQHBx92e/bZZw3DqNyt/vbbbz/sOWeeeaZxxx13GIZhGJMnTzbq1atnFBQUVD/+3XffGVar1cjOzjYMwzBiY2ONxx577JgZAOM///lP9dcFBQUGYHz//fc19jpFpO5ozo2ImK5v375MmjTpsPsiIyOr/7tHjx6HPdajRw9SUlIA2LBhA8nJyQQHB1c/3qtXL5xOJ5s2bcJisZCZmUm/fv2Om6Fjx47V/x0cHExYWBh79uw51ZckIiZSuRER0wUHBx9xmqimBAYGntBxfn5+h31tsVhwOp21EUlEapnm3IiIy/v999+P+Lpdu3YAtGvXjtWrV1NYWFj9+JIlS7BarbRt25bQ0FCaN2/Ozz//XKeZRcQ8GrkREdOVlpaSnZ192H2+vr40aNAAgJkzZ9KtWzd69+7Nxx9/zPLly3n//fcBGDFiBE8++SQjR45k7Nix7N27l7vvvpvrrruO6OhoAMaOHcvtt99OVFQUAwYMID8/nyVLlnD33XfX7QsVkTqhciMipvvhhx+IiYk57L62bduyceNGoPJKpk8++YQ777yTmJgYZsyYQfv27QEICgpi7ty53HvvvZxxxhkEBQUxZMgQXnnllervNXLkSEpKSnj11Vd58MEHadCgAUOHDq27FygidcpiGIZhdggRkWOxWCx8+eWXDBo0yOwoIuImNOdGREREPIrKjYiIiHgUzbkREZemM+cicrI0ciMiIiIeReVGREREPIrKjYiIiHgUlRsRERHxKCo3IiIi4lFUbkRERMSjqNyIiIiIR1G5EREREY+iciMiIiIe5f8AwsEj8soiV04AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Teacher\n",
      "model is loaded properly\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:07<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher weights and architecture saved and exported for lambda: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary for results\n",
    "lambda_results = {}\n",
    "\n",
    "# Loop for training the teacher model with different lambda values\n",
    "for i in lmda_list_teacher:\n",
    "    # Reset the teacher model for each lambda\n",
    "    teacher_model = torchvision.models.efficientnet_b3(weights='DEFAULT')    \n",
    "    # Replace the last fully connected layer with a new one\n",
    "    teacher_model.classifier = nn.Linear(1536, num_classes)\n",
    "    teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=best_lr_teacher)\n",
    "\n",
    "    teacher_model_weights_path = f'weights/teacher_model_weights_{model_name}_{data_name}_{i}.pth'\n",
    "    \n",
    "    # Initialize the adversary for the teacher\n",
    "    adv = Adversary()\n",
    "    teacher_optimizer_adv = optim.Adam(adv.parameters(), lr=best_lr_teacher)\n",
    "\n",
    "    # pretrain_teacher(teacher_model, trainloader, criterion_clf, teacher_optimizer, device, epochs_pretrain)\n",
    "    # pretrain_adversary(adv, student_model, optimizer_adv, trainloader, adv_criterion, device, epochs_pretrain)\n",
    "    # lmda = i\n",
    "\n",
    "    # Train the teacher model with adversarial training\n",
    "    teacher_mean_abs_val_disparity = train_teacher(model_name, data_name, teacher_model, adv, trainloader, criterion_clf, adv_criterion, teacher_optimizer, teacher_optimizer_adv, device, epochs, i, patience=patience_teacher)\n",
    "\n",
    "    # extract class mean embeddings for teacher\n",
    "    retrieve_teacher_class_weights(model_name, teacher_model, teacher_model_weights_path, num_classes, data_name, testloader, batch_size, bucket_name, i)\n",
    "\n",
    "    # Save the teacher model and its state\n",
    "    # torch.save(teacher_model.state_dict(), f'teacher_model_weights_ckd_wider_lambda{i}.pth')\n",
    "    # torch.save(teacher_model, f'teacher_model_ckd_wider_lambda{i}.pth')\n",
    "    print('Teacher weights and architecture saved and exported for lambda:', i)\n",
    "\n",
    "    # Store the teacher results in the dictionary\n",
    "    lambda_results[i] = {\n",
    "        'teacher_mean_abs_val_disparity': teacher_mean_abs_val_disparity\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b72203-7f14-4b78-a234-28deda2d4098",
   "metadata": {},
   "source": [
    "## KD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f650b946-70e7-4c16-a834-d8fddf36aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training script\n",
    "\n",
    "def train(student, teacher, T_EMB, train_dataloader, optimizer, criterion, kd_loss, nd_loss, epoch, batch_size, temperature, adv, adv_criterion, optimizer_adv, lmda):\n",
    "\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    train_loss = AverageMeter()\n",
    "    train_error = AverageMeter()\n",
    "\n",
    "    Cls_loss = AverageMeter()\n",
    "    Div_loss = AverageMeter()\n",
    "    Norm_Dir_loss = AverageMeter()\n",
    "\n",
    "    # First train adversary in this epoch\n",
    "    train_adversary(adv, student, optimizer_adv, train_dataloader, adv_criterion, 1)\n",
    "\n",
    "    # test T_EMB\n",
    "    T_EMB = T_EMB\n",
    "\n",
    "    # Model on train mode\n",
    "    student.train()\n",
    "    teacher.eval()\n",
    "    running_loss = 0.0 \n",
    "    epoch_loss = 0.0  \n",
    "    num_batches = 0 \n",
    "    confusion_male = np.zeros((num_classes, num_classes))\n",
    "    confusion_female = np.zeros((num_classes, num_classes))\n",
    " \n",
    "    step_per_epoch = len(train_dataloader)\n",
    "\n",
    "    for step, data in enumerate(tqdm(train_dataloader)):\n",
    "        \n",
    "        start = time.time()\n",
    "        s_FEATS = []\n",
    "        features = {}\n",
    "\n",
    "        inputs = data['img'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        targets = data['target'].to(device)\n",
    "\n",
    "        curr_batch_size = len(inputs)\n",
    "\n",
    "        # register hook for feature embeddings\n",
    "        student.avgpool.register_forward_hook(get_features('feats'))\n",
    "        \n",
    "        # compute output\n",
    "        optimizer.zero_grad()\n",
    "        s_logits = student(inputs)\n",
    "\n",
    "        s_FEATS.append(features['feats'].cpu().numpy())\n",
    "        s_emb = np.concatenate(s_FEATS)\n",
    "        # print(f'before reshaping s_emb: {s_emb.shape}')\n",
    "        # reshape embedding features to flatten \n",
    "        s_emb = s_emb.reshape((curr_batch_size, s_emb.shape[1]))\n",
    "        s_emb = torch.from_numpy(s_emb)\n",
    "        s_emb = s_emb.to(device)\n",
    "\n",
    "        # fix embedding output on student model\n",
    "        s_emb_size = 1280\n",
    "        t_emb_size = 1536\n",
    "        \n",
    "        emb_inflate = nn.Sequential(\n",
    "            nn.BatchNorm1d(s_emb_size),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(s_emb_size, t_emb_size)\n",
    "            )\n",
    "        \n",
    "        ## clean model\n",
    "        for m in student.modules():\n",
    "            if isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        \n",
    "        emb_inflate.to(device)\n",
    "\n",
    "        s_emb = emb_inflate(s_emb)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "                        \n",
    "            ####\n",
    "            \n",
    "            t_FEATS = []\n",
    "            features = {}\n",
    "    \n",
    "            # register hook for feature embeddings\n",
    "            teacher.avgpool.register_forward_hook(get_features('feats'))\n",
    "            \n",
    "            # compute output\n",
    "            t_logits = teacher(inputs)\n",
    "    \n",
    "            t_FEATS.append(features['feats'].cpu().numpy())\n",
    "            t_emb = np.concatenate(t_FEATS)\n",
    "            # reshape embedding features to flatten \n",
    "            t_emb = t_emb.reshape((curr_batch_size, t_emb.shape[1]))\n",
    "\n",
    "\n",
    "        ## save s_emb and t_emb as torch tensors \n",
    "        t_emb = torch.from_numpy(t_emb)\n",
    "\n",
    "        # s_emb = s_emb.to(device)\n",
    "        t_emb = t_emb.to(device)\n",
    "\n",
    "\n",
    "        # print(s_emb.size() == s_emb.size())\n",
    "        # print(s_emb.size())\n",
    "        # print(s_emb.size())\n",
    "        \n",
    "        ###\n",
    "\n",
    "        # detach student_outputs to avoid exploding gradients by passing same inputs (with gradience) into two different models. \n",
    "        studentached = s_logits.detach()\n",
    "        # One-hot encode labels and concatenate with student's predictions\n",
    "        one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "        concatenated_output = torch.cat((studentached, one_hot_labels), dim=1)\n",
    "\n",
    "        # Run the adversarial model on concatenated true labels, and predicted labels\n",
    "        with torch.no_grad():\n",
    "            adversary_output = adv(concatenated_output)\n",
    "\n",
    "        \n",
    "         # Calc adversary loss, which is an MSE loss, because this is a regression output.       \n",
    "        adversary_loss = adv_criterion(adversary_output, targets)\n",
    "        # cls loss\n",
    "        cls_loss = criterion(s_logits, labels) * cls_loss_factor\n",
    "        # KD loss\n",
    "        div_loss = kd_loss(s_out = s_logits, t_out = t_logits) * min(1.0, epoch/warm_up)\n",
    "        # ND loss\n",
    "        norm_dir_loss = nd_loss(s_emb=s_emb, t_emb=t_emb, T_EMB=T_EMB, labels=labels)\n",
    "\n",
    "        if lmda != 0:\n",
    "            loss = cls_loss + div_loss + norm_dir_loss + (cls_loss + div_loss + norm_dir_loss)/adversary_loss - lmda * adversary_loss\n",
    "        else:\n",
    "            loss = cls_loss + div_loss + norm_dir_loss\n",
    "        \n",
    "        # measure accuracy and record loss\n",
    "        batch_size = inputs.size(0)\n",
    "        _, pred = s_logits.data.cpu().topk(1, dim=1)\n",
    "        train_error.update(torch.ne(pred.squeeze(), labels.cpu()).float().sum().item() / batch_size, batch_size)\n",
    "        train_loss.update(loss.item(), batch_size)\n",
    "\n",
    "        Cls_loss.update(cls_loss.item(), batch_size)\n",
    "        Div_loss.update(div_loss.item(), batch_size)\n",
    "        Norm_Dir_loss.update(norm_dir_loss.item(), batch_size)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        epoch_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "        t = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))\n",
    "        s1 = '\\r{} [{}/{}]'.format(t, step+1, step_per_epoch)\n",
    "        s2 = ' - {:.2f}ms/step - nd_loss: {:.3f} - kd_loss: {:.3f} - cls_loss: {:.3f} - train_loss: {:.3f} - train_acc: {:.3f}'.format(\n",
    "             1000 * (time.time() - start), norm_dir_loss.item(), div_loss.item(), cls_loss.item(), train_loss.val, 1-train_error.val)\n",
    "\n",
    "        print(s1+s2, end='', flush=True)\n",
    "\n",
    "    epoch_loss /= num_batches\n",
    "    # student_epoch_losses.append(epoch_loss)\n",
    "\n",
    "\n",
    "    print()\n",
    "    return Norm_Dir_loss.avg, Div_loss.avg, Cls_loss.avg, train_loss.avg, train_error.avg\n",
    "\n",
    "\n",
    "def test(student, teacher, test_dataloader, criterion, adv, lmda, kd_loss, nd_loss, epoch, optimizer):\n",
    "\n",
    "    def get_features(name):\n",
    "        def hook(model, input, output):\n",
    "            features[name] = output.detach()\n",
    "        return hook\n",
    "    \n",
    "    test_loss = AverageMeter()\n",
    "    test_error = AverageMeter()\n",
    "\n",
    "    # Model on eval mode\n",
    "    student.eval()\n",
    "    teacher.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_val_loss = 0.0\n",
    "    num_batches = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(tqdm(test_dataloader)):\n",
    "\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "\n",
    "            # compute logits\n",
    "            s_logits = student(inputs)\n",
    "            t_logits = teacher(inputs)\n",
    "\n",
    "            # get feature embeddings\n",
    "\n",
    "            #########\n",
    "\n",
    "            curr_batch_size = len(inputs)\n",
    "\n",
    "            # register hook for feature embeddings\n",
    "            student.avgpool.register_forward_hook(get_features('feats'))\n",
    "            \n",
    "            # compute output\n",
    "            optimizer.zero_grad()\n",
    "            s_logits = student(inputs)\n",
    "    \n",
    "            s_FEATS.append(features['feats'].cpu().numpy())\n",
    "            s_emb = np.concatenate(s_FEATS)\n",
    "            # print(f'before reshaping s_emb: {s_emb.shape}')\n",
    "            # reshape embedding features to flatten \n",
    "            s_emb = s_emb.reshape((curr_batch_size, s_emb.shape[1]))\n",
    "            s_emb = torch.from_numpy(s_emb)\n",
    "            s_emb = s_emb.to(device)\n",
    "    \n",
    "            # fix embedding output on student model\n",
    "            s_emb_size = 1280\n",
    "            t_emb_size = 1536\n",
    "            \n",
    "            emb_inflate = nn.Sequential(\n",
    "                nn.BatchNorm1d(s_emb_size),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(s_emb_size, t_emb_size)\n",
    "                )\n",
    "\n",
    "            ## clean model\n",
    "            for m in student.modules():\n",
    "                if isinstance(m, nn.BatchNorm1d):\n",
    "                    m.weight.data.fill_(1)\n",
    "                    m.bias.data.zero_()\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    m.bias.data.zero_()\n",
    "    \n",
    "            \n",
    "            emb_inflate.to(device)\n",
    "    \n",
    "            s_emb = emb_inflate(s_emb)\n",
    "\n",
    "\n",
    "            t_FEATS = []\n",
    "            features = {}\n",
    "    \n",
    "            # register hook for feature embeddings\n",
    "            teacher.avgpool.register_forward_hook(get_features('feats'))\n",
    "            \n",
    "            # compute output\n",
    "            t_logits = teacher(inputs)\n",
    "    \n",
    "            t_FEATS.append(features['feats'].cpu().numpy())\n",
    "            t_emb = np.concatenate(t_FEATS)\n",
    "            # reshape embedding features to flatten \n",
    "            t_emb = t_emb.reshape((curr_batch_size, t_emb.shape[1]))\n",
    "\n",
    "\n",
    "            ## save s_emb and t_emb as torch tensors \n",
    "            t_emb = torch.from_numpy(t_emb)\n",
    "    \n",
    "            # s_emb = s_emb.to(device)\n",
    "            t_emb = t_emb.to(device)\n",
    "        \n",
    "            ##########\n",
    "\n",
    "\n",
    "            \n",
    "            studentached = s_logits.detach()   \n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((studentached, one_hot_labels), dim=1)\n",
    "\n",
    "            adversary_output = adv(concatenated_output)\n",
    "            adversary_loss = adv_criterion(adversary_output, targets)\n",
    "            # cls loss\n",
    "            cls_loss = criterion(s_logits, labels) * cls_loss_factor\n",
    "            # KD loss\n",
    "            div_loss = kd_loss(s_out = s_logits, t_out = t_logits) * min(1.0, epoch/warm_up)\n",
    "            # ND loss\n",
    "            norm_dir_loss = nd_loss(s_emb=s_emb, t_emb=t_emb, T_EMB=T_EMB, labels=labels)\n",
    "\n",
    "            if lmda != 0:\n",
    "                test_loss = cls_loss + div_loss + norm_dir_loss + (cls_loss + div_loss + norm_dir_loss)/adversary_loss - lmda * adversary_loss\n",
    "            else:\n",
    "                test_loss = cls_loss + div_loss + norm_dir_loss\n",
    "            \n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            batch_size = inputs.size(0)\n",
    "            _, pred = s_logits.data.cpu().topk(1, dim=1)\n",
    "            test_error.update(torch.ne(pred.squeeze(), labels.cpu()).float().sum().item() / batch_size, batch_size)\n",
    "            test_loss.update(loss.item(), batch_size)\n",
    "\n",
    "            \n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            # Compute the validation accuracy\n",
    "            _, predicted = torch.max(s_logits, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            num_batches += 1\n",
    "            recall_diff = evaluate_model_with_gender_multiclass(predicted, labels, targets, num_classes=num_classes)\n",
    "            confusion_male += recall_diff[1]\n",
    "            confusion_female += recall_diff[2]\n",
    "\n",
    "        ##\n",
    "        total_val_loss /= num_batches\n",
    "        confusion_male /= num_batches\n",
    "        confusion_female /= num_batches\n",
    "\n",
    "        epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "        val_losses.append(total_val_loss)\n",
    "        non_zero_abs_values = np.abs(epoch_disparity[epoch_disparity != 0])\n",
    "        mean_non_zero_abs_disparity = np.mean(non_zero_abs_values)\n",
    "        val_disparities.append(mean_non_zero_abs_disparity)\n",
    "        accuracy = total_correct / total_samples\n",
    "        val_accuracies.append(accuracy)\n",
    "        print(f'*****Epoch {epoch + 1}/{epochs}*****\\n' \n",
    "        f'*****Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}*****\\n'\n",
    "        f'*****Validation Accuracy: {accuracy * 100:.2f}%*****\\n'\n",
    "        f'*****Total Avg Disparity: {mean_non_zero_abs_disparity}*****\\n')\n",
    "        class_recall_mapping = {class_name: epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "        \n",
    "        # Print disparities by class label\n",
    "        for class_label, recall_diff in class_recall_mapping.items():\n",
    "            print(f\"Class {class_label}: Recall Difference = {recall_diff}\")\n",
    "\n",
    "\n",
    "    # Check for early stopping\n",
    "    if abs(total_val_loss) < abs(best_total_val_loss):\n",
    "        best_total_val_loss = total_val_loss\n",
    "        patience_counter = 0\n",
    "        best_epoch_mean_abs_disparity = mean_non_zero_abs_disparity\n",
    "        torch.save(student.state_dict(), f'weights/student_model_weights_efficientnetb0_wider_checkpoint_lmda_{lmda}.pth')\n",
    "        torch.save(student, f'weights/student_model_efficientnetb0_wider_checkpoint_lmda_{lmda}.pth')\n",
    "    else:\n",
    "        patience_counter += 1 \n",
    "\n",
    "    file_path = os.path.join(output_dir, f'student_validation_{lmda}.txt')\n",
    "    \n",
    "    # Append data to the text file\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write(f'********Epoch: {epochs}***********')\n",
    "        \n",
    "        file.write(\"Student Val Accuracies:\\n\")\n",
    "        for accuracy in val_accuracies:\n",
    "            file.write(f\"{accuracy}\\n\")\n",
    "    \n",
    "        file.write(\"\\nStudent Val Disparities:\\n\")\n",
    "        for disparity in val_disparities:\n",
    "            file.write(f\"{disparity}\\n\")\n",
    "\n",
    "        for class_label, recall_diff in class_recall_mapping.items():\n",
    "            file.write(f\"Class {class_label}: Recall Difference = {recall_diff}\\n\")\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print('Early stopping')\n",
    "        return test_loss.avg, test_error.avg\n",
    "    \n",
    "    print(f\"Data has been appended to {file_path}\")\n",
    "\n",
    "    return test_loss.avg, test_error.avg\n",
    "\n",
    "\n",
    "def epoch_loop(student, teacher, train_loader, test_loader, num_class, T_EMB, save_dir, batch_size, logger, lr, lmda):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    # student = nn.DataParallel(student, device_ids=args.gpus)\n",
    "    # student = nn.DataParallel(student)\n",
    "    student = student\n",
    "    student.to(device)\n",
    "    # teacher = nn.DataParallel(teacher, device_ids=args.gpus)\n",
    "    # teacher = nn.DataParallel(teacher)\n",
    "    teacher = teacher\n",
    "    teacher.to(device)\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "    best_total_val_loss = float('inf')\n",
    "    best_epoch_accuracy = 0.0\n",
    "    best_epoch_disparity = 0.0\n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    # loss\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    kd_loss = KDLoss(kl_loss_factor=kd_loss_factor, T=t).to(device)\n",
    "    nd_loss = DirectNormLoss(num_class=num_class, nd_loss_factor=nd_loss_factor).to(device)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.SGD(params=student.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay, nesterov=True)\n",
    "\n",
    "    # weights\n",
    "    save_dir = Path(save_dir)\n",
    "    weights = save_dir / 'weights'\n",
    "    weights.mkdir(parents=True, exist_ok=True)\n",
    "    last = weights / 'last'\n",
    "    best = weights / 'best'\n",
    "\n",
    "    # acc,loss\n",
    "    acc_loss = save_dir / 'acc_loss'\n",
    "    acc_loss.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_acc_savepath = acc_loss / 'train_acc.npy'\n",
    "    train_loss_savepath = acc_loss / 'train_loss.npy'\n",
    "    val_acc_savepath = acc_loss / 'val_acc.npy'\n",
    "    val_loss_savepath = acc_loss / 'val_loss.npy'\n",
    "\n",
    "    # tensorboard\n",
    "    logdir = save_dir / 'logs'\n",
    "    logdir.mkdir(parents=True, exist_ok=True)\n",
    "    summary_writer = SummaryWriter(logdir, flush_secs=120)\n",
    "\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_error = 0\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "\n",
    "    logger = logger\n",
    "\n",
    "    # Train model\n",
    "    best_error = 1\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        if epoch in [150, 180, 210]:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] *= 0.1\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, epochs))\n",
    "        norm_dir_loss, div_loss, cls_loss, train_epoch_loss, train_error = train(student=student,\n",
    "                                                                                 teacher=teacher,\n",
    "                                                                                 T_EMB=T_EMB,\n",
    "                                                                                 train_dataloader=train_loader,\n",
    "                                                                                 optimizer=optimizer,\n",
    "                                                                                 criterion=criterion,\n",
    "                                                                                 kd_loss=kd_loss,\n",
    "                                                                                 nd_loss=nd_loss,\n",
    "                                                                                 epoch=epoch,\n",
    "                                                                                 batch_size = batch_size,\n",
    "                                                                                 temperature = temperature, \n",
    "                                                                                 adv = adv, \n",
    "                                                                                 adv_criterion = adv_criterion, \n",
    "                                                                                 optimizer_adv=optimizer_adv,\n",
    "                                                                                 lmda = lmda)\n",
    "        test_epoch_loss, test_error = test(student=student,\n",
    "                                           teacher=teacher,\n",
    "                                           test_dataloader=test_loader,\n",
    "                                           criterion=criterion,\n",
    "                                           adv = adv,\n",
    "                                           lmda = lmda,\n",
    "                                           kd_loss = kd_loss,\n",
    "                                           nd_loss = nd_loss,\n",
    "                                           epoch=epoch,\n",
    "                                           optimizer=optimizer)\n",
    "\n",
    "        s = \"Train Loss: {:.3f}, Train Acc: {:.3f}, Test Loss: {:.3f}, Test Acc: {:.3f}, lr: {:.5f}\".format(\n",
    "            train_epoch_loss, 1-train_error, test_epoch_loss, 1-test_error, optimizer.param_groups[0]['lr'])\n",
    "        logger.info(colorstr('green', s))\n",
    "\n",
    "        # save acc,loss\n",
    "        train_loss.append(train_epoch_loss)\n",
    "        train_acc.append(1-train_error)\n",
    "        test_loss.append(test_epoch_loss)\n",
    "        test_acc.append(1-test_error)\n",
    "\n",
    "        # save model\n",
    "        is_best = test_error < best_error\n",
    "        best_error = min(best_error, test_error)\n",
    "        state = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': student.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_error': best_error,\n",
    "                'train_acc': train_acc,\n",
    "                'train_loss': train_loss,\n",
    "                'test_acc': test_acc,\n",
    "                'test_loss': test_loss,\n",
    "            }\n",
    "\n",
    "        last_path = last / 'epoch_{}_loss_{:.3f}_acc_{:.3f}'.format(\n",
    "            epoch + 1, test_epoch_loss, 1-test_error)\n",
    "        best_path = best / 'epoch_{}_acc_{:.3f}'.format(\n",
    "                epoch + 1, 1-best_error)\n",
    "\n",
    "        Save_Checkpoint(state, last, last_path, best, best_path, is_best)\n",
    "\n",
    "        # tensorboard\n",
    "        if epoch == 1:\n",
    "            # images, labels = next(iter(train_loader))\n",
    "            data = next(iter(train_loader))\n",
    "            images = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "\n",
    "            img_grid = torchvision.utils.make_grid(images)\n",
    "            summary_writer.add_image('Image', img_grid)\n",
    "        summary_writer.add_scalar('lr', optimizer.param_groups[0]['lr'], epoch)\n",
    "        summary_writer.add_scalar('train_loss', train_epoch_loss, epoch)\n",
    "        summary_writer.add_scalar('train_error', train_error, epoch)\n",
    "        summary_writer.add_scalar('val_loss', test_epoch_loss, epoch)\n",
    "        summary_writer.add_scalar('val_error', test_error, epoch)\n",
    "\n",
    "        summary_writer.add_scalar('nd_loss', norm_dir_loss, epoch)\n",
    "        summary_writer.add_scalar('kd_loss', div_loss, epoch)\n",
    "        summary_writer.add_scalar('cls_loss', cls_loss, epoch)\n",
    "\n",
    "    summary_writer.close()\n",
    "    import os\n",
    "    if not os.path.exists(train_acc_savepath) or not os.path.exists(train_loss_savepath):\n",
    "        np.save(train_acc_savepath, train_acc)\n",
    "        np.save(train_loss_savepath, train_loss)\n",
    "        np.save(val_acc_savepath, test_acc)\n",
    "        np.save(val_loss_savepath, test_loss)\n",
    "\n",
    "    plot_loss_curve(val_losses)\n",
    "\n",
    "    return best_epoch_mean_abs_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "697182fa-851d-46a5-bcc1-052b7cd7ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some params\n",
    "workers = 8 # number of data loading workers\n",
    "momentum = 0.9 # SGD momentum\n",
    "cls_loss_factor =1.0 # cls loss weight factor\n",
    "kd_loss_factor =1.0 #KD loss weight factor\n",
    "t =4.0 #temperature\n",
    "nd_loss_factor =1.0 # ND loss weight factor\n",
    "warm_up=20.0 #loss weight warm up epochs\n",
    "weight_decay = 5e-4 \n",
    "\n",
    "def run_norm_and_dir_kd(save_dir, student_model, teacher_model, teacher_weights_path, num_class, epochs, batch_size, lr, lmda):\n",
    "    \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s [line:%(lineno)d] %(message)s',\n",
    "                        datefmt='%d %b %Y %H:%M:%S')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.info(colorstr('green', \"Distribute train, total batch size:{}, epoch:{}\".format(batch_size, epochs)))\n",
    " \n",
    "    \n",
    "    # load in models\n",
    "    student = student_model\n",
    "    \n",
    "    teacher = teacher_model\n",
    "    \n",
    "    print('Load Teacher Weights')\n",
    "\n",
    "    ###\n",
    "    session = boto3.session.Session()\n",
    "    s3 = session.client('s3')\n",
    "    bucket_name = '210bucket' \n",
    "\n",
    "    teacher_model_weights_buffer = io.BytesIO()\n",
    "    s3.download_fileobj(bucket_name, teacher_weights_path, teacher_model_weights_buffer)\n",
    "    teacher_model_weights_buffer.seek(0)  \n",
    "\n",
    "    # Load the model\n",
    "    # model = models_package.__dict__[model_name](num_class=num_class)\n",
    "    teacher_ckpt = torch.load(teacher_model_weights_buffer)\n",
    "    teacher.load_state_dict(teacher_ckpt)\n",
    "    # print(\"Keys in checkpoint:\", teacher_ckpt.keys())\n",
    "    print(\"model is loaded properly\")\n",
    "\n",
    "        \n",
    "    # teacher_ckpt = torch.load(teacher_weights)['model']\n",
    "    # teacher.load_state_dict(teacher_ckpt)\n",
    "\n",
    "    for param in teacher.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    ## get teacher class mean embeddings\n",
    "    with open(\"./class_means/WIDER_embedding_fea/efficientnetb3.json\", 'r') as f:\n",
    "        T_EMB = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    logger.info(colorstr('green', 'Use ' + 'efficientnetb3' + ' Training ' + 'efficientnetb0' + ' ...'))\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    best_epoch_mean_abs_disparity = epoch_loop(student=student, teacher=teacher, train_loader = trainloader, test_loader = testloader, num_class = num_classes, T_EMB = T_EMB, save_dir = save_dir, batch_size = batch_size, logger = logger, lr = best_lr_student, lmda = lmda)\n",
    "\n",
    "    return best_epoch_mean_abs_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f00ed527-6705-4f12-b7af-2c5d0a1e753f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:22<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 0: loss - 0.5741341257536853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:22<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 1: loss - 0.26860244618153867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 162/162 [01:22<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 2: loss - 0.26330004531292267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                | 0/162 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 35.06 MiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 13.99 GiB is allocated by PyTorch, and 579.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m student_optimizer_adv \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(adv\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mbest_lr_student)\n\u001b[1;32m     20\u001b[0m pretrain_student(student_model, teacher_model, trainloader, criterion_clf, student_optimizer, device, alpha, temperature, epochs_pretrain)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mpretrain_adversary\u001b[49m\u001b[43m(\u001b[49m\u001b[43madv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_adv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_pretrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m student_mean_abs_val_disparity \u001b[38;5;241m=\u001b[39m run_norm_and_dir_kd(save_dir, student_model, teacher_model, teacher_model_weights_path, num_classes, epochs, batch_size, best_lr_student, i)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# torch.save(student_model.state_dict(), f'student_model_weights_ckd_wider_lambda{i}.pth')\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# torch.save(student_model, f'student_model_ckd_wider_lambda{i}.pth')\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print('Student weights and architecture saved and exported for lambda:', i)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Check if the key exists in the dictionary\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m, in \u001b[0;36mpretrain_adversary\u001b[0;34m(adv, student, adversary_optimizer, trainloader, adv_criterion, device, epochs_pretrain)\u001b[0m\n\u001b[1;32m     13\u001b[0m student \u001b[38;5;241m=\u001b[39m student\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m adversary_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m student_output \u001b[38;5;241m=\u001b[39m \u001b[43mstudent\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m one_hot_labels \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(labels, num_classes\u001b[38;5;241m=\u001b[39mnum_classes)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     17\u001b[0m concatenated_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((student_output, one_hot_labels), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_res_connect:\n\u001b[1;32m    166\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/activation.py:393\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2071\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 2071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 35.06 MiB is free. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 13.99 GiB is allocated by PyTorch, and 579.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Loop for training the student model with different lambda values\n",
    "for i in lmda_list_student:\n",
    "    # load teacher model with lambda 0\n",
    "\n",
    "    teacher_model = torchvision.models.efficientnet_b3(weights='DEFAULT')\n",
    "    teacher_model.classifier = nn.Linear(1536, num_classes)\n",
    "    teacher_model_weights_path = f'weights/teacher_model_weights_{model_name}_{data_name}_{i}.pth'\n",
    "\n",
    "    student_model = torchvision.models.efficientnet_b0(weights='DEFAULT')\n",
    "    student_model.classifier = nn.Linear(1280, num_classes)\n",
    "\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=best_lr_student)\n",
    "    student_scheduler = torch.optim.lr_scheduler.StepLR(student_optimizer, step_size=step_size, gamma=gamma)\n",
    "    \n",
    "    adv = Adversary()\n",
    "    adv.to(device)\n",
    "    student_optimizer_adv = optim.Adam(adv.parameters(), lr=best_lr_student)\n",
    "\n",
    "    \n",
    "    pretrain_student(student_model, teacher_model, trainloader, criterion_clf, student_optimizer, device, alpha, temperature, epochs_pretrain)\n",
    "    pretrain_adversary(adv, teacher_model, optimizer_adv, trainloader, adv_criterion, device, epochs_pretrain)\n",
    "    \n",
    "    student_mean_abs_val_disparity = run_norm_and_dir_kd(save_dir, student_model, teacher_model, teacher_model_weights_path, num_classes, epochs, batch_size, best_lr_student, i)\n",
    "\n",
    "\n",
    "    # torch.save(student_model.state_dict(), f'student_model_weights_ckd_wider_lambda{i}.pth')\n",
    "    # torch.save(student_model, f'student_model_ckd_wider_lambda{i}.pth')\n",
    "    # print('Student weights and architecture saved and exported for lambda:', i)\n",
    "\n",
    "    # Check if the key exists in the dictionary\n",
    "    if i not in lambda_results:\n",
    "        # If not, create a new entry for that key\n",
    "        lambda_results[i] = {\n",
    "            'student_mean_abs_val_disparity': student_mean_abs_val_disparity\n",
    "    }\n",
    "    else:\n",
    "        # If the key exists, update the existing entry\n",
    "        lambda_results[i].update({\n",
    "            'student_mean_abs_val_disparity': student_mean_abs_val_disparity\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073656a3-9d3d-469d-a66f-0afc3c289ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance_metrics(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_teacher_preds = []\n",
    "    all_student_preds = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "            \n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1).cpu().numpy()\n",
    "        student_preds = torch.argmax(student_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_teacher_preds.append(teacher_preds)\n",
    "        all_student_preds.append(student_preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_teacher_preds = np.concatenate(all_teacher_preds)\n",
    "    all_student_preds = np.concatenate(all_student_preds)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': (accuracy_score(all_labels, all_teacher_preds), accuracy_score(all_labels, all_student_preds)),\n",
    "        'precision': (precision_score(all_labels, all_teacher_preds, average='weighted', zero_division=0), precision_score(all_labels, all_student_preds, average='weighted', zero_division=0)),\n",
    "        'recall': (recall_score(all_labels, all_teacher_preds, average='weighted'), recall_score(all_labels, all_student_preds, average='weighted')),\n",
    "        'f1': (f1_score(all_labels, all_teacher_preds, average='weighted'), f1_score(all_labels, all_student_preds, average='weighted'))\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'all_labels': all_labels,\n",
    "        'all_teacher_preds': all_teacher_preds,\n",
    "        'all_student_preds': all_student_preds\n",
    "    }\n",
    "\n",
    "def compare_model_size(teacher, student):\n",
    "    teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "    student_params = sum(p.numel() for p in student.parameters())\n",
    "    return teacher_params, student_params\n",
    "\n",
    "def compare_inference_time(teacher, student, dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    data = next(dataiter)\n",
    "    inputs = data['img']\n",
    "    \n",
    "    teacher = teacher.to(device)\n",
    "    student = student.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        teacher_outputs = teacher(inputs)\n",
    "    teacher_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        student_outputs = student(inputs)\n",
    "    student_time = time.time() - start_time\n",
    "    \n",
    "    return teacher_time, student_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e04fd-db83-4893-bfd5-31d8808243d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each lambda value\n",
    "for lmda_teacher in lmda_list_teacher:\n",
    "    for lmda_student in lmda_list_student:\n",
    "\n",
    "    # Load teacher and student models for the current lambda\n",
    "    teacher_model = torch.load(f'weights/teacher_model_weights_{model_name}_{dataset}_{lmda}.pth')\n",
    "    student_model = torch.load(f'weights/student_model_weights_efficientnetb0_wider_checkpoint_lmda_{lmda}.pth')\n",
    "\n",
    "    # Compute performance metrics\n",
    "    performance_metrics = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "\n",
    "    # Compute model sizes and inference times\n",
    "    teacher_params, student_params = compare_model_size(teacher_model, student_model)\n",
    "    teacher_time, student_time = compare_inference_time(teacher_model, student_model, testloader)\n",
    "\n",
    "    # Update results for the current lambda value\n",
    "    if lmda in lambda_results:\n",
    "        lambda_results[lmda].update({\n",
    "            'performance_metrics': performance_metrics,\n",
    "            'teacher_params': teacher_params,\n",
    "            'student_params': student_params,\n",
    "            'teacher_time': teacher_time,\n",
    "            'student_time': student_time\n",
    "        })\n",
    "    else:\n",
    "        lambda_results[lmda] = {\n",
    "            'performance_metrics': performance_metrics,\n",
    "            'teacher_params': teacher_params,\n",
    "            'student_params': student_params,\n",
    "            'teacher_time': teacher_time,\n",
    "            'student_time': student_time\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c127f4e-cc52-45ff-a035-9e0184fb9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store accuracies\n",
    "teacher_accuracies = []\n",
    "student_accuracies = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Access the performance metrics for each pair\n",
    "    teacher_accuracy = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['accuracy'][0]\n",
    "    student_accuracy = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['accuracy'][1]\n",
    "\n",
    "    # Append accuracies to the lists\n",
    "    teacher_accuracies.append((lmda_teacher, teacher_accuracy))\n",
    "    student_accuracies.append((lmda_student, student_accuracy))\n",
    "\n",
    "# To plot, you might need to separate the lambda values and accuracies\n",
    "teacher_lambdas, teacher_acc = zip(*teacher_accuracies)\n",
    "student_lambdas, student_acc = zip(*student_accuracies)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(teacher_lambdas, teacher_acc, label='Teacher Accuracy', marker='o')\n",
    "plt.plot(student_lambdas, student_acc, label='Student Accuracy', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d58ea-0417-4a20-bc3f-4b69f15b9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store precisions\n",
    "teacher_precisions = []\n",
    "student_precisions = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the precision metrics for each pair\n",
    "        teacher_precision = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['precision'][0]\n",
    "        student_precision = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['precision'][1]\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append precisions to the lists along with lambda values\n",
    "    teacher_precisions.append((lmda_teacher, teacher_precision))\n",
    "    student_precisions.append((lmda_student, student_precision))\n",
    "\n",
    "# To plot, you might need to separate the lambda values and precisions\n",
    "teacher_lambdas, teacher_prec = zip(*teacher_precisions)\n",
    "student_lambdas, student_prec = zip(*student_precisions)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(teacher_lambdas, teacher_prec, label='Teacher Precision', marker='o')\n",
    "plt.plot(student_lambdas, student_prec, label='Student Precision', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ee757-c1af-4f1a-85bd-136bc85e6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store recalls\n",
    "teacher_recalls = []\n",
    "student_recalls = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the recall metrics for each pair\n",
    "        teacher_recall = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['recall'][0]\n",
    "        student_recall = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['recall'][1]\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append recalls to the lists along with lambda values\n",
    "    teacher_recalls.append((lmda_teacher, teacher_recall))\n",
    "    student_recalls.append((lmda_student, student_recall))\n",
    "\n",
    "# To plot, you might need to separate the lambda values and recalls\n",
    "teacher_lambdas, teacher_rec = zip(*teacher_recalls)\n",
    "student_lambdas, student_rec = zip(*student_recalls)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(teacher_lambdas, teacher_rec, label='Teacher Recall', marker='o')\n",
    "plt.plot(student_lambdas, student_rec, label='Student Recall', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4e93d-9344-49fc-978f-a00d8d8e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store F1 scores\n",
    "teacher_f1s = []\n",
    "student_f1s = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the F1 scores for each pair\n",
    "        teacher_f1 = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['f1'][0]\n",
    "        student_f1 = lambda_results[(lmda_teacher, lmda_student)]['performance_metrics']['metrics']['f1'][1]\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append F1 scores to the lists along with lambda values\n",
    "    teacher_f1s.append((lmda_teacher, teacher_f1))\n",
    "    student_f1s.append((lmda_student, student_f1))\n",
    "\n",
    "# To plot, you might need to separate the lambda values and F1 scores\n",
    "teacher_lambdas, teacher_f1_scores = zip(*teacher_f1s)\n",
    "student_lambdas, student_f1_scores = zip(*student_f1s)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(teacher_lambdas, teacher_f1_scores, label='Teacher F1 Score', marker='o')\n",
    "plt.plot(student_lambdas, student_f1_scores, label='Student F1 Score', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b769e1-25e1-423c-b77f-af275eb11152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store model sizes\n",
    "teacher_sizes = []\n",
    "student_sizes = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the model sizes for each pair\n",
    "        teacher_size = lambda_results[(lmda_teacher, lmda_student)]['teacher_params'] / 1e6  # Convert to millions\n",
    "        student_size = lambda_results[(lmda_teacher, lmda_student)]['student_params'] / 1e6\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append model sizes to the lists along with lambda values\n",
    "    teacher_sizes.append((lmda_teacher, teacher_size))\n",
    "    student_sizes.append((lmda_student, student_size))\n",
    "\n",
    "# To plot, you might need to separate the lambda values and model sizes\n",
    "teacher_lambdas, teacher_model_sizes = zip(*teacher_sizes)\n",
    "student_lambdas, student_model_sizes = zip(*student_sizes)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(teacher_lambdas, teacher_model_sizes, label='Teacher Model Size', marker='o')\n",
    "plt.plot(student_lambdas, student_model_sizes, label='Student Model Size', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Model Size (Millions of Parameters)')\n",
    "plt.title('Model Size Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8aae8d-9a0d-45b3-9fc2-c27bc5fcaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store inference times\n",
    "teacher_times = []\n",
    "student_times = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if the key is a tuple (indicating a lambda pair)\n",
    "    if isinstance(key, tuple) and len(key) == 2:\n",
    "        lmda_teacher, lmda_student = key\n",
    "        # Access the inference times for each pair\n",
    "        teacher_time = lambda_results[(lmda_teacher, lmda_student)]['teacher_time']\n",
    "        student_time = lambda_results[(lmda_teacher, lmda_student)]['student_time']\n",
    "    else:\n",
    "        # If the key is not a tuple, skip this iteration\n",
    "        continue\n",
    "\n",
    "    # Append inference times to the lists along with lambda values\n",
    "    teacher_times.append((lmda_teacher, teacher_time))\n",
    "    student_times.append((lmda_student, student_time))\n",
    "\n",
    "# To plot, you might need to separate the lambda values and inference times\n",
    "teacher_lambdas, teacher_inference_times = zip(*teacher_times)\n",
    "student_lambdas, student_inference_times = zip(*student_times)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(teacher_lambdas, teacher_inference_times, label='Teacher Inference Time', marker='o')\n",
    "plt.plot(student_lambdas, student_inference_times, label='Student Inference Time', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Inference Time (s)')\n",
    "plt.title('Inference Time Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7cb7f0-12a9-4cec-8188-048c3ffcadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store disparity values\n",
    "teacher_disparities = []\n",
    "student_disparities = []\n",
    "lambda_pairs = list(lambda_results.keys())\n",
    "\n",
    "# Iterate over the keys in lambda_results\n",
    "for key in lambda_pairs:\n",
    "    # Check if it's an integer key (indicating a lambda value for student)\n",
    "    if isinstance(key, int):\n",
    "        # Check and extract teacher disparity if it exists\n",
    "        if 'teacher_mean_abs_val_disparity' in lambda_results[key]:\n",
    "            teacher_disparity = lambda_results[key]['teacher_mean_abs_val_disparity']\n",
    "            if isinstance(teacher_disparity, list):  # Assuming the disparity could be stored as a list\n",
    "                teacher_disparity = teacher_disparity[0]\n",
    "            teacher_disparities.append((key, teacher_disparity))\n",
    "\n",
    "        # Extract student disparity\n",
    "        if 'student_mean_abs_val_disparity' in lambda_results[key]:\n",
    "            student_disparity = lambda_results[key]['student_mean_abs_val_disparity']\n",
    "            student_disparities.append((key, student_disparity))\n",
    "\n",
    "# Separate the lambda values and disparity values\n",
    "teacher_lambdas, teacher_disparity_values = zip(*teacher_disparities) if teacher_disparities else ([], [])\n",
    "student_lambdas, student_disparity_values = zip(*student_disparities) if student_disparities else ([], [])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "if teacher_disparities:\n",
    "    plt.plot(teacher_lambdas, teacher_disparity_values, label='Teacher Average Disparity', marker='o')\n",
    "if student_disparities:\n",
    "    plt.plot(student_lambdas, student_disparity_values, label='Student Average Disparity', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Average Disparity')\n",
    "plt.title('Average Disparity Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80376f-d5b1-4008-8099-18693972c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(predictions, class_names, title):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=predictions)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(all_labels, predictions, class_names, title):\n",
    "    cm = confusion_matrix(all_labels, predictions)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(pd.DataFrame(cm, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to generate predictions and compute metrics\n",
    "def generate_predictions_and_metrics(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs = batch['img'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            \n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "\n",
    "    return all_labels, all_preds\n",
    "\n",
    "# Loop over each lambda value for the teacher model\n",
    "for lmda_teacher in lmda_list_teacher:\n",
    "    # Load the teacher model\n",
    "    teacher_model = torch.load(f'teacher_model_ckd_wider_lambda{lmda_teacher}.pth')\n",
    "\n",
    "    # Generate predictions for the teacher model\n",
    "    all_labels, all_teacher_preds = generate_predictions_and_metrics(teacher_model, testloader)\n",
    "\n",
    "    # Plot distribution and confusion matrix for the teacher model\n",
    "    plot_distribution(all_teacher_preds, class_names_new, f'Teacher Model Predictions (Lambda={lmda_teacher})')\n",
    "    plot_confusion_matrix(all_labels, all_teacher_preds, class_names_new, f'Teacher Confusion Matrix (Lambda={lmda_teacher})')\n",
    "\n",
    "    # Print classification report for the teacher model\n",
    "    teacher_report = classification_report(all_labels, all_teacher_preds, target_names=class_names_new, zero_division=0)\n",
    "    print(f'Classification Report - Teacher Model (Lambda={lmda_teacher})')\n",
    "    print(teacher_report)\n",
    "\n",
    "# Loop over each lambda value for the student model\n",
    "for lmda_student in lmda_list_student:\n",
    "    # Load the student model\n",
    "    student_model = torch.load(f'student_model_ckd_wider_lambda{lmda_student}.pth')\n",
    "\n",
    "    # Generate predictions for the student model\n",
    "    all_labels, all_student_preds = generate_predictions_and_metrics(student_model, testloader)\n",
    "\n",
    "    # Plot distribution and confusion matrix for the student model\n",
    "    plot_distribution(all_student_preds, class_names_new, f'Student Model Predictions (Lambda={lmda_student})')\n",
    "    plot_confusion_matrix(all_labels, all_student_preds, class_names_new, f'Student Confusion Matrix (Lambda={lmda_student})')\n",
    "\n",
    "    # Print classification report for the student model\n",
    "    student_report = classification_report(all_labels, all_student_preds, target_names=class_names_new, zero_division=0)\n",
    "    print(f'Classification Report - Student Model (Lambda={lmda_student})')\n",
    "    print(student_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf516d7-2f71-4abd-b904-0e1364cca7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_variance_tradeoff(model_results, model_type, lambdas):\n",
    "    bias_values = []\n",
    "    accuracy_values = []\n",
    "\n",
    "    if model_type == 'teacher':\n",
    "        for lmda in lambdas:\n",
    "            if lmda in model_results and 'teacher_mean_abs_val_disparity' in model_results[lmda]:\n",
    "                bias_values.append(model_results[lmda]['teacher_mean_abs_val_disparity'][0])\n",
    "                performance_key = next((key for key in model_results if isinstance(key, tuple) and key[0] == lmda), None)\n",
    "                if performance_key:\n",
    "                    accuracy_values.append(model_results[performance_key]['performance_metrics']['metrics']['accuracy'][0])\n",
    "        model_name = \"Teacher\"\n",
    "    elif model_type == 'student':\n",
    "        for lmda in lambdas:\n",
    "            if lmda in model_results and 'student_mean_abs_val_disparity' in model_results[lmda]:\n",
    "                bias_values.append(model_results[lmda]['student_mean_abs_val_disparity'])\n",
    "                performance_key = next((key for key in model_results if isinstance(key, tuple) and key[1] == lmda), None)\n",
    "                if performance_key:\n",
    "                    accuracy_values.append(model_results[performance_key]['performance_metrics']['metrics']['accuracy'][1])\n",
    "        model_name = \"Student\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'teacher' or 'student'.\")\n",
    "\n",
    "\n",
    "    # Weight for the trade-off (can be adjusted based on preference)\n",
    "    bias_weight = 1\n",
    "\n",
    "    # Calculate the weighted ratio\n",
    "    weighted_ratios = np.array(accuracy_values) / (1 + bias_weight * np.array(bias_values))\n",
    "    closest_to_one_index = np.argmin(np.abs(weighted_ratios - 1))\n",
    "    optimal_bias = bias_values[closest_to_one_index]\n",
    "    optimal_accuracy = accuracy_values[closest_to_one_index]\n",
    "    optimal_ratio = weighted_ratios[closest_to_one_index]\n",
    "\n",
    "    # Plotting the bias-variance trade-off curve\n",
    "    plt.plot(bias_values, accuracy_values, marker='o', linestyle='-', label=f'{model_name} Trade-off Points')\n",
    "\n",
    "    # Mark all points with their lambda values\n",
    "    for i, (bias, acc, lmbda) in enumerate(zip(bias_values, accuracy_values, lambdas)):\n",
    "        plt.annotate(f'λ={lmbda}', (bias, acc), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    # Highlight the optimal point\n",
    "    plt.scatter(optimal_bias, optimal_accuracy, color='r', s=100, marker='X', label=f'Optimal Point (λ={lambdas[closest_to_one_index]})')\n",
    "    plt.xlabel('Disparity')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{model_name} Accuracy-Fairness Trade-off Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Print optimal values\n",
    "    print(f\"Optimal Lambda for {model_name}: {lambdas[closest_to_one_index]}\")\n",
    "    print(f\"Optimal Bias/Disparity for {model_name}: {optimal_bias}\")\n",
    "    print(f\"Optimal Accuracy for {model_name}: {optimal_accuracy}\")\n",
    "    print(f\"Optimal Weighted Ratio for {model_name}: {optimal_ratio:.2f}\")\n",
    "    \n",
    "# Plot for Teacher\n",
    "plot_bias_variance_tradeoff(lambda_results, 'teacher', lmda_list_teacher)\n",
    "\n",
    "# Plot for Student\n",
    "plot_bias_variance_tradeoff(lambda_results, 'student', lmda_list_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7caf96-e434-472e-88c5-0bb0b3d300a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd96b9-a3f7-4f06-9dbd-48c8f4ed8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance_metrics_for_demo(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "\n",
    "    detailed_info = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        # Assuming gender or other attributes are part of 'target'\n",
    "        attributes = batch['target'].to(device)  \n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "\n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1)\n",
    "        student_preds = torch.argmax(student_outputs, dim=1)\n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            if teacher_preds[i] != labels[i] and student_preds[i] == labels[i]:\n",
    "                info = {\n",
    "                    'image': inputs[i],\n",
    "                    'actual_class': labels[i].item(),\n",
    "                    'teacher_pred_class': teacher_preds[i].item(),\n",
    "                    'student_pred_class': student_preds[i].item(),\n",
    "                    'actual_attribute': attributes[i].item(),  # Modify based on your dataset\n",
    "                    # If your model also predicts attributes, include them here\n",
    "                }\n",
    "                detailed_info.append(info)\n",
    "\n",
    "    return detailed_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d6a799-dafe-42d6-9adb-b92c652db521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_details(info_list, rows=5, cols=5):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 15))\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i in range(rows * cols):\n",
    "        if i < len(info_list):\n",
    "            data = info_list[i]\n",
    "            image = data['image']\n",
    "            actual_class = data['actual_class']\n",
    "            teacher_pred_class = data['teacher_pred_class']\n",
    "            student_pred_class = data['student_pred_class']\n",
    "            actual_attribute = round(data['actual_attribute'], 2)  # Round to 2 decimal places\n",
    "\n",
    "            # Normalize the image for display\n",
    "            image_display = image.cpu().numpy().transpose(1, 2, 0)\n",
    "            image_display = (image_display - image_display.min()) / (image_display.max() - image_display.min())\n",
    "\n",
    "            title = f'Actual: Class {actual_class}, Attr {actual_attribute}\\n' + \\\n",
    "                    f'Teacher: Class {teacher_pred_class}\\n' + \\\n",
    "                    f'Student: Class {student_pred_class}'\n",
    "\n",
    "            axes[i].imshow(image_display)\n",
    "            axes[i].set_title(title)\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2516587-f2dc-4202-9b2c-11b2e1c4384e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed info where student is correct and teacher is wrong\n",
    "detailed_info = compare_performance_metrics_for_demo(teacher_model, student_model, testloader)\n",
    "\n",
    "# Display images with details\n",
    "plot_images_with_details(detailed_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24f7ad-a174-4218-b7c5-e6352912de72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
