{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e057459-072c-4cc9-9547-5fb77dfbf36b",
   "metadata": {},
   "source": [
    "## WIDER Dataset - DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fd4796-6aec-42af-9e21-413c8841c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66acd606-5ac6-4a16-92c4-59d34d57861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import boto3\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms, RandAugment\n",
    "import torch\n",
    "import tarfile\n",
    "import os\n",
    "import getpass\n",
    "import s3fs\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from data.data_loader import load_cifar10, load_cifar100, load_imagenet, load_prof, load_wider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a55be-ed9a-4a8a-a16e-8725a011a310",
   "metadata": {},
   "source": [
    "### Data Download - Do not need to repeat this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e679eef-7c26-4ac3-9b73-a8310d9d94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "# # !aws s3 cp s3://210bucket/wider_attribute_image.tgz ./wider_attribute_image.tgz\n",
    "# Option 2\n",
    "# s3 = boto3.client('s3')\n",
    "# s3.download_file('210bucket', 'wider_attribute_image.tgz', 'wider_attribute_image.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7f2e4c-61bc-4c4c-8aae-596d37c60768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the .tgz file\n",
    "# with tarfile.open('wider_attribute_image.tgz', 'r:gz') as tar:\n",
    "#     tar.extractall(path=\"local_wider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d2d531-4065-4e23-b186-ab9248633d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload the image files to s3 Bukcet\n",
    "# s3 = boto3.client('s3')\n",
    "\n",
    "# def upload_dir_to_s3(bucket_name, s3_folder, local_dir):\n",
    "#     for root, dirs, files in os.walk(local_dir):\n",
    "#         for file in files:\n",
    "#             local_path = os.path.join(root, file)\n",
    "#             relative_path = os.path.relpath(local_path, local_dir)\n",
    "#             s3_path = os.path.join(s3_folder, relative_path)\n",
    "            \n",
    "#             s3.upload_file(local_path, bucket_name, s3_path)\n",
    "\n",
    "# upload_dir_to_s3('210bucket', 'WIDER/', 'WIDER/Image/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239f8ac-8c25-46b1-b7dd-f602145f1b91",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea1301a1-88a0-4aab-bcb8-83b34be3161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### now available using \"from data.data_loader import\" #########################\n",
    "\n",
    "# class DataSet(Dataset):\n",
    "#     def __init__(self, ann_files, augs, img_size, dataset):\n",
    "#         self.dataset = dataset\n",
    "#         self.ann_files = ann_files\n",
    "#         self.augment = self.augs_function(augs, img_size)\n",
    "#         self.transform = transforms.Compose(\n",
    "#             [\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "#             ]\n",
    "#         )\n",
    "#         self.anns = []\n",
    "#         self.s3_client = boto3.client('s3') \n",
    "#         self.load_anns()\n",
    "#         print(self.augment)\n",
    "\n",
    "#         if self.dataset == \"wider\":\n",
    "#             self.transform = transforms.Compose(\n",
    "#                 [\n",
    "#                     transforms.ToTensor(),\n",
    "#                     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "#                 ]\n",
    "#             )\n",
    "\n",
    "#     def extract_label_from_filename(self, file_name):\n",
    "#         # Split the path and extract the part with '--'\n",
    "#         parts = file_name.split('/')\n",
    "#         for part in parts:\n",
    "#             if '--' in part:\n",
    "#                 # Extract the numeric part before '--'\n",
    "#                 label = part.split('--')[0]\n",
    "#                 if label.isdigit():\n",
    "#                     return int(label)  # Return as an integer\n",
    "#         raise ValueError(f\"Label not found in file name: {file_name}\")\n",
    "\n",
    "        \n",
    "\n",
    "#     def augs_function(self, augs, img_size):            \n",
    "#         t = []\n",
    "#         if 'randomflip' in augs:\n",
    "#             t.append(transforms.RandomHorizontalFlip())\n",
    "#         if 'ColorJitter' in augs:\n",
    "#             t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "#         if 'resizedcrop' in augs:\n",
    "#             t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "#         if 'RandAugment' in augs: # need to review RandAugment()\n",
    "#             t.append(RandAugment())\n",
    "#             # t.append(transforms.RandomApply([\n",
    "#             #     transforms.RandomRotation(degrees=10),\n",
    "#             #     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "#             #     transforms.RandomPerspective(distortion_scale=0.05)\n",
    "#             # ], p=0.5))\n",
    "\n",
    "#         t.append(transforms.Resize((img_size, img_size)))\n",
    "    \n",
    "#         return transforms.Compose(t)\n",
    "\n",
    "#     def load_anns(self):\n",
    "#         s3_client = boto3.client('s3')\n",
    "#         self.anns = []\n",
    "#         for ann_file in self.ann_files:\n",
    "#             bucket, key = self.parse_s3_path(ann_file)\n",
    "#             response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "#             json_data = json.loads(response['Body'].read())\n",
    "#             for image in json_data['images']:\n",
    "#                 file_name = image['file_name']\n",
    "#                 label = self.extract_label_from_filename(file_name)  # Use the new method\n",
    "#                 for target in image['targets']:\n",
    "#                     ann = {\n",
    "#                         'img_path': f's3://210bucket/WIDER/{file_name}',\n",
    "#                         'bbox': target['bbox'],\n",
    "#                         'label': label,  \n",
    "#                         'target': target['attribute']\n",
    "#                     }\n",
    "#                     self.anns.append(ann)\n",
    "#         print(f\"Loaded annotations: {len(self.anns)}\")\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.anns)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         idx = idx % len(self)\n",
    "#         ann = self.anns[idx]\n",
    "    \n",
    "#         if not isinstance(ann, dict) or \"img_path\" not in ann:\n",
    "#             raise ValueError(f\"Annotation at index {idx} is not a dictionary with an 'img_path' key: {ann}\")\n",
    "    \n",
    "#         bucket, key = self.parse_s3_path(ann[\"img_path\"])\n",
    "#         try:\n",
    "#             response = self.s3_client.get_object(Bucket=bucket, Key=key)\n",
    "#             img = Image.open(io.BytesIO(response['Body'].read())).convert(\"RGB\")\n",
    "#         except self.s3_client.exceptions.NoSuchKey:\n",
    "#             print(f\"File not found: s3://{bucket}/{key}\")\n",
    "#             img = self.get_placeholder_image()\n",
    "#             return None \n",
    "    \n",
    "#         x, y, w, h = ann['bbox']\n",
    "#         img = img.crop((x, y, x + w, y + h))\n",
    "#         img = self.augment(img)\n",
    "#         img = self.transform(img)\n",
    "    \n",
    "#         label = torch.tensor(ann['label'], dtype=torch.long)    \n",
    "#         target = torch.tensor(ann['target'], dtype=torch.float32)\n",
    "    \n",
    "#         message = {\n",
    "#             \"label\": label,  \n",
    "#             \"target\": target,  \n",
    "#             \"img\": img \n",
    "#         }\n",
    "    \n",
    "#         return message\n",
    "\n",
    "\n",
    "#     def get_placeholder_image(self):\n",
    "#         return Image.new('RGB', (256, 256), color = 'gray')\n",
    "\n",
    "#     @staticmethod\n",
    "#     def parse_s3_path(s3_path):\n",
    "#         if not s3_path.startswith(\"s3://\"):\n",
    "#             raise ValueError(f\"Invalid S3 path: {s3_path}\")\n",
    "#         s3_path = s3_path[5:]\n",
    "#         bucket, key = s3_path.split('/', 1)\n",
    "#         return bucket, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f9594ae-71a7-40a7-8c7a-bd24aaac4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### now available using \"from data.data_loader import\" #########################\n",
    "\n",
    "# def load_wider(batch_size=64, subset_size=None):\n",
    "\n",
    "#     train_augs = ['randomflip', 'ColorJitter', 'resizedcrop', 'RandAugment']\n",
    "#     test_augs = []  \n",
    "#     img_size = 256 \n",
    "    \n",
    "#     train_dataset = DataSet(\n",
    "#         ann_files=['s3://210bucket/wider_attribute_annotation/wider_attribute_trainval.json'],  \n",
    "#         augs=train_augs,\n",
    "#         img_size=img_size,\n",
    "#         dataset='wider'\n",
    "#     )\n",
    "    \n",
    "#     test_dataset = DataSet(\n",
    "#         ann_files=['s3://210bucket/wider_attribute_annotation/wider_attribute_test.json'], \n",
    "#         augs=test_augs,\n",
    "#         img_size=img_size,\n",
    "#         dataset='wider'\n",
    "#     )\n",
    "    \n",
    "#     if subset_size is not None:\n",
    "#         train_indices = np.random.choice(len(train_dataset), subset_size, replace=False)\n",
    "#         test_indices = np.random.choice(len(test_dataset), subset_size, replace=False)\n",
    "        \n",
    "#         train_subset = Subset(train_dataset, train_indices)\n",
    "#         test_subset = Subset(test_dataset, test_indices)\n",
    "        \n",
    "#         train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "#         test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "#     else:\n",
    "#         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708ee75d-2c9f-4f41-bb28-101fb565f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded annotations: 28345\n",
      "Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ColorJitter(brightness=(0.5, 1.5), contrast=(0.5, 1.5), saturation=(0.5, 1.5), hue=None)\n",
      "    RandomResizedCrop(size=(256, 256), scale=(0.7, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Loaded annotations: 29179\n",
      "Compose(\n",
      "    Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader  = load_wider(batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
