{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e057459-072c-4cc9-9547-5fb77dfbf36b",
   "metadata": {},
   "source": [
    "## WIDER Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fd4796-6aec-42af-9e21-413c8841c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef039b2-3250-430b-87fd-afec88e8bd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import boto3\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms, RandAugment\n",
    "import torch\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ]\n",
    "        )\n",
    "        self.anns = []\n",
    "        self.s3_client = boto3.client('s3')  # Initialize the S3 client\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs: # need to review RandAugment()\n",
    "            t.append(RandAugment())\n",
    "            # t.append(transforms.RandomApply([\n",
    "            #     transforms.RandomRotation(degrees=10),\n",
    "            #     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            #     transforms.RandomPerspective(distortion_scale=0.05)\n",
    "            # ], p=0.5))\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "    \n",
    "        return transforms.Compose(t)\n",
    "\n",
    "\n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            bucket, key = self.parse_s3_path(ann_file)\n",
    "            response = self.s3_client.get_object(Bucket=bucket, Key=key)\n",
    "            json_data = json.loads(response['Body'].read())\n",
    "            self.anns += json_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        bucket, key = self.parse_s3_path(ann[\"img_path\"])\n",
    "        response = self.s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        img = Image.open(io.BytesIO(response['Body'].read())).convert(\"RGB\")\n",
    "\n",
    "        if self.dataset == \"wider\":\n",
    "            x, y, w, h = ann['bbox']\n",
    "            img = img.crop([x, y, x+w, y+h])\n",
    "        \n",
    "        img = self.augment(img)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        message = {\n",
    "            \"img_path\": ann['img_path'],\n",
    "            \"target\": torch.tensor(ann['target']),\n",
    "            \"img\": img\n",
    "        }\n",
    "        return message\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_s3_path(s3_path):\n",
    "        if not s3_path.startswith(\"s3://\"):\n",
    "            raise ValueError(f\"Invalid S3 path: {s3_path}\")\n",
    "        s3_path = s3_path[5:]\n",
    "        bucket, key = s3_path.split('/', 1)\n",
    "        return bucket, key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae875e97-3cdd-4d4b-a77b-ba6050e03b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def load_wider(batch_size=64):\n",
    "\n",
    "    # Define transformations and augmentations\n",
    "    train_augs = ['randomflip', 'ColorJitter', 'resizedcrop', 'RandAugment']\n",
    "    test_augs = []  \n",
    "    img_size = 256 \n",
    "    \n",
    "    train_dataset = DataSet(\n",
    "        ann_files=['s3://210bucket/wider_attribute_annotation/wider_attribute_trainval.json'],  \n",
    "        augs=train_augs,\n",
    "        img_size=img_size,\n",
    "        dataset='wider'\n",
    "    )\n",
    "    \n",
    "    test_dataset = DataSet(\n",
    "        ann_files=['s3://210bucket/wider_attribute_annotation/wider_attribute_test.json'], \n",
    "        augs=test_augs,\n",
    "        img_size=img_size,\n",
    "        dataset='wider'\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d511f2e9-3845-48b6-97d2-ab1cb96226f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ColorJitter(brightness=(0.5, 1.5), contrast=(0.5, 1.5), saturation=(0.5, 1.5), hue=None)\n",
      "    RandomResizedCrop(size=(256, 256), scale=(0.7, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=warn)\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(256, 256), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader  = load_wider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469db80-e536-4082-a9df-95786efe286f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
