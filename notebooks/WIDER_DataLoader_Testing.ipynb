{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e057459-072c-4cc9-9547-5fb77dfbf36b",
   "metadata": {},
   "source": [
    "## WIDER Dataset - DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9fd4796-6aec-42af-9e21-413c8841c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66acd606-5ac6-4a16-92c4-59d34d57861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import boto3\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision.transforms import transforms, RandAugment\n",
    "import torch\n",
    "import tarfile\n",
    "import os\n",
    "import getpass\n",
    "import s3fs\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from data.data_loader import load_cifar10, load_cifar100, load_imagenet, load_prof, load_wider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619a55be-ed9a-4a8a-a16e-8725a011a310",
   "metadata": {},
   "source": [
    "### Data Download - Do not need to repeat this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e679eef-7c26-4ac3-9b73-a8310d9d94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "# # !aws s3 cp s3://210bucket/wider_attribute_image.tgz ./wider_attribute_image.tgz\n",
    "# Option 2\n",
    "# s3 = boto3.client('s3')\n",
    "# s3.download_file('210bucket', 'wider_attribute_image.tgz', 'wider_attribute_image.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f2e4c-61bc-4c4c-8aae-596d37c60768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the .tgz file\n",
    "# with tarfile.open('wider_attribute_image.tgz', 'r:gz') as tar:\n",
    "#     tar.extractall(path=\"local_wider\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d2d531-4065-4e23-b186-ab9248633d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Upload the image files to s3 Bukcet\n",
    "# s3 = boto3.client('s3')\n",
    "\n",
    "# def upload_dir_to_s3(bucket_name, s3_folder, local_dir):\n",
    "#     for root, dirs, files in os.walk(local_dir):\n",
    "#         for file in files:\n",
    "#             local_path = os.path.join(root, file)\n",
    "#             relative_path = os.path.relpath(local_path, local_dir)\n",
    "#             s3_path = os.path.join(s3_folder, relative_path)\n",
    "            \n",
    "#             s3.upload_file(local_path, bucket_name, s3_path)\n",
    "\n",
    "# upload_dir_to_s3('210bucket', 'WIDER/', 'WIDER/Image/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239f8ac-8c25-46b1-b7dd-f602145f1b91",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee7cfbca-1ceb-4e2b-8891-a8e8ee73b17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################## now available using \"from data.data_loader import\" #########################\n",
    "\n",
    "# class DataSet(Dataset):\n",
    "#     def __init__(self, ann_files, augs, img_size, dataset, undersampe=False):\n",
    "#         self.dataset = dataset\n",
    "#         self.ann_files = ann_files\n",
    "#         self.augment = self.augs_function(augs, img_size)\n",
    "#         self.transform = transforms.Compose(\n",
    "#             [\n",
    "#                 transforms.ToTensor(),\n",
    "#                 transforms.Normalize(mean=[0, 0, 0], \n",
    "#                                      std=[1, 1, 1])\n",
    "#             ]\n",
    "#         )\n",
    "#         self.anns = []\n",
    "#         self.s3_client = boto3.client('s3') \n",
    "#         self.load_anns()\n",
    "#         print(self.augment)\n",
    "\n",
    "#         if self.dataset == \"wider\":\n",
    "#             self.transform = transforms.Compose(\n",
    "#                 [\n",
    "#                     transforms.ToTensor(),\n",
    "#                     transforms.Normalize(mean=[0.5, 0.5, 0.5], \n",
    "#                                          std=[0.5, 0.5, 0.5])\n",
    "#                 ]\n",
    "#             )\n",
    "\n",
    "#     def extract_label_from_filename(self, file_name):\n",
    "#         # Split the path and extract the part with '--'\n",
    "#         parts = file_name.split('/')\n",
    "#         for part in parts:\n",
    "#             if '--' in part:\n",
    "#                 # Extract the numeric part before '--'\n",
    "#                 label = part.split('--')[0]\n",
    "#                 if label.isdigit():\n",
    "#                     return int(label)  # Return as an integer\n",
    "#         raise ValueError(f\"Label not found in file name: {file_name}\")\n",
    "\n",
    "        \n",
    "\n",
    "#     def augs_function(self, augs, img_size):            \n",
    "#         t = []\n",
    "#         if 'randomflip' in augs:\n",
    "#             t.append(transforms.RandomHorizontalFlip())\n",
    "#         if 'ColorJitter' in augs:\n",
    "#             t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "#         if 'resizedcrop' in augs:\n",
    "#             t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "#         if 'RandAugment' in augs: # need to review RandAugment()\n",
    "#             t.append(RandAugment())\n",
    "#             # t.append(transforms.RandomApply([\n",
    "#             #     transforms.RandomRotation(degrees=10),\n",
    "#             #     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "#             #     transforms.RandomPerspective(distortion_scale=0.05)\n",
    "#             # ], p=0.5))\n",
    "\n",
    "#         t.append(transforms.Resize((img_size, img_size)))\n",
    "    \n",
    "#         return transforms.Compose(t)\n",
    "\n",
    "#     def load_anns(self):\n",
    "#         s3_client = boto3.client('s3')\n",
    "#         self.anns = []\n",
    "#         for ann_file in self.ann_files:\n",
    "#             bucket, key = self.parse_s3_path(ann_file)\n",
    "#             response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "#             json_data = json.loads(response['Body'].read())\n",
    "#             for image in json_data['images']:\n",
    "#                 file_name = image['file_name']\n",
    "#                 label = self.extract_label_from_filename(file_name)  # Use the new method\n",
    "#                 for target in image['targets']:\n",
    "#                     ann = {\n",
    "#                         'img_path': f's3://210bucket/WIDER/{file_name}',\n",
    "#                         'bbox': target['bbox'],\n",
    "#                         'label': label,  \n",
    "#                         'target': target['attribute']\n",
    "#                     }\n",
    "#                     self.anns.append(ann)\n",
    "#         print(f\"Loaded annotations: {len(self.anns)}\")\n",
    "\n",
    "\n",
    "#     def undersample_anns(self):\n",
    "#         # Shuffle annotations before undersampling\n",
    "#         random.shuffle(self.anns)\n",
    "\n",
    "#         # Count the instances per class\n",
    "#         class_counts = {}\n",
    "#         for ann in self.anns:\n",
    "#             label = self.extract_label(ann['img_path'])  # Assuming this method returns the class label\n",
    "#             class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "#         # Find the minimum class count\n",
    "#         min_count = min(class_counts.values())\n",
    "\n",
    "#         # Perform undersampling\n",
    "#         undersampled_anns = []\n",
    "#         current_counts = {label: 0 for label in class_counts}\n",
    "#         for ann in self.anns:\n",
    "#             label = self.extract_label(ann['img_path'])\n",
    "#             if current_counts[label] < min_count:\n",
    "#                 undersampled_anns.append(ann)\n",
    "#                 current_counts[label] += 1\n",
    "\n",
    "#         # Update the annotations to the undersampled list\n",
    "#         self.anns = undersampled_anns\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.anns)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         idx = idx % len(self)\n",
    "#         ann = self.anns[idx]\n",
    "    \n",
    "#         if not isinstance(ann, dict) or \"img_path\" not in ann:\n",
    "#             raise ValueError(f\"Annotation at index {idx} is not a dictionary with an 'img_path' key: {ann}\")\n",
    "    \n",
    "#         bucket, key = self.parse_s3_path(ann[\"img_path\"])\n",
    "#         try:\n",
    "#             response = self.s3_client.get_object(Bucket=bucket, Key=key)\n",
    "#             img = Image.open(io.BytesIO(response['Body'].read())).convert(\"RGB\")\n",
    "#         except self.s3_client.exceptions.NoSuchKey:\n",
    "#             print(f\"File not found: s3://{bucket}/{key}\")\n",
    "#             img = self.get_placeholder_image()\n",
    "#             return None \n",
    "    \n",
    "#         x, y, w, h = ann['bbox']\n",
    "#         img = img.crop((x, y, x + w, y + h))\n",
    "#         img = self.augment(img)\n",
    "#         img = self.transform(img)\n",
    "    \n",
    "#         label = torch.tensor(ann['label'], dtype=torch.long)    \n",
    "#         target = torch.tensor(ann['target'], dtype=torch.float32)\n",
    "    \n",
    "#         message = {\n",
    "#             \"label\": label,  \n",
    "#             \"target\": target,  \n",
    "#             \"img\": img \n",
    "#         }\n",
    "    \n",
    "#         return message\n",
    "\n",
    "\n",
    "#     def get_placeholder_image(self):\n",
    "#         return Image.new('RGB', (256, 256), color = 'gray')\n",
    "\n",
    "#     @staticmethod\n",
    "#     def parse_s3_path(s3_path):\n",
    "#         if not s3_path.startswith(\"s3://\"):\n",
    "#             raise ValueError(f\"Invalid S3 path: {s3_path}\")\n",
    "#         s3_path = s3_path[5:]\n",
    "#         bucket, key = s3_path.split('/', 1)\n",
    "#         return bucket, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bfe2428-0f48-4151-a1b9-a6a78b30e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################## now available using \"from data.data_loader import\" #########################\n",
    "\n",
    "# def load_wider(batch_size=64, subset_size=None):\n",
    "\n",
    "#     train_augs = ['randomflip', 'ColorJitter', 'resizedcrop', 'RandAugment']\n",
    "#     test_augs = []  \n",
    "#     img_size = 256 \n",
    "    \n",
    "#     train_dataset = DataSet(\n",
    "#         ann_files=['s3://210bucket/wider_attribute_annotation/wider_attribute_trainval.json'],  \n",
    "#         augs=train_augs,\n",
    "#         img_size=img_size,\n",
    "#         dataset='wider'\n",
    "#     )\n",
    "    \n",
    "#     test_dataset = DataSet(\n",
    "#         ann_files=['s3://210bucket/wider_attribute_annotation/wider_attribute_test.json'], \n",
    "#         augs=test_augs,\n",
    "#         img_size=img_size,\n",
    "#         dataset='wider'\n",
    "#     )\n",
    "    \n",
    "#     if subset_size is not None:\n",
    "#         train_indices = np.random.choice(len(train_dataset), subset_size, replace=False)\n",
    "#         test_indices = np.random.choice(len(test_dataset), subset_size, replace=False)\n",
    "        \n",
    "#         train_subset = Subset(train_dataset, train_indices)\n",
    "#         test_subset = Subset(test_dataset, test_indices)\n",
    "        \n",
    "#         train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "#         test_loader = DataLoader(test_subset, batch_size=batch_size, shuffle=False)\n",
    "#     else:\n",
    "#         train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#         test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b168947-30a1-4b77-ac09-389fbddcc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## now available using \"from data.data_loader import\" #########################\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset, undersampe=False):\n",
    "\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], \n",
    "                                     std=[1, 1, 1])\n",
    "            ]\n",
    "        )\n",
    "        self.anns = []\n",
    "        self.s3_client = boto3.client('s3') \n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.5, 0.5, 0.5], \n",
    "                                         std=[0.5, 0.5, 0.5])\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    def extract_label_from_filename(self, file_name):\n",
    "        # Split the path and extract the part with '--'\n",
    "        parts = file_name.split('/')\n",
    "        for part in parts:\n",
    "            if '--' in part:\n",
    "                # Extract the numeric part before '--'\n",
    "                label = part.split('--')[0]\n",
    "                if label.isdigit():\n",
    "                    return int(label)  # Return as an integer\n",
    "        raise ValueError(f\"Label not found in file name: {file_name}\")\n",
    "\n",
    "        if label is not None:\n",
    "            remapped_label = self.label_mapping[label]\n",
    "            return remapped_label\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n",
    "\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs: # need to review RandAugment()\n",
    "            t.append(RandAugment())\n",
    "            # t.append(transforms.RandomApply([\n",
    "            #     transforms.RandomRotation(degrees=10),\n",
    "            #     transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "            #     transforms.RandomPerspective(distortion_scale=0.05)\n",
    "            # ], p=0.5))\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "    \n",
    "        return transforms.Compose(t)\n",
    "\n",
    "    def load_anns(self):\n",
    "        s3_client = boto3.client('s3')\n",
    "        self.anns = []\n",
    "\n",
    "        for ann_file in self.ann_files:\n",
    "            bucket, key = self.parse_s3_path(ann_file)\n",
    "            response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "            json_data = json.loads(response['Body'].read())\n",
    "\n",
    "        \n",
    "        for image in json_data['images']:\n",
    "            file_name = image['file_name']\n",
    "            label = self.extract_label_from_filename(file_name)  # Use the new method\n",
    "            for target in image['targets']:\n",
    "                ann = {\n",
    "                    'img_path': f's3://210bucket/WIDER/{file_name}',\n",
    "                    'bbox': target['bbox'],\n",
    "                    'label': label,  \n",
    "                    'targets': target['attribute']\n",
    "                }\n",
    "                self.anns.append(ann)\n",
    "                \n",
    "        print(f\"Loaded annotations: {len(self.anns)}\")\n",
    "\n",
    "        # for ann_file in self.ann_files:\n",
    "        #     bucket, key = self.parse_s3_path(ann_file)\n",
    "        #     response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "        #     json_data = json.loads(response['Body'].read())\n",
    "        #     self.anns += json_data\n",
    "            \n",
    "        #     display(json_data)\n",
    "            \n",
    "        # print(f\"Loaded annotations: {len(self.anns)}\")\n",
    "\n",
    "    \n",
    "    def undersample_anns(self):\n",
    "        # Shuffle annotations before undersampling\n",
    "        random.shuffle(self.anns)\n",
    "\n",
    "        # Count the instances per class\n",
    "        class_counts = {}\n",
    "        for ann in self.anns:\n",
    "            label = self.extract_label_from_filename(ann['img_path'])  # Assuming this method returns the class label\n",
    "            class_counts[label] = class_counts.get(label, 0) + 1\n",
    "\n",
    "        # Find the minimum class count\n",
    "        min_count = min(class_counts.values())\n",
    "\n",
    "        # Perform undersampling\n",
    "        undersampled_anns = []\n",
    "        current_counts = {label: 0 for label in class_counts}\n",
    "        for ann in self.anns:\n",
    "            label = self.extract_label_from_filename(ann['img_path'])\n",
    "            if current_counts[label] < min_count:\n",
    "                undersampled_anns.append(ann)\n",
    "                current_counts[label] += 1\n",
    "\n",
    "        # Update the annotations to the undersampled list\n",
    "        self.anns = undersampled_anns\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "    \n",
    "        if not isinstance(ann, dict) or \"img_path\" not in ann:\n",
    "            raise ValueError(f\"Annotation at index {idx} is not a dictionary with an 'img_path' key: {ann}\")\n",
    "    \n",
    "        bucket, key = self.parse_s3_path(ann[\"img_path\"])\n",
    "        try:\n",
    "            response = self.s3_client.get_object(Bucket=bucket, Key=key)\n",
    "            img = Image.open(io.BytesIO(response['Body'].read())).convert(\"RGB\")\n",
    "        except self.s3_client.exceptions.NoSuchKey:\n",
    "            print(f\"File not found: s3://{bucket}/{key}\")\n",
    "            img = self.get_placeholder_image()\n",
    "            return None \n",
    "    \n",
    "        x, y, w, h = ann['bbox']\n",
    "        img = img.crop((x, y, x + w, y + h))\n",
    "        img = self.augment(img)\n",
    "        img = self.transform(img)\n",
    "        img_path = io.BytesIO(response['Body'].read())\n",
    "        label = self.extract_label_from_filename(ann[\"img_path\"]) \n",
    "\n",
    "        # attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "        # summed_attributes = [max(sum(attribute), 0) for attribute in zip(*attributes_list)]\n",
    "\n",
    "        # display(ann['targets'])\n",
    "        \n",
    "        # if isinstance(ann['targets'], list):\n",
    "        #     attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "        #     summed_attributes = [max(sum(attribute), 0) for attribute in zip(*attributes_list)]\n",
    "\n",
    "        # elif isinstance(ann['targets'], int):\n",
    "        #     # If 'target' is a single integer, handle it accordingly\n",
    "        #     summed_attributes = [ann['targets']]\n",
    "        # else:\n",
    "        #     # Handle other cases or unknown structures\n",
    "        #     print(f\"Unknown structure for 'target' in ann: {ann}\")\n",
    "        #     summed_attributes = []\n",
    "\n",
    "        # target_tensor = torch.tensor(summed_attributes, dtype=torch.float32)\n",
    "\n",
    "        # target = torch.Tensor(summed_attributes)\n",
    "        target = torch.tensor(ann['targets'], dtype=torch.float32)\n",
    "        \n",
    "        message = {\n",
    "            \"label\": label,  \n",
    "            \"target\": target,  \n",
    "            \"img\": img \n",
    "        }\n",
    "    \n",
    "        return message\n",
    "\n",
    "\n",
    "    def get_placeholder_image(self):\n",
    "        return Image.new('RGB', (256, 256), color = 'gray')\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_s3_path(s3_path):\n",
    "        if not s3_path.startswith(\"s3://\"):\n",
    "            raise ValueError(f\"Invalid S3 path: {s3_path}\")\n",
    "        s3_path = s3_path[5:]\n",
    "        bucket, key = s3_path.split('/', 1)\n",
    "        return bucket, key\n",
    "\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            return remapped_label\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "125b85bd-13ec-4638-9969-a903d633d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        # Option 1: Return a placeholder tensor (adapt the shape to match your data)\n",
    "        # return torch.tensor([]), torch.tensor([])\n",
    "        # Option 2: Raise an exception\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "addba717-7718-456b-86c1-efe996ea79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 30\n",
    "batch_size = 372\n",
    "num_workers = 4\n",
    "\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f9594ae-71a7-40a7-8c7a-bd24aaac4bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded annotations: 29179\n",
      "Compose(\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Loaded annotations: 28345\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_file = ['s3://210bucket/wider_attribute_annotation/wider_attribute_test.json']\n",
    "test_file = ['s3://210bucket/wider_attribute_annotation/wider_attribute_trainval.json']\n",
    "\n",
    "train_dataset = DataSet(train_file, augs=['RandAugment'], img_size=226, dataset='wider')\n",
    "test_dataset = DataSet(test_file, augs=[], img_size=226, dataset='wider')\n",
    "\n",
    "\n",
    "# trainloader = DataLoader(train_dataset, \n",
    "#                           batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=custom_collate)\n",
    "# testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "708ee75d-2c9f-4f41-bb28-101fb565f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader, testloader  = load_wider(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "05a27aa7-bb8b-43c3-8554-e78f0e74d674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'target': tensor([ 1., -1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1.]),\n",
       " 'img': tensor([[[ 0.3020,  0.3020,  0.3176,  ..., -0.4588, -0.4275, -0.4275],\n",
       "          [ 0.9686,  0.9686,  0.9608,  ..., -0.4902, -0.4902, -0.4902],\n",
       "          [ 0.9686,  0.9686,  0.9686,  ..., -0.0431, -0.0118, -0.0118],\n",
       "          ...,\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "         [[ 0.3098,  0.3098,  0.3255,  ..., -0.4510, -0.4196, -0.4196],\n",
       "          [ 0.9765,  0.9765,  0.9686,  ..., -0.4824, -0.4824, -0.4824],\n",
       "          [ 0.9686,  0.9686,  0.9686,  ..., -0.0353, -0.0039, -0.0039],\n",
       "          ...,\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "         [[ 0.2000,  0.2000,  0.2157,  ..., -0.5608, -0.5294, -0.5294],\n",
       "          [ 0.8667,  0.8667,  0.8588,  ..., -0.5922, -0.5922, -0.5922],\n",
       "          [ 0.8745,  0.8745,  0.8824,  ..., -0.1451, -0.1137, -0.1137],\n",
       "          ...,\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]])}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fb71235c-05e8-43c5-aca6-ce2aab92ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, collate_fn=custom_collate)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec7ca5b-c1ec-4b91-a018-f44e181e1a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d6cb21-17da-4b68-ba34-27105f7fae0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "895dd851-7331-48a8-aeb0-e2786abd2253",
   "metadata": {},
   "source": [
    "## New WIDER DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "247a0b81-f8f9-463e-bd61-14160af3530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import boto3\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms, RandAugment\n",
    "import torch\n",
    "import tarfile\n",
    "import os\n",
    "import getpass\n",
    "import s3fs\n",
    "import json\n",
    "from urllib.parse import urlparse\n",
    "from data.data_loader import load_cifar10, load_cifar100, load_imagenet, load_prof, load_wider\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f0701d-68a9-4920-8967-b180583f0b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001379 # 0.096779\n",
    "num_epochs = 15 # 200\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "num_classes = 30\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "beta = 0.0\n",
    "patience = 7  # for early stopping\n",
    "\n",
    "batch_size = 372\n",
    "num_workers = 4\n",
    "\n",
    "# class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "# class_labels_new = torch.tensor([i for i in range(len(class_labels))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6e4857-5df5-46ec-857e-2aaf7366713c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchvision.transforms.RandAugment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "749f86d0-cbfe-4d96-b4f7-1271fbf54c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader = load_wider(batch_size, num_workers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6e4c7-bf28-4259-8088-3031d113b9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
