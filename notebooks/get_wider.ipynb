{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f2ff1-23e6-4c8d-85d7-f4196bb34bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from shutil import move\n",
    "import s3fs\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b6d2a-2937-400a-a0da-601fcef20f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_key = getpass.getpass(\"Enter your access: \")\n",
    "\n",
    "secret_key = password = getpass.getpass(\"Enter your secret: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ad2ee-4b83-4ca0-a74c-8f0abc2cb46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to get images onto EC2\n",
    "\n",
    "wider_dir = './WIDER'\n",
    "if not os.path.exists(wider_dir):\n",
    "    os.makedirs(wider_dir)\n",
    "\n",
    "# Specify your S3 bucket and file path\n",
    "bucket_name = '210bucket'\n",
    "s3_file_path = 'wider_attribute_image.tgz'\n",
    "\n",
    "# Initialize an S3 filesystem\n",
    "s3 = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "\n",
    "# Download the .tgz file from S3\n",
    "with s3.open(f\"{bucket_name}/{s3_file_path}\", 'rb') as s3_file:\n",
    "    with tarfile.open(fileobj=s3_file, mode=\"r:gz\") as tar:\n",
    "        # Specify the destination directory where you want to store the extracted contents\n",
    "        extract_dir = wider_dir # Change this to your desired directory\n",
    "        tar.extractall(path=extract_dir)\n",
    "\n",
    "print(\"File downloaded and extracted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891a975-3ef3-447a-a06f-31015b428c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your S3 bucket and directory path\n",
    "s3_directory_path = 'wider_attribute_annotation/'\n",
    "\n",
    "local_directory = './WIDER/Annotations'  # Change this to your desired directory\n",
    "\n",
    "s3_files = s3.ls(f\"{bucket_name}/{s3_directory_path}\")\n",
    "\n",
    "\n",
    "# Create the local directory if it doesn't exist\n",
    "os.makedirs(local_directory, exist_ok=True)\n",
    "\n",
    "# Download each file from the S3 directory to the local directory\n",
    "for s3_file in s3_files:\n",
    "    # Get the filename from the S3 file path\n",
    "    filename = os.path.basename(s3_file)\n",
    "    \n",
    "    # Download the file to the local directory\n",
    "    local_path = os.path.join(local_directory, filename)\n",
    "    with s3.open(s3_file, 'rb') as s3_file_obj:\n",
    "        with open(local_path, 'wb') as local_file:\n",
    "            local_file.write(s3_file_obj.read())\n",
    "\n",
    "print(\"Files downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09cfb64-d1dd-46e4-ac30-64e73064ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_move_images(json_data, trainval_json, split_ratio=0.5):\n",
    "    # Create a dictionary to store images by class\n",
    "    class_images = {}\n",
    "    for i in json_data['images']:\n",
    "        scene_id = i['scene_id']\n",
    "        file_name = i['file_name']\n",
    "        image_data = i['targets']\n",
    "\n",
    "        # Add the image to the class_images dictionary\n",
    "        if scene_id not in class_images:\n",
    "            class_images[scene_id] = []\n",
    "        class_images[scene_id].append({'scene_id': scene_id, 'file_name': file_name, 'targets': image_data})\n",
    "    \n",
    "    # Create wider_attribute_trainval.json\n",
    "    trainval_data = []\n",
    "\n",
    "    # Process each class\n",
    "    for scene_id, images in class_images.items():\n",
    "        # Shuffle the images in the class\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # Select half of the images\n",
    "        split_index = int(len(images) * split_ratio)\n",
    "        trainval_images = images[:split_index]\n",
    "        test_images = images[split_index:]\n",
    "\n",
    "        # Add selected images to wider_attribute_trainval.json\n",
    "        trainval_data.extend(trainval_images)\n",
    "\n",
    "        # Remove sampled images from test_data\n",
    "        for test_image in test_images:\n",
    "            json_data['images'].remove({'scene_id': scene_id, 'file_name': test_image['file_name'], 'targets': test_image['targets']})\n",
    "    \n",
    "    # Save updated wider_attribute_test.json\n",
    "    with open(\"WIDER/Annotations/wider_attribute_test.json\", 'w') as test_file:\n",
    "        json.dump(json_data, test_file)\n",
    "\n",
    "    with open(trainval_json, 'r') as trainval_file:\n",
    "        existing_data = json.load(trainval_file)\n",
    "\n",
    "    # Update the existing 'images' values with trainval_data\n",
    "    existing_data['images'].extend(trainval_data)\n",
    "\n",
    "    # Write the updated data back to the file\n",
    "    with open(trainval_json, 'w') as trainval_file:\n",
    "        json.dump(existing_data, trainval_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load wider_attribute_test.json\n",
    "    with open(\"WIDER/Annotations/wider_attribute_test.json\", 'r') as test_file:\n",
    "        test_data = json.load(test_file)\n",
    "\n",
    "    # Define the path for wider_attribute_trainval.json\n",
    "    trainval_json_path = \"WIDER/Annotations/wider_attribute_trainval.json\"\n",
    "\n",
    "    # Call the function to split and move images\n",
    "    split_and_move_images(test_data, trainval_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa707daa-70c2-4f3f-875f-1514c18f333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_wider(tag, data_path):\n",
    "#     img_path = os.path.join(data_path, \"Image\")\n",
    "#     ann_path = os.path.join(data_path, \"Annotations\")\n",
    "#     ann_file = os.path.join(ann_path, \"wider_attribute_{}.json\".format(tag))\n",
    "\n",
    "#     data = json.load(open(ann_file, \"r\"))\n",
    "\n",
    "#     image_list = data['images']\n",
    "#     # for image in image_list:\n",
    "#     #     for person in image[\"targets\"]: # iterate over each person\n",
    "#     #         tmp = {}\n",
    "#     #         tmp['img_path'] = os.path.join(img_path, image['file_name'])\n",
    "#     #         tmp['bbox'] = person['bbox']\n",
    "#     #         attr = person[\"attribute\"]\n",
    "#     #         for i, item in enumerate(attr):\n",
    "#     #             if item == -1:\n",
    "#     #                 attr[i] = 0\n",
    "#     #             if item == 0:\n",
    "#     #                 attr[i] = 0  # pad un-specified samples\n",
    "#     #             if item == 1:\n",
    "#     #                 attr[i] = 1\n",
    "#     #         tmp[\"target\"] = attr\n",
    "#     #         final.append(tmp)\n",
    "\n",
    "#     json.dump(image_list, open(\"data/wider/{}_wider.json\".format(tag), \"w\"))\n",
    "#     print(\"data/wider/{}_wider.json\".format(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e6c3c1-5b2d-48d2-b13f-ef74433f83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #run once\n",
    "# if not os.path.exists(\"data/wider\"):\n",
    "#     os.makedirs(\"data/wider\")\n",
    "\n",
    "# # 0 (zero) means negative, we treat un-specified attribute as negative in the trainval set\n",
    "# make_wider(tag='trainval', data_path='WIDER') \n",
    "# make_wider(tag='test', data_path='WIDER')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
