{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9f2ff1-23e6-4c8d-85d7-f4196bb34bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from shutil import move\n",
    "import s3fs\n",
    "import json\n",
    "import getpass\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442b6d2a-2937-400a-a0da-601fcef20f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your access:  ········\n",
      "Enter your secret:  ········\n"
     ]
    }
   ],
   "source": [
    "# access_key = getpass.getpass(\"Enter your access: \")\n",
    "\n",
    "# secret_key = password = getpass.getpass(\"Enter your secret: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f85ad2ee-4b83-4ca0-a74c-8f0abc2cb46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# # Run once to get images onto EC2\n",
    "\n",
    "# wider_dir = './WIDER'\n",
    "# if not os.path.exists(wider_dir):\n",
    "#     os.makedirs(wider_dir)\n",
    "\n",
    "# # Specify your S3 bucket and file path\n",
    "# bucket_name = '210bucket'\n",
    "# s3_file_path = 'wider_attribute_image.tgz'\n",
    "\n",
    "# # Initialize an S3 filesystem\n",
    "# s3 = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "\n",
    "# # Download the .tgz file from S3\n",
    "# with s3.open(f\"{bucket_name}/{s3_file_path}\", 'rb') as s3_file:\n",
    "#     with tarfile.open(fileobj=s3_file, mode=\"r:gz\") as tar:\n",
    "#         # Specify the destination directory where you want to store the extracted contents\n",
    "#         extract_dir = wider_dir # Change this to your desired directory\n",
    "#         tar.extractall(path=extract_dir)\n",
    "\n",
    "# print(\"File downloaded and extracted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d891a975-3ef3-447a-a06f-31015b428c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# # Specify your S3 bucket and directory path\n",
    "# s3_directory_path = 'wider_attribute_annotation/'\n",
    "\n",
    "# local_directory = './WIDER/Annotations'  # Change this to your desired directory\n",
    "\n",
    "# s3_files = s3.ls(f\"{bucket_name}/{s3_directory_path}\")\n",
    "\n",
    "\n",
    "# # Create the local directory if it doesn't exist\n",
    "# os.makedirs(local_directory, exist_ok=True)\n",
    "\n",
    "# # Download each file from the S3 directory to the local directory\n",
    "# for s3_file in s3_files:\n",
    "#     # Get the filename from the S3 file path\n",
    "#     filename = os.path.basename(s3_file)\n",
    "    \n",
    "#     # Download the file to the local directory\n",
    "#     local_path = os.path.join(local_directory, filename)\n",
    "#     with s3.open(s3_file, 'rb') as s3_file_obj:\n",
    "#         with open(local_path, 'wb') as local_file:\n",
    "#             local_file.write(s3_file_obj.read())\n",
    "\n",
    "# print(\"Files downloaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09cfb64-d1dd-46e4-ac30-64e73064ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def split_and_move_images(json_data, trainval_json, split_ratio=0.5):\n",
    "#     # Create a dictionary to store images by class\n",
    "#     class_images = {}\n",
    "#     for i in json_data['images']:\n",
    "#         scene_id = i['scene_id']\n",
    "#         file_name = i['file_name']\n",
    "#         image_data = i['targets']\n",
    "\n",
    "#         # Add the image to the class_images dictionary\n",
    "#         if scene_id not in class_images:\n",
    "#             class_images[scene_id] = []\n",
    "#         class_images[scene_id].append({'scene_id': scene_id, 'file_name': file_name, 'targets': image_data})\n",
    "    \n",
    "#     # Create wider_attribute_trainval.json\n",
    "#     trainval_data = []\n",
    "\n",
    "#     # Process each class\n",
    "#     for scene_id, images in class_images.items():\n",
    "#         # Shuffle the images in the class\n",
    "#         random.shuffle(images)\n",
    "\n",
    "#         # Select half of the images\n",
    "#         split_index = int(len(images) * split_ratio)\n",
    "#         trainval_images = images[:split_index]\n",
    "#         test_images = images[split_index:]\n",
    "\n",
    "#         # Add selected images to wider_attribute_trainval.json\n",
    "#         trainval_data.extend(trainval_images)\n",
    "\n",
    "#         # Remove sampled images from test_data\n",
    "#         for trainval in trainval_images:\n",
    "#             json_data['images'].remove({'scene_id': scene_id, 'file_name': trainval['file_name'], 'targets': trainval['targets']})\n",
    "    \n",
    "#     # Save updated wider_attribute_test.json\n",
    "#     with open(\"WIDER/Annotations/wider_attribute_test.json\", 'w') as test_file:\n",
    "#         json.dump(json_data, test_file)\n",
    "\n",
    "#     with open(trainval_json, 'r') as trainval_file:\n",
    "#         existing_data = json.load(trainval_file)\n",
    "\n",
    "#     # Update the existing 'images' values with trainval_data\n",
    "#     existing_data['images'].extend(trainval_data)\n",
    "\n",
    "#     # Write the updated data back to the file\n",
    "#     with open(trainval_json, 'w') as trainval_file:\n",
    "#         json.dump(existing_data, trainval_file)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Load wider_attribute_test.json\n",
    "#     with open(\"WIDER/Annotations/wider_attribute_test.json\", 'r') as test_file:\n",
    "#         test_data = json.load(test_file)\n",
    "\n",
    "#     # Define the path for wider_attribute_trainval.json\n",
    "#     trainval_json_path = \"WIDER/Annotations/wider_attribute_trainval.json\"\n",
    "\n",
    "#     # Call the function to split and move images\n",
    "#     split_and_move_images(test_data, trainval_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b45b985-083e-4fe6-8538-551499680bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Function to load and return the contents of a JSON file\n",
    "def load_json_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Load the JSON files\n",
    "test_data = load_json_file('WIDER/Annotations/wider_attribute_test.json')\n",
    "trainval_data = load_json_file('WIDER/Annotations/wider_attribute_trainval.json')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47638319-456d-40ed-aed6-cd409309f6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No common file names found.\n"
     ]
    }
   ],
   "source": [
    "# Function to extract file names from the JSON data\n",
    "def extract_file_names(json_data):\n",
    "    file_names = []\n",
    "    for image in json_data['images']:\n",
    "        file_names.append(image['file_name'])\n",
    "    return file_names\n",
    "\n",
    "# Extract file names from each dataset\n",
    "test_file_names = extract_file_names(test_data)\n",
    "trainval_file_names = extract_file_names(trainval_data)\n",
    "\n",
    "# Convert lists to sets and find common elements\n",
    "common_file_names = set(test_file_names) & set(trainval_file_names)\n",
    "\n",
    "# Check if there are any common file names and print the count\n",
    "if common_file_names:\n",
    "    print(\"Number of common file names:\", len(common_file_names))\n",
    "    print(\"Common file names:\", common_file_names)\n",
    "else:\n",
    "    print(\"No common file names found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c36c06-c181-4cc8-9684-7b8cebc61852",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train/25--Soldier_Patrol/25_Soldier_Patrol_Soldier_Patrol_25_340.jpg' in trainval_file_names:\n",
    "    print('file found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c2c89a-9f64-4ec6-9781-da8ccdb2ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train/25--Soldier_Patrol/25_Soldier_Patrol_Soldier_Patrol_25_340.jpg' in trainval_file_names:\n",
    "    print('file found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "780b6d10-0259-4187-bd3c-47c89f8f3752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec4a0d7-a8e8-4d65-8930-014f5541eeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10324"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainval_file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa707daa-70c2-4f3f-875f-1514c18f333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_wider(tag, data_path):\n",
    "    img_path = os.path.join(data_path, \"Image\")\n",
    "    ann_path = os.path.join(data_path, \"Annotations\")\n",
    "    ann_file = os.path.join(ann_path, \"wider_attribute_{}.json\".format(tag))\n",
    "\n",
    "    data = json.load(open(ann_file, \"r\"))\n",
    "\n",
    "    image_list = data['images']\n",
    "    # for image in image_list:\n",
    "    #     for person in image[\"targets\"]: # iterate over each person\n",
    "    #         tmp = {}\n",
    "    #         tmp['img_path'] = os.path.join(img_path, image['file_name'])\n",
    "    #         tmp['bbox'] = person['bbox']\n",
    "    #         attr = person[\"attribute\"]\n",
    "    #         for i, item in enumerate(attr):\n",
    "    #             if item == -1:\n",
    "    #                 attr[i] = 0\n",
    "    #             if item == 0:\n",
    "    #                 attr[i] = 0  # pad un-specified samples\n",
    "    #             if item == 1:\n",
    "    #                 attr[i] = 1\n",
    "    #         tmp[\"target\"] = attr\n",
    "    #         final.append(tmp)\n",
    "\n",
    "    json.dump(image_list, open(\"data/wider/{}_wider.json\".format(tag), \"w\"))\n",
    "    print(\"data/wider/{}_wider.json\".format(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9e6c3c1-5b2d-48d2-b13f-ef74433f83d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/wider/trainval_wider.json\n",
      "data/wider/test_wider.json\n"
     ]
    }
   ],
   "source": [
    "#run once\n",
    "if not os.path.exists(\"data/wider\"):\n",
    "    os.makedirs(\"data/wider\")\n",
    "\n",
    "# 0 (zero) means negative, we treat un-specified attribute as negative in the trainval set\n",
    "make_wider(tag='trainval', data_path='WIDER') \n",
    "make_wider(tag='test', data_path='WIDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3e1d0-50bc-47c4-a1b5-da197bf7daa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
