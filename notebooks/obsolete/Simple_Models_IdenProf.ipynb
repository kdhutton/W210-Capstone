{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c972625-0d8d-41d0-9f18-5e60794d4c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost --quiet\n",
    "# !pip install --upgrade xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ff48206-d437-4652-b317-91a844b5050b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03b52ba7-a5ca-447f-a0f3-0d5d4db438ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pytorch - Dataloader\n",
    "\n",
    "# def load_prof_for_ml(train_path, test_path):\n",
    "\n",
    "#     transform = transforms.Compose([\n",
    "#         transforms.Resize((226, 226)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "    \n",
    "#     traindataset = datasets.ImageFolder(root=train_path, transform=transform)\n",
    "#     testdataset = datasets.ImageFolder(root=test_path, transform=transform)\n",
    "    \n",
    "#     # to a list of tuples with images and labels\n",
    "#     train_data = [(image.numpy(), label) for image, label in traindataset]\n",
    "#     test_data = [(image.numpy(), label) for image, label in testdataset]\n",
    "    \n",
    "#     # features and labels\n",
    "#     X_train, y_train = zip(*train_data)\n",
    "#     X_test, y_test = zip(*test_data)\n",
    "    \n",
    "#     # to numpy arrays\n",
    "#     X_train = torch.tensor(X_train).numpy().reshape(len(X_train), -1)\n",
    "#     X_test = torch.tensor(X_test).numpy().reshape(len(X_test), -1)\n",
    "#     y_train = torch.tensor(y_train).numpy()\n",
    "#     y_test = torch.tensor(y_test).numpy()\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e11c9f-d841-4905-95b1-6ed9eef40ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Pytorch\n",
    "\n",
    "def is_image_file(filename):\n",
    "    valid_extensions = [\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\"]\n",
    "    return any(filename.lower().endswith(ext) for ext in valid_extensions)\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if is_image_file(filename):\n",
    "            label = os.path.basename(folder)\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            with Image.open(img_path) as img:\n",
    "                img = img.convert('RGB')\n",
    "                img = img.resize((226, 226))\n",
    "                images.append(np.array(img))\n",
    "                labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def load_prof_for_ml(train_path, test_path):\n",
    "    X_train, y_train = [], []\n",
    "    X_test, y_test = [], []\n",
    "\n",
    "    for class_folder in os.listdir(train_path):\n",
    "        imgs, lbls = load_images_from_folder(os.path.join(train_path, class_folder))\n",
    "        X_train.extend(imgs)\n",
    "        y_train.extend(lbls)\n",
    "\n",
    "    for class_folder in os.listdir(test_path):\n",
    "        imgs, lbls = load_images_from_folder(os.path.join(test_path, class_folder))\n",
    "        X_test.extend(imgs)\n",
    "        y_test.extend(lbls)\n",
    "\n",
    "    X_train = np.array(X_train).reshape(len(X_train), -1)\n",
    "    X_test = np.array(X_test).reshape(len(X_test), -1)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_train = le.fit_transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb4d0e12-8836-44fc-94cf-717e95288c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/ubuntu/W210-Capstone/notebooks/idenprof/train'\n",
    "test_path = '/home/ubuntu/W210-Capstone/notebooks/idenprof/test'\n",
    "X_train, X_test, y_train, y_test = load_prof_for_ml(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b35f79f-4a88-4a6e-a71b-d3d5510099f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[172, 222, 255, ..., 129, 106,  64],\n",
       "       [116,  87,  53, ...,  57,  56,  54],\n",
       "       [151, 193, 251, ..., 181, 207, 244],\n",
       "       ...,\n",
       "       [235, 230, 224, ..., 110, 102,  91],\n",
       "       [193, 199, 189, ..., 217, 229, 241],\n",
       "       [ 12,  13,   0, ...,  98,  98,  96]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5782765-a95b-4ef7-8c16-b7a061cc1fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0851c51d-6eba-48f4-9aa7-397ff15bd8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.467, F1: 0.4597919427256182, Recall: 0.467, Precision: 0.4665723225481096, AUC: 0.7038888888888889\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
    "    # 'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    # 'Gradient Boosting': GradientBoostingClassifier(n_estimators=100),\n",
    "    # 'AdaBoost': AdaBoostClassifier(n_estimators=100)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    y_test_binarized = lb.fit_transform(y_test)\n",
    "    predictions_binarized = lb.transform(predictions)\n",
    "    auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "    print(f\"{name} - Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec86311-c060-48e3-8118-13841bcc3347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "# }\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test, predictions)\n",
    "#     f1 = f1_score(y_test, predictions, average='weighted')\n",
    "#     recall = recall_score(y_test, predictions, average='weighted')\n",
    "#     precision = precision_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "#     lb = LabelBinarizer()\n",
    "#     y_test_binarized = lb.fit_transform(y_test)\n",
    "#     predictions_binarized = lb.transform(predictions)\n",
    "#     auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "#     print(f\"{name} - Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "719ed314-d3c3-4da4-9ab9-8b52015b15e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_model = XGBClassifier(\n",
    "#     n_estimators=10,  # kernel keeps dying n_estimators=100\n",
    "#     learning_rate=0.1,\n",
    "#     gamma=2,\n",
    "#     subsample=0.9,\n",
    "#     colsample_bytree=0.5,\n",
    "#     use_label_encoder=False,\n",
    "#     eval_metric='logloss',\n",
    "#     n_jobs=1, # kernel keeps dying\n",
    "#     early_stopping_rounds = 10\n",
    "# )\n",
    "\n",
    "\n",
    "# eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "# # xgb_model.fit(X_train, y_train, early_stopping_rounds=10, eval_set=eval_set, verbose=True)\n",
    "# # eval_set = [(X_test, y_test)]\n",
    "# xgb_model.fit(X_train, y_train, eval_set=eval_set, verbose=True)\n",
    "\n",
    "# predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, predictions)\n",
    "# f1 = f1_score(y_test, predictions, average='weighted')\n",
    "# recall = recall_score(y_test, predictions, average='weighted')\n",
    "# precision = precision_score(y_test, predictions, average='weighted')\n",
    "\n",
    "# lb = LabelBinarizer()\n",
    "# y_test_binarized = lb.fit_transform(y_test)\n",
    "# predictions_binarized = lb.transform(predictions)\n",
    "# auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "# print(f\"XGBoost - Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81166848-ca74-49e3-9904-4e703585a0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.14401\tvalidation_1-mlogloss:2.23760\n",
      "[1]\tvalidation_0-mlogloss:2.01155\tvalidation_1-mlogloss:2.18098\n",
      "[2]\tvalidation_0-mlogloss:1.89377\tvalidation_1-mlogloss:2.13118\n",
      "[3]\tvalidation_0-mlogloss:1.79101\tvalidation_1-mlogloss:2.08732\n",
      "[4]\tvalidation_0-mlogloss:1.69771\tvalidation_1-mlogloss:2.05028\n",
      "[5]\tvalidation_0-mlogloss:1.61259\tvalidation_1-mlogloss:2.01462\n",
      "[6]\tvalidation_0-mlogloss:1.53474\tvalidation_1-mlogloss:1.98281\n",
      "[7]\tvalidation_0-mlogloss:1.46093\tvalidation_1-mlogloss:1.95400\n",
      "[8]\tvalidation_0-mlogloss:1.39292\tvalidation_1-mlogloss:1.92931\n",
      "[9]\tvalidation_0-mlogloss:1.32978\tvalidation_1-mlogloss:1.90691\n",
      "Accuracy: 0.433, F1: 0.4279137152355479, Recall: 0.433, Precision: 0.42957091853074925, AUC: 0.6849999999999999\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=10,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,  \n",
    "    eval_metric='mlogloss',   # multi-class classification\n",
    "    n_jobs=1,                  # To prevent the kernel from dying\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "xgb_model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=eval_set, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "predictions = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_test_binarized = lb.fit_transform(y_test)\n",
    "predictions_binarized = lb.transform(predictions)\n",
    "auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda8d224-7bc4-4f43-b94c-b05e07f2be17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           2.1911           79.43m\n",
      "         2           2.1014           39.76m\n",
      "         3           2.0262            0.00s\n",
      "Gradient Boosting - Accuracy: 0.3385, F1: 0.32295341310197223, Recall: 0.3385, Precision: 0.32798180543599725, AUC: 0.6325000000000001\n"
     ]
    }
   ],
   "source": [
    "## need to look into this code, but this takes FOREVER!!!!!\n",
    "\n",
    "models = {\n",
    "    'Gradient Boosting': GradientBoostingClassifier(\n",
    "        n_estimators=3, # initally had 100, and tried 5 and keep losing connection - you can try with more estimators if that works for you\n",
    "        learning_rate=0.1,\n",
    "        n_iter_no_change=5,  \n",
    "        validation_fraction=0.1, \n",
    "        verbose=True,\n",
    "        warm_start=True  # Enable warm start\n",
    "    )\n",
    "}\n",
    "for name, model in models.items():\n",
    "    if name == 'Gradient Boosting':\n",
    "        # eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "        # model.fit(X_train, y_train, verbose=True)\n",
    "        model.fit(X_train, y_train)\n",
    "    else:\n",
    "        # eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    # AUC\n",
    "    lb = LabelBinarizer()\n",
    "    y_test_binarized = lb.fit_transform(y_test)\n",
    "    predictions_binarized = lb.transform(predictions)\n",
    "    auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "    print(f\"{name} - Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff54e1c7-8086-4155-8d73-14fd9c1a91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Testing \n",
    "\n",
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the model\n",
    "# ada_boost = AdaBoostClassifier()\n",
    "\n",
    "# # Set up the parameters grid\n",
    "# param_grid = {\n",
    "#     'n_estimators': [10],\n",
    "#     'learning_rate': [0.01, 0.1, 1.0]\n",
    "# }\n",
    "\n",
    "# # Perform grid search\n",
    "# grid_search = GridSearchCV(estimator=ada_boost, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Fit the model\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters\n",
    "# print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# # Use the best estimator for further predictions\n",
    "# best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b19821fe-aa6c-4419-a727-eac69b2ce791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Accuracy: 0.2375, F1: 0.18981870885516053, Recall: 0.2375, Precision: 0.1837460971640944, AUC: 0.576388888888889\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'AdaBoost': AdaBoostClassifier(\n",
    "        n_estimators=10,\n",
    "        learning_rate = 0.1\n",
    "        \n",
    "    )}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Gradient Boosting':\n",
    "        # eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "        # model.fit(X_train, y_train, verbose=True)\n",
    "        model.fit(X_train, y_train)\n",
    "    else:\n",
    "        # eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    # AUC\n",
    "    lb = LabelBinarizer()\n",
    "    y_test_binarized = lb.fit_transform(y_test)\n",
    "    predictions_binarized = lb.transform(predictions)\n",
    "    auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "    print(f\"{name} - Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d408aaad-4525-4b6d-8d62-f99a4d6ba905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Accuracy: 0.2455, F1: 0.23398605757347404, Recall: 0.2455, Precision: 0.23345162230307406, AUC: 0.5808333333333333\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'AdaBoost': AdaBoostClassifier(\n",
    "        n_estimators=10,\n",
    "        learning_rate = 0.2\n",
    "        \n",
    "    )}\n",
    "\n",
    "for name, model in models.items():\n",
    "    if name == 'Gradient Boosting':\n",
    "        # eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "        # model.fit(X_train, y_train, verbose=True)\n",
    "        model.fit(X_train, y_train)\n",
    "    else:\n",
    "        # eval_set = [(X_train, y_train), (X_test, y_test)]  \n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average='weighted')\n",
    "    recall = recall_score(y_test, predictions, average='weighted')\n",
    "    precision = precision_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "    # AUC\n",
    "    lb = LabelBinarizer()\n",
    "    y_test_binarized = lb.fit_transform(y_test)\n",
    "    predictions_binarized = lb.transform(predictions)\n",
    "    auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "    print(f\"{name} - Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a0f79-c995-4771-9a01-00ca7106a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {\n",
    "#     'Gradient Boosting': GradientBoostingClassifier(n_estimators=100),\n",
    "#     'AdaBoost': AdaBoostClassifier(n_estimators=100)\n",
    "# }\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     predictions = model.predict(X_test)\n",
    "\n",
    "#     accuracy = accuracy_score(y_test, predictions)\n",
    "#     f1 = f1_score(y_test, predictions, average='weighted')\n",
    "#     recall = recall_score(y_test, predictions, average='weighted')\n",
    "#     precision = precision_score(y_test, predictions, average='weighted')\n",
    "    \n",
    "#     lb = LabelBinarizer()\n",
    "#     y_test_binarized = lb.fit_transform(y_test)\n",
    "#     predictions_binarized = lb.transform(predictions)\n",
    "#     auc = roc_auc_score(y_test_binarized, predictions_binarized, average='macro')\n",
    "\n",
    "#     print(f\"{name} - Accuracy: {accuracy}, F1: {f1}, Recall: {recall}, Precision: {precision}, AUC: {auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13eb74d-8dd2-4a3b-92a7-3bb6034ae7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
