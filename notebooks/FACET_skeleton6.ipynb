{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b75b68a7-5330-4b64-805d-3fe0e0064a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.8/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.8/dist-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.8/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.2.140)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.8/dist-packages (0.21.0)\n",
      "Requirement already satisfied: numpy>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (10.1.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2.31.5)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /usr/local/lib/python3.8/dist-packages (from scikit-image) (0.3)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.3.1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.2.0)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (6.1.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.14.0)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.24.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (2023.9.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.8/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.8/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchvision) (12.2.140)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: s3fs in /usr/local/lib/python3.8/dist-packages (2023.9.2)\n",
      "Requirement already satisfied: aiobotocore~=2.5.4 in /usr/local/lib/python3.8/dist-packages (from s3fs) (2.5.4)\n",
      "Requirement already satisfied: fsspec==2023.9.2 in /usr/local/lib/python3.8/dist-packages (from s3fs) (2023.9.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from s3fs) (3.8.6)\n",
      "Collecting botocore<1.31.18,>=1.31.17 (from aiobotocore~=2.5.4->s3fs)\n",
      "  Obtaining dependency information for botocore<1.31.18,>=1.31.17 from https://files.pythonhosted.org/packages/3d/e5/32a88f5a95e3d43c2e3ed86fc1ffdb715547a04f95a51d00e1185af63b0c/botocore-1.31.17-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.31.17-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.8/dist-packages (from aiobotocore~=2.5.4->s3fs) (1.15.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.8/dist-packages (from aiobotocore~=2.5.4->s3fs) (0.11.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.8/dist-packages (from aioitertools<1.0.0,>=0.5.1->aiobotocore~=2.5.4->s3fs) (4.8.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs) (1.25.8)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/lib/python3/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (2.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.31.18,>=1.31.17->aiobotocore~=2.5.4->s3fs) (1.14.0)\n",
      "Using cached botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.65\n",
      "    Uninstalling botocore-1.31.65:\n",
      "      Successfully uninstalled botocore-1.31.65\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.29.58 requires botocore==1.31.58, but you have botocore 1.31.17 which is incompatible.\n",
      "boto3 1.28.65 requires botocore<1.32.0,>=1.31.65, but you have botocore 1.31.17 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.31.17\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.8/dist-packages (1.28.65)\n",
      "Collecting botocore<1.32.0,>=1.31.65 (from boto3)\n",
      "  Obtaining dependency information for botocore<1.32.0,>=1.31.65 from https://files.pythonhosted.org/packages/63/c6/8e29a2b9dffa188d07c26d19ae578a26d8063834e4d844bf22c2a0028229/botocore-1.31.65-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.31.65-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from boto3) (0.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.32.0,>=1.31.65->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/lib/python3/dist-packages (from botocore<1.32.0,>=1.31.65->boto3) (1.25.8)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.65->boto3) (1.14.0)\n",
      "Using cached botocore-1.31.65-py3-none-any.whl (11.3 MB)\n",
      "\u001b[33mDEPRECATION: devscripts 2.20.2ubuntu2 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of devscripts or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.17\n",
      "    Uninstalling botocore-1.31.17:\n",
      "      Successfully uninstalled botocore-1.31.17\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.5.4 requires botocore<1.31.18,>=1.31.17, but you have botocore 1.31.65 which is incompatible.\n",
      "awscli 1.29.58 requires botocore==1.31.58, but you have botocore 1.31.65 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.31.65\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install for AWS\n",
    "!pip install torch\n",
    "!pip install pandas\n",
    "!pip install scikit-image\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install torchvision\n",
    "!pip install s3fs\n",
    "!pip install boto3\n",
    "# !pip install fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d921d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x7f4de76c9340>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import tarfile\n",
    "import shutil\n",
    "import torchvision\n",
    "import random\n",
    "import warnings\n",
    "import boto3\n",
    "import s3fs\n",
    "import io\n",
    "import time\n",
    "import botocore.exceptions\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, utils, models, datasets\n",
    "from io import BytesIO\n",
    "from torch import nn, optim\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "\n",
    "# import fiftyone as fo\n",
    "# import fiftyone.brain as fob\n",
    "# import fiftyone.zoo as foz\n",
    "# from fiftyone import ViewField as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35460ff2-00fb-4177-8dba-7eb46accc65f",
   "metadata": {},
   "source": [
    "# Define Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c292eb58-f5d2-4b65-99b7-1146031d6a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "fine_tune_learning_rate = learning_rate / 10\n",
    "num_classes = 52\n",
    "num_epochs = 2\n",
    "fine_tune_epochs = 3\n",
    "disparity_weight = 0.1\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9291892c",
   "metadata": {},
   "source": [
    "# Load, Transform, and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf02a7f-5d9d-45aa-b048-0b82e5f96627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3', region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151506f8-ee9b-4e93-9288-f5c9294b54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the S3 bucket name and prefixes\n",
    "bucket_name = 'w210facetdata'\n",
    "annotations_prefix = 'annotations/'\n",
    "images_prefix = 'images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e8f2565-feba-45cc-ae23-2423efa4555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV annotations from S3\n",
    "annotations_s3_path = f's3://{bucket_name}/{annotations_prefix}annotations.csv'\n",
    "df = pd.read_csv(annotations_s3_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c7160d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting unique class labels from the 'class1' column\n",
    "classes = df['class1'].unique()\n",
    "\n",
    "# Creating a mapping from index to class label\n",
    "idx_to_class = {i: j for i, j in enumerate(classes)}\n",
    "\n",
    "# Creating a reverse mapping from class label to index\n",
    "class_to_idx = {value: key for key, value in idx_to_class.items()}\n",
    "\n",
    "# Creating a mapping from index to annotation column name starting from the 7th column\n",
    "idx_to_annot = {i: j for i, j in enumerate(df.columns[6:])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0854c838-4960-4199-ac65-dc3f1a860ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check count of jpg files\n",
    "# def count_jpg_files(bucket_name, prefix=''):\n",
    "#     \"\"\"\n",
    "#     Count the number of .jpg files in an S3 bucket under a given prefix.\n",
    "    \n",
    "#     Parameters:\n",
    "#     - bucket_name (str): Name of the S3 bucket.\n",
    "#     - prefix (str): Prefix path to filter results. Default is empty.\n",
    "    \n",
    "#     Returns:\n",
    "#     - count (int): Count of .jpg files.\n",
    "#     \"\"\"\n",
    "#     count = 0\n",
    "#     paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    \n",
    "#     for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "#         for obj in page.get('Contents', []):\n",
    "#             if obj['Key'].endswith('.jpg'):\n",
    "#                 count += 1\n",
    "\n",
    "#     return count\n",
    "\n",
    "# # Count .jpg files in the 'w210facetdata' bucket under the 'images/' prefix\n",
    "# jpg_count = count_jpg_files(bucket_name, images_prefix)\n",
    "# print(f\"Number of .jpg files in the '{bucket_name}/{images_prefix}' path: {jpg_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b71e49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[0][6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c51757c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2a24773-8c94-471b-93d7-8325af201183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a2edac-be96-46de-acac-f821844c4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36fea9e1-5796-4959-87f5-fc7e281ff232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # toggle on/off subsetting\n",
    "# # Define the number of samples you want in your subset\n",
    "# subset_size = 100  # Adjust the size as needed\n",
    "\n",
    "# # Create a smaller subset of your dataset\n",
    "# train_data = train_data[:subset_size]\n",
    "# test_data = test_data[:subset_size]\n",
    "# val_data = val_data[:subset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bca4ae0f-b5e7-49e2-9ca5-c50d417c156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define additional metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Lists to store metric values during training\n",
    "train_losses_student, val_losses_student, train_losses_teacher, val_losses_teacher = [], [], [], []\n",
    "train_accuracies_student, val_accuracies_student, train_accuracies_teacher, val_accuracies_teacher = [], [], [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de230e63-4d98-4cf6-a36b-aa31ff1c8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fc8ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, split_data, image_dir, transform=None):\n",
    "        self.data = split_data\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx, 2]\n",
    "        image_key = f'{images_prefix}{img_name}'  # Construct S3 object key\n",
    "        # Load image from S3\n",
    "        img_object = s3_client.get_object(Bucket=bucket_name, Key=image_key)\n",
    "        img_data = img_object['Body'].read()\n",
    "        # Open the image directly from the byte stream using PIL\n",
    "        image = Image.open(BytesIO(img_data))\n",
    "        annotations = self.data.iloc[idx, 6:].values.astype(np.float16).reshape(-1, 1)\n",
    "        label = class_to_idx[self.data.iloc[idx, 3]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label), torch.from_numpy(annotations)\n",
    "\n",
    "# Create custom datasets and data loaders\n",
    "image_dir = 'FACET'  # Local directory if you want to save images locally\n",
    "train_dataset = CustomDataset(split_data=train_data, image_dir=image_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = CustomDataset(split_data=test_data, image_dir=image_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "val_dataset = CustomDataset(split_data=val_data, image_dir=image_dir, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ca0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "\n",
    "# for i, sample in enumerate(train_dataset):\n",
    "#     ax = plt.subplot(1, 4, i + 1)\n",
    "#     plt.imshow(np.transpose(sample[0], [1,2,0]))\n",
    "#     plt.tight_layout()\n",
    "#     ax.set_title('Sample #{}'.format(i))\n",
    "#     ax.axis('off')\n",
    "#     plt.show()\n",
    "#     if i == 3:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1500c8f1",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94e55ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('mps')\n",
    "\n",
    "# Define your smaller ResNet student model\n",
    "# Deeper neural network class to be used as teacher:\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, num_classes=52):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(131072, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Lightweight neural network class to be used as student:\n",
    "class LightNN(nn.Module):\n",
    "    def __init__(self, num_classes=52):\n",
    "        super(LightNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(65536, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Define loss functions\n",
    "criterion_teacher = nn.CrossEntropyLoss()  # Loss for teacher model\n",
    "criterion_student = nn.KLDivLoss()  # Knowledge distillation loss\n",
    "\n",
    "# Instantiate the teacher and student models\n",
    "teacher_model = torchvision.models.resnet50(pretrained=True)\n",
    "num_ftrs = teacher_model.fc.in_features\n",
    "teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "student_model = LightNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# Load pre-trained weights if available\n",
    "pretrained_path = 'pretrained_student.pth'\n",
    "if os.path.exists(pretrained_path):\n",
    "    student_model.load_state_dict(torch.load(pretrained_path))\n",
    "    print(\"Loaded pre-trained weights for student model.\")\n",
    "\n",
    "# Define optimizer for the student model\n",
    "optimizer_student = optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "optimizer_teacher = optim.Adam(teacher_model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1881b911",
   "metadata": {},
   "source": [
    "# Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61577f09-4f08-4a5f-a576-38a591f86f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define attributes and concepts in your dataset\n",
    "attributes = df.columns[6:].tolist()  # All attributes\n",
    "concepts = list(idx_to_class.values())  # All concepts\n",
    "\n",
    "# Create a dictionary to map attribute names to column indices\n",
    "attr_idx = {attr: idx for idx, attr in enumerate(attributes)}\n",
    "\n",
    "# Initialize dictionaries to store recall values for teacher and student models\n",
    "teacher_recall_values = {attr: {concept: [] for concept in concepts} for attr in attributes}\n",
    "student_recall_values = {attr: {concept: [] for concept in concepts} for attr in attributes}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b5297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable anomaly detection\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "# Update the total number of epochs to include fine-tuning epochs\n",
    "total_epochs = num_epochs + fine_tune_epochs\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(total_epochs):\n",
    "    # Change learning rate for fine-tuning phase\n",
    "    if epoch == num_epochs:\n",
    "        for param_group in optimizer_student.param_groups:\n",
    "            param_group['lr'] = fine_tune_learning_rate\n",
    "        for param_group in optimizer_teacher.param_groups:\n",
    "            param_group['lr'] = fine_tune_learning_rate\n",
    "        print(f'Starting fine-tuning with learning rate: {fine_tune_learning_rate}')\n",
    "\n",
    "    student_model.train()\n",
    "    teacher_model.train()\n",
    "    for images, labels, annotations in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer_student.zero_grad()\n",
    "        optimizer_teacher.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        teacher_outputs = teacher_model(images).to(device)\n",
    "        student_outputs = student_model(images).to(device)\n",
    "\n",
    "        # Calculate additional metrics including recall\n",
    "        recall_student = recall_score(labels.cpu().numpy(), torch.argmax(student_outputs, dim=1).cpu().numpy(), average='weighted')\n",
    "        recall_teacher = recall_score(labels.cpu().numpy(), torch.argmax(teacher_outputs, dim=1).cpu().numpy(), average='weighted')\n",
    "\n",
    "        # Update recall values\n",
    "        for attr in attributes:\n",
    "            for concept in concepts:\n",
    "                # Check if the sample belongs to the specified attribute and concept\n",
    "                attr_indices = np.where(annotations[:, attr_idx[attr]].cpu().numpy() == 1)[0]  # Get indices where attribute is 1\n",
    "                concept_indices = np.where(labels.cpu().numpy() == class_to_idx[concept])[0]  # Get indices where concept matches\n",
    "                common_indices = np.intersect1d(attr_indices, concept_indices)  # Common indices\n",
    "                if common_indices.size > 0:\n",
    "                    teacher_recall_values[attr][concept].append(recall_teacher)\n",
    "                    student_recall_values[attr][concept].append(recall_student)\n",
    "\n",
    "        # Calculate the Knowledge Distillation loss and Cross Entropy loss\n",
    "        kd_loss = criterion_student(\n",
    "            F.log_softmax(student_outputs / 5, dim=1),  # Apply temperature scaling\n",
    "            F.softmax(teacher_outputs / 5, dim=1)  # Apply temperature scaling\n",
    "        )\n",
    "        ce_loss = criterion_teacher(student_outputs, labels)\n",
    "    \n",
    "    # Calculate the disparity for each attribute and concept\n",
    "    for attr in attributes:\n",
    "        for concept in concepts:\n",
    "            # Calculate the disparity (difference in recall)\n",
    "            teacher_recall = np.mean(teacher_recall_values[attr][concept])\n",
    "            student_recall = np.mean(student_recall_values[attr][concept])\n",
    "            disparity = teacher_recall - student_recall\n",
    "    \n",
    "            # Clone tensors before performing inplace operations\n",
    "            kd_loss = kd_loss.clone()\n",
    "            ce_loss = ce_loss.clone()\n",
    "            disparity_tensor = torch.tensor(disparity, dtype=torch.float32).to(device)  # Convert disparity to a PyTorch tensor\n",
    "            disparity_loss = disparity_weight * disparity_tensor.clone()\n",
    "            total_loss = alpha * kd_loss + (1 - alpha) * ce_loss + disparity_loss\n",
    "    \n",
    "        # Perform the backward pass\n",
    "        total_loss.backward()\n",
    "    \n",
    "        # Optimize the models\n",
    "        optimizer_student.step()\n",
    "        optimizer_teacher.step()\n",
    "\n",
    "        # Zero the gradients after updating weights\n",
    "        optimizer_student.zero_grad()\n",
    "        optimizer_teacher.zero_grad()\n",
    "\n",
    "# Disable anomaly detection when done\n",
    "torch.autograd.set_detect_anomaly(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14901784",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7269dd13-feeb-4da4-ba83-89af85450e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disparity(teacher_recall_values, student_recall_values):\n",
    "    disparity_values = {}\n",
    "    for attr in attributes:  # Ensure 'attributes' is defined and correctly formatted\n",
    "        disparity_values[attr] = {}\n",
    "        for concept in concepts:  # Ensure 'concepts' is defined and correctly formatted\n",
    "            teacher_values = teacher_recall_values.get(attr, {}).get(concept, [])\n",
    "            student_values = student_recall_values.get(attr, {}).get(concept, [])\n",
    "            if teacher_values and student_values:  # Check non-empty lists\n",
    "                disparity_values[attr][concept] = np.mean(\n",
    "                    [teacher_val - student_val for teacher_val, student_val in zip(teacher_values, student_values)]\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Missing values for attr: {attr}, concept: {concept}\")  # Debugging print statement\n",
    "    return disparity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaac4b6-07b8-44b4-ba19-240926f7bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "student_model.eval()\n",
    "teacher_model.eval()\n",
    "val_loss_student = 0.0\n",
    "val_predictions_student = []\n",
    "val_targets_student = []\n",
    "\n",
    "val_loss_teacher = 0.0\n",
    "val_predictions_teacher = []\n",
    "val_targets_teacher = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, annotations in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Forward pass\n",
    "        student_outputs = student_model(images)\n",
    "        teacher_outputs = teacher_model(images)\n",
    "\n",
    "        # Calculate cross-entropy loss for validation\n",
    "        student_loss = criterion_teacher(student_outputs, labels)\n",
    "        teacher_loss = criterion_teacher(teacher_outputs, labels)\n",
    "\n",
    "        val_loss_student += student_loss.item()\n",
    "        val_loss_teacher += teacher_loss.item()\n",
    "\n",
    "        # Store predictions and ground truth labels for metrics\n",
    "        val_predictions_student.extend(torch.argmax(student_outputs, dim=1).cpu().numpy())\n",
    "        val_predictions_teacher.extend(torch.argmax(teacher_outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        val_targets_student.extend(labels.cpu().numpy())\n",
    "        val_targets_teacher.extend(labels.cpu().numpy())\n",
    "\n",
    "end_time = time.time()  # End time measurement\n",
    "inference_time_student = (end_time - start_time) / len(val_loader)\n",
    "inference_time_teacher = (end_time - start_time) / len(val_loader)\n",
    "\n",
    "val_disparity_values = calculate_disparity(teacher_recall_values, student_recall_values)\n",
    "\n",
    "# Calculate the average disparity\n",
    "avg_disparity = np.mean(\n",
    "    [value for attr_dict in val_disparity_values.values()\n",
    "     for concept_dict in attr_dict.values()\n",
    "     for value in (concept_dict.values() if isinstance(concept_dict, dict) else [concept_dict])])\n",
    "\n",
    "\n",
    "# Calculate validation accuracy and recall\n",
    "val_accuracy_student = accuracy_score(val_targets_student, val_predictions_student)\n",
    "val_accuracy_teacher = accuracy_score(val_targets_teacher, val_predictions_teacher)\n",
    "val_recall_student = recall_score(val_targets_student, val_predictions_student, average='weighted')\n",
    "val_recall_teacher = recall_score(val_targets_teacher, val_predictions_teacher, average='weighted')\n",
    "val_precision_student = precision_score(val_targets_student, val_predictions_student, average='weighted')\n",
    "val_precision_teacher = precision_score(val_targets_teacher, val_predictions_teacher, average='weighted')\n",
    "val_f1_student = f1_score(val_targets_student, val_predictions_student, average='weighted')\n",
    "val_f1_teacher = f1_score(val_targets_teacher, val_predictions_teacher, average='weighted')\n",
    "\n",
    "# Get model size (number of parameters)\n",
    "model_size_student = sum(p.numel() for p in student_model.parameters())\n",
    "model_size_teacher = sum(p.numel() for p in teacher_model.parameters())\n",
    "\n",
    "val_metrics_teacher = calculate_metrics(val_targets_teacher, val_predictions_teacher)\n",
    "val_metrics_student = calculate_metrics(val_targets_student, val_predictions_student)\n",
    "  \n",
    "# Gather metrics in dictionaries for easier plotting\n",
    "teacher_metrics = {\n",
    "    'Accuracy': val_metrics_teacher[0],\n",
    "    'Precision': val_metrics_teacher[1],\n",
    "    'Recall': val_metrics_teacher[2],\n",
    "    'F1 Score': val_metrics_teacher[3],\n",
    "    'Disparity': avg_disparity,  # Corrected here\n",
    "    'Model Size': model_size_teacher,\n",
    "    'Inference Time': inference_time_teacher\n",
    "}\n",
    "\n",
    "student_metrics = {\n",
    "    'Accuracy': val_metrics_student[0],\n",
    "    'Precision': val_metrics_student[1],\n",
    "    'Recall': val_metrics_student[2],\n",
    "    'F1 Score': val_metrics_student[3],\n",
    "    'Disparity': avg_disparity,  # Corrected here\n",
    "    'Model Size': model_size_student,\n",
    "    'Inference Time': inference_time_student\n",
    "}\n",
    "\n",
    "# Define labels for plotting\n",
    "size_labels = ['Model Size']\n",
    "time_labels = ['Inference Time']\n",
    "other_labels = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'Disparity']  # Define labels for other metrics\n",
    "\n",
    "# Extract values for each type of metric\n",
    "size_teacher_values = [teacher_metrics['Model Size']]\n",
    "size_student_values = [student_metrics['Model Size']]\n",
    "\n",
    "time_teacher_values = [teacher_metrics['Inference Time']]\n",
    "time_student_values = [student_metrics['Inference Time']]\n",
    "\n",
    "other_teacher_values = [teacher_metrics[key] for key in other_labels]\n",
    "other_student_values = [student_metrics[key] for key in other_labels]\n",
    "\n",
    "# Print validation results for this epoch\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}]'\n",
    "      f' Teacher Loss: {val_loss_teacher / len(val_loader):.4f}'\n",
    "      f' Teacher Accuracy: {val_accuracy_teacher:.4f}'\n",
    "      f' Teacher Recall: {val_recall_teacher:.4f}'\n",
    "      f' Student Loss: {val_loss_student / len(val_loader):.4f}'\n",
    "      f' Student Accuracy: {val_accuracy_student:.4f}'\n",
    "      f' Student Recall: {val_recall_student:.4f}')\n",
    "\n",
    "# Print disparity for validation\n",
    "for attr in attributes:\n",
    "    for concept in concepts:\n",
    "        # Handle potential missing values with a default of NaN or another value of your choice\n",
    "        print(f'Validation Disparity for {attr} and {concept}: {val_disparity_values.get(attr, {}).get(concept, np.nan):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d61927-0920-46d5-93f2-d9c8492d753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(labels, teacher_values, student_values, title):\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, teacher_values, width, label='Teacher')\n",
    "    rects2 = ax.bar(x + width/2, student_values, width, label='Student')\n",
    "\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to create a bar plot specifically for disparity\n",
    "def plot_disparity(title):\n",
    "    labels = ['Disparity']\n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    rects1 = ax.bar(x - width/2, [teacher_metrics['Disparity']], width, label='Teacher')\n",
    "    rects2 = ax.bar(x + width/2, [student_metrics['Disparity']], width, label='Student')\n",
    "\n",
    "    ax.set_xlabel('Metrics')\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create plots\n",
    "create_plot(size_labels, size_teacher_values, size_student_values, 'Model Size Comparison')\n",
    "create_plot(time_labels, time_teacher_values, time_student_values, 'Inference Time Comparison')\n",
    "plot_disparity('Disparity Comparison')\n",
    "create_plot(other_labels[:-1], other_teacher_values[:-1], other_student_values[:-1], 'Other Metrics Comparison')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student_model.state_dict(), 'student_model2.pth')\n",
    "torch.save(teacher_model.state_dict(), 'teacher_model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f26941",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(val_targets_student, val_predictions_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(val_targets_teacher, val_predictions_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46008340",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_student / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_teacher / len(val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
