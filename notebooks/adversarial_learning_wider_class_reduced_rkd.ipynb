{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50f79206-feac-4302-abb1-d699b6354a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision.models.resnet import ResNet34_Weights\n",
    "from torchvision.datasets import ImageFolder\n",
    "from utils.loss_functions import tkd_kdloss\n",
    "# from models_package.models import Teacher, Student\n",
    "\n",
    "# new libraries\n",
    "from models_package.models import Teacher, Student, CustomResNet18\n",
    "from torchvision import datasets, transforms, models\n",
    "from data.data_loader import load_cifar10, load_cifar100, load_imagenet, load_prof, load_wider\n",
    "from torchvision.models.resnet import ResNet, BasicBlock, Bottleneck\n",
    "from torchvision.models.resnet import ResNet18_Weights, ResNet34_Weights\n",
    "from utils.loss_functions import tkd_kdloss, DD_loss, AD_loss, RKDDistanceLoss, RKDAngleLoss\n",
    "from utils.misc_tools_rkd import best_lr_rkd, rkd_train_teacher, rkd_train_student_with_distillation, rkd_test_model\n",
    "from utils.compare_tools_rkd import compare_model_size, compare_inference_time, compare_performance_metrics, plot_comparison\n",
    "\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3c0ec8-98dc-4933-b9a3-e96fce39c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 300\n",
    "epochs_pretrain = 3\n",
    "epochs_optimal_lr = 3\n",
    "patience_teacher = 10  # 6\n",
    "patience_student = 10\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "# batch_size = 128\n",
    "batch_size = 384\n",
    "\n",
    "num_workers = 4\n",
    "\n",
    "# set to true to use stratified sampling\n",
    "stratified_sampling_flag = True\n",
    "\n",
    "# list of lambda values to loop through for grid search\n",
    "lmda_list = [0]\n",
    "\n",
    "# labels used including for plotting\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "num_classes = 16 #len(class_labels)\n",
    "class_names_new = [f\"Class {label}\" for label in range(num_classes)]\n",
    "\n",
    "# Create directory and file path to save all outputs\n",
    "output_dir = f'./runs_{datetime.now().strftime(\"%Y_%m_%d_%H_%M\")}'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2770eac-10b7-47de-ba06-9aa63cd7ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46265942-58a1-4c1a-a7ea-82d919a7e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your JSON file is named 'your_file.json'\n",
    "file_path = 'data/WIDER/Annotations/wider_attribute_trainval.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    data = json.load(file)\n",
    "\n",
    "class_idx = data['scene_id_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312fa312-b347-4434-862b-d25e32a79108",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_mapping = {\n",
    "    0: \"Team_Sports\",\n",
    "    1: \"Celebration\",\n",
    "    2: \"Parade\",\n",
    "    3: \"Waiter_Or_Waitress\",\n",
    "    4: \"Individual_Sports\",\n",
    "    5: \"Surgeons\",\n",
    "    6: \"Spa\",\n",
    "    7: \"Law_Enforcement\",\n",
    "    8: \"Business\",\n",
    "    9: \"Dresses\",\n",
    "    10: \"Water_Activities\",\n",
    "    11: \"Picnic\",\n",
    "    12: \"Rescue\",\n",
    "    13: \"Cheering\",\n",
    "    14: \"Performance_And_Entertainment\",\n",
    "    15: \"Family\"\n",
    "}\n",
    "\n",
    "# Ensure that all 16 new classes are covered\n",
    "# If some classes are not explicitly mentioned in new_label_mapping, add them\n",
    "for i in range(16):\n",
    "    if i not in new_label_mapping:\n",
    "        new_label_mapping[i] = \"Additional Category {}\".format(i)\n",
    "\n",
    "class_idx = new_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c922f94-bf69-40d5-bc88-1e6fab4b4ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StratifiedBatchSampler:\n",
    "    \"\"\"Stratified batch sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, y, batch_size, shuffle=True):\n",
    "        if torch.is_tensor(y):\n",
    "            y = y.numpy()\n",
    "        assert len(y.shape) == 1, 'label array must be 1D'\n",
    "        n_batches = int(len(y) / batch_size)\n",
    "        self.skf = StratifiedKFold(n_splits=n_batches, shuffle=shuffle)\n",
    "        self.X = torch.randn(len(y),1).numpy()\n",
    "        self.y = y\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.skf.random_state = torch.randint(0,int(1e8),size=()).item()\n",
    "        for train_idx, test_idx in self.skf.split(self.X, self.y):\n",
    "            yield test_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)//self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c84514-66c9-4543-8448-cafa751730ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "\n",
    "        # Create a mapping from old labels to new labels\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "\n",
    "        self.new_label_mapping = {\n",
    "            0: 2,  # Parade\n",
    "            1: 8,  # Business\n",
    "            2: 7,  # Law Enforcement\n",
    "            3: 14,  # Performance and Entertainment\n",
    "            4: 1,  # Celebration\n",
    "            5: 13,  # Cheering\n",
    "            6: 8,  # Business\n",
    "            7: 8,  # Business\n",
    "            8: 1,  # Celebration\n",
    "            9: 14,  # Performance and Entertainment\n",
    "            10: 15, # Family\n",
    "            11: 15, # Family\n",
    "            12: 11, # Picnic\n",
    "            13: 7, # Law Enforcement\n",
    "            14: 6, # Spa\n",
    "            15: 13, # Cheering\n",
    "            16: 5, # Surgeons\n",
    "            17: 3, # Waiter or Waitress\n",
    "            18: 4, # Individual Sports\n",
    "            19: 0, # Team Sports\n",
    "            20: 0, # Team Sports\n",
    "            21: 0, # Team Sports\n",
    "            22: 4, # Individual Sports\n",
    "            23: 10, # Water Activities\n",
    "            24: 4, # Individual Sports\n",
    "            25: 1, # Celebration\n",
    "            26: 9, # Dresses\n",
    "            27: 12, # Rescue\n",
    "            28: 10,# Water Activities\n",
    "            29: 0  # Team Sports\n",
    "        }\n",
    "\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        # Initialize transformations directly\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ] \n",
    "        )\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                ] \n",
    "            )        \n",
    "\n",
    "        self.anns = []\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs:\n",
    "            t.append(transforms.RandAugment())\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "\n",
    "        return transforms.Compose(t)\n",
    "    \n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            json_data = json.load(open(ann_file, \"r\"))\n",
    "            self.anns += json_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure the index is within bounds\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            img = Image.open(f'data/WIDER/Image/{ann[\"file_name\"]}').convert(\"RGB\")\n",
    "\n",
    "            # If this is the wider dataset, proceed with specific processing\n",
    "            # x, y, w, h = ann['bbox']\n",
    "            # img_area = img.crop([x, y, x+w, y+h])\n",
    "            img_area = self.augment(img)\n",
    "            img_area = self.transform(img_area)\n",
    "            attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "            num_people = len(attributes_list)\n",
    "            attributes_distribution = [max(sum(attribute), 0)/num_people for attribute in zip(*attributes_list)]\n",
    "            # Extract label from image path\n",
    "            img_path = f'data/WIDER/Image/{ann[\"file_name\"]}'\n",
    "            label = self.extract_label(img_path)  # You might need to implement this method\n",
    "            \n",
    "            return {\n",
    "                \"label\": label,\n",
    "                \"target\": torch.tensor([attributes_distribution[0]], dtype=torch.float32),\n",
    "                \"img\": img_area\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during the processing of an image, log the error and the index\n",
    "            print(f\"Error processing image at index {idx}: {e}\")\n",
    "            # Instead of returning None, raise the exception\n",
    "            raise\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"data/WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"data/WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"data/WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            new_label_mapping = self.new_label_mapping[remapped_label]\n",
    "            return new_label_mapping\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea2490c2-046a-4a19-9717-642adbabb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012d6bd8-61d5-4a20-845b-689234718508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe2adb5-687d-4055-a108-a9c041836b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandAugment(num_ops=2, magnitude=9, num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DataSet(train_file, augs = ['RandAugment'], img_size = 226, dataset = 'wider') #, include_augmented=include_augmented)\n",
    "test_dataset = DataSet(test_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "\n",
    "\n",
    "if stratified_sampling_flag:\n",
    "    trainloader = DataLoader(train_dataset, \n",
    "                             batch_sampler=StratifiedBatchSampler(torch.tensor([train_dataset[i]['label'] for i in range(len(train_dataset))]), \n",
    "                             batch_size=batch_size), num_workers=num_workers, collate_fn=custom_collate)\n",
    "else:\n",
    "    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=num_workers, collate_fn=custom_collate)\n",
    "\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d18d4b-a3c0-4c5b-ad75-e74b6b1b7296",
   "metadata": {},
   "source": [
    "# Start Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c37c867-c1d1-438c-ac22-755904ce121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def calculate_recall_multiclass(conf_matrix):\n",
    "    recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    recalls[np.isnan(recalls)] = 0  # Replace NaN with 0\n",
    "    return recalls\n",
    "\n",
    "def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes):\n",
    "    predictions = pred.cpu()\n",
    "    true_labels = label.cpu()\n",
    "    gender = gender.cpu()\n",
    "\n",
    "    # Identify male and female indices based on the gender threshold\n",
    "    male_indices = np.where(gender >= 0.5)[0]\n",
    "    female_indices = np.where(gender < 0.5)[0]\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot_labels = one_hot_encode(true_labels, num_classes=num_classes)\n",
    "    one_hot_preds = one_hot_encode(predictions, num_classes=num_classes)\n",
    "    # Initialize recall arrays\n",
    "    male_recall = np.zeros(num_classes)\n",
    "    female_recall = np.zeros(num_classes)\n",
    "\n",
    "    # Extract predictions and labels for male and female indices\n",
    "    male_predictions = np.argmax(one_hot_preds[male_indices], axis=1)\n",
    "    female_predictions = np.argmax(one_hot_preds[female_indices], axis=1)\n",
    "    male_labels = np.argmax(one_hot_labels[male_indices], axis=1)\n",
    "    female_labels = np.argmax(one_hot_labels[female_indices], axis=1)\n",
    "\n",
    "    # Check if the class labels are within the expected range\n",
    "    assert (0 <= male_predictions.min() < num_classes) and (0 <= male_predictions.max() < num_classes), \"Invalid class indices in male predictions\"\n",
    "    assert (0 <= female_predictions.min() < num_classes) and (0 <= female_predictions.max() < num_classes), \"Invalid class indices in female predictions\"\n",
    "    assert (0 <= male_labels.min() < num_classes) and (0 <= male_labels.max() < num_classes), \"Invalid class indices in male labels\"\n",
    "    assert (0 <= female_labels.min() < num_classes) and (0 <= female_labels.max() < num_classes), \"Invalid class indices in female labels\"\n",
    "\n",
    "    # Calculate confusion matrices for each gender\n",
    "    male_conf_matrix = confusion_matrix(male_labels, male_predictions, labels=np.arange(num_classes))\n",
    "    female_conf_matrix = confusion_matrix(female_labels, female_predictions, labels=np.arange(num_classes))\n",
    "\n",
    "    # Calculate recall for each class and gender\n",
    "    male_recall[:len(male_conf_matrix)] = calculate_recall_multiclass(male_conf_matrix)\n",
    "    female_recall[:len(female_conf_matrix)] = calculate_recall_multiclass(female_conf_matrix)\n",
    "\n",
    "    return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c6b93cb-37c9-448f-a8d9-424d3c4d40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "###################### Testing 1 ######################\n",
    "# Create instances of your models\n",
    "\n",
    "\n",
    "teacher_model = models.resnet50(pretrained=True)  # Keep ResNet50 as it is\n",
    "teacher_model.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "student_model = CustomResNet18()\n",
    "student_model.fc = nn.Linear(512, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdcd643-ac9d-4e22-821a-4c784c86e4a5",
   "metadata": {},
   "source": [
    "This is the initialization of the 2-layer Adversary Perceptron. It is initialized with the number of classes*2, which represents the predicted labels (y_hat) and the true labels (y). The output of the final layer is a regression output, which is intended to predict the strength of gender (continuous number where anything past 0.5 is more male).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836f2993-0505-47c6-85ee-2ad2f45db946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adversary(nn.Module):\n",
    "    def __init__(self, input_size=num_classes):\n",
    "        super(Adversary, self).__init__()\n",
    "\n",
    "        self.a1 = nn.Linear(input_size*2, 16)\n",
    "        self.a2 = nn.Linear(16, 1)  # Output size 1 for regression\n",
    "        nn.init.xavier_normal_(self.a1.weight)\n",
    "        nn.init.kaiming_normal_(self.a2.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        adversary = F.relu(self.a1(input_ids))\n",
    "        adversary_output = F.sigmoid(self.a2(adversary))  # Linear activation for regression\n",
    "        return adversary_output\n",
    "\n",
    "# Instantiate the Adversary\n",
    "adv = Adversary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a761874d-cc14-482e-9c8c-6342adea3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_student(student, teacher, trainloader, criterion, optimizer, device, alpha, temperature, epochs_pretrain, patience=patience_student):\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs_pretrain):\n",
    "        student.train()\n",
    "        student.to(device)\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student(inputs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "            \n",
    "            # If not scalar, sum up to make sure the loss is scalar\n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "                \n",
    "            # Now combine the losses\n",
    "            loss = alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        print(f'*******Epoch {epoch}: loss - {epoch_loss}')\n",
    "        student_epoch_losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f4630d-f0d5-4d83-b61f-8707df8800a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_teacher(teacher, trainloader, criterion, optimizer, device, epochs_pretrain, patience=patience_student):\n",
    "    teacher.to(device)\n",
    "    teacher.train()  # Set the model to training mode\n",
    "    best_val_loss = float('inf')  \n",
    "    patience_counter = 0 \n",
    "    teacher_epoch_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs_pretrain):\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            teacher_outputs = teacher(inputs)\n",
    "\n",
    "            ce_loss = criterion(teacher_outputs, labels)\n",
    "                \n",
    "            loss = ce_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        epoch_loss /= num_batches\n",
    "        print(f'*******Epoch {epoch}: loss - {epoch_loss}')\n",
    "        teacher_epoch_losses.append(epoch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005d66e3-f169-4d59-bc29-b5c0e05816b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain_adversary(adv, model, adversary_optimizer, trainloader, adv_criterion, device, epochs_pretrain):\n",
    "\n",
    "  for epoch in range(epochs_pretrain):\n",
    "    epoch_loss = 0\n",
    "    epoch_batches = 0\n",
    "    for i, data in enumerate(tqdm(trainloader)): # starting from the 0th batch\n",
    "        # get the inputs and labels\n",
    "        adv.train()\n",
    "        adv.to(device)\n",
    "        inputs = data['img'].to(device)\n",
    "        labels = data['label'].to(device)\n",
    "        targets = data['target'].to(device)\n",
    "        model = model.to(device)\n",
    "        adversary_optimizer.zero_grad()\n",
    "        student_output = model(inputs)\n",
    "        one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "        concatenated_output = torch.cat((student_output, one_hot_labels), dim=1)\n",
    "        adversary_output = adv(concatenated_output)\n",
    "        adversary_loss = adv_criterion(adversary_output, targets) # compute loss\n",
    "        adversary_loss.backward() # back prop\n",
    "        adversary_optimizer.step()\n",
    "        epoch_loss += adversary_loss.item()\n",
    "        epoch_batches += 1\n",
    "\n",
    "    print(\"Average Pretrain Adversary epoch loss: \", epoch_loss/epoch_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7b4731c-f105-4192-9650-6587c46f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and scheduler for the student model\n",
    "student_optimizer = optim.Adam(student_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Optimizer and scheduler for the teacher model\n",
    "teacher_optimizer = optim.SGD(teacher_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "teacher_scheduler = torch.optim.lr_scheduler.StepLR(teacher_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "optimizer_adv = optim.Adam(adv.parameters(), lr=learning_rate)\n",
    "\n",
    "# Instantiate the model and the loss function\n",
    "criterion_clf = nn.CrossEntropyLoss()\n",
    "adv_criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3b7719f-4d65-4601-8e1d-1015de2201cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### finding the optimal learning rate\n",
    "# def train_teacher_optimal_lr(model, trainloader, criterion, optimizer, scheduler, device, epochs_optimal_lr=5, lr_range=(1e-4, 1e-1), plot_loss=True):\n",
    "#     model.train()\n",
    "#     model.to(device)\n",
    "#     lr_values = np.logspace(np.log10(lr_range[0]), np.log10(lr_range[1]), epochs_optimal_lr * len(trainloader))  # Generate learning rates for each batch\n",
    "#     lr_iter = iter(lr_values)\n",
    "#     losses = []\n",
    "#     lrs = []\n",
    "    \n",
    "#     for epoch in range(epochs_optimal_lr):\n",
    "#         for i, batch in enumerate(tqdm(trainloader)):\n",
    "#             lr = next(lr_iter)\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr'] = lr  # Set new learning rate\n",
    "            \n",
    "#             inputs, labels = batch['img'].to(device), batch['label'].to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             losses.append(loss.item())\n",
    "#             lrs.append(lr)\n",
    "    \n",
    "#     # Calculate the derivative of the loss\n",
    "#     loss_derivative = np.gradient(losses)\n",
    "    \n",
    "#     # Find the learning rate corresponding to the minimum derivative (steepest decline)\n",
    "#     best_lr_index = np.argmin(loss_derivative)\n",
    "#     best_lr = lrs[best_lr_index]\n",
    "    \n",
    "#     if plot_loss:\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.figure()\n",
    "#         plt.plot(lrs, losses)\n",
    "#         plt.xscale('log')\n",
    "#         plt.xlabel('Learning Rate')\n",
    "#         plt.ylabel('Loss')\n",
    "#         plt.title('Learning Rate Range Test - Teacher')\n",
    "#         plt.axvline(x=best_lr, color='red', linestyle='--', label=f'Best LR: {best_lr}')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "    \n",
    "#     print(f'Best Learning Rate Teacher: {best_lr}')\n",
    "#     return best_lr\n",
    "\n",
    "# ############# input ############## \n",
    "# best_lr_teacher = train_teacher_optimal_lr(teacher_model, trainloader, criterion_clf, teacher_optimizer, teacher_scheduler, device, epochs_optimal_lr)  \n",
    "# print(best_lr_teacher)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fc2fd75-c5a3-415d-8da7-32816addb845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### finding the optimal learning rate\n",
    "# def train_student_optimal_lr(model, trainloader, criterion, optimizer, device, epochs_optimal_lr=5, lr_range=(1e-4, 1e-1), plot_loss=True):\n",
    "#     model.train()\n",
    "#     model.to(device)\n",
    "#     lr_values = np.logspace(np.log10(lr_range[0]), np.log10(lr_range[1]), epochs_optimal_lr * len(trainloader))  # Generate learning rates for each batch\n",
    "#     lr_iter = iter(lr_values)\n",
    "#     losses = []\n",
    "#     lrs = []\n",
    "    \n",
    "#     for epoch in range(epochs_optimal_lr):\n",
    "#         for i, batch in enumerate(tqdm(trainloader)):\n",
    "#             lr = next(lr_iter)\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr'] = lr  # Set new learning rate\n",
    "            \n",
    "#             inputs, labels = batch['img'].to(device), batch['label'].to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             losses.append(loss.item())\n",
    "#             lrs.append(lr)\n",
    "    \n",
    "#     # Calculate the derivative of the loss\n",
    "#     loss_derivative = np.gradient(losses)\n",
    "    \n",
    "#     # Find the learning rate corresponding to the minimum derivative (steepest decline)\n",
    "#     best_lr_index = np.argmin(loss_derivative)\n",
    "#     best_lr = lrs[best_lr_index]\n",
    "    \n",
    "#     if plot_loss:\n",
    "#         import matplotlib.pyplot as plt\n",
    "#         plt.figure()\n",
    "#         plt.plot(lrs, losses)\n",
    "#         plt.xscale('log')\n",
    "#         plt.xlabel('Learning Rate')\n",
    "#         plt.ylabel('Loss')\n",
    "#         plt.title('Learning Rate Range Test - Student')\n",
    "#         plt.axvline(x=best_lr, color='red', linestyle='--', label=f'Best LR: {best_lr}')\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "    \n",
    "#     print(f'Best Learning Rate Student: {best_lr}')\n",
    "#     return best_lr\n",
    "\n",
    "# ############# input ############## \n",
    "# best_lr_student = train_student_optimal_lr(student_model, trainloader, criterion_clf, student_optimizer, device, epochs_optimal_lr)  \n",
    "# print(best_lr_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3997f6f4-9e71-41f1-964e-02d7b98e9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for testing, delete this cell\n",
    "# best_lr_teacher = learning_rate\n",
    "# best_lr_student = learning_rate\n",
    "\n",
    "best_lr_teacher = 0.003934318606406605\n",
    "best_lr_student = 0.006674426826180685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "411c4f7a-d0b4-478f-9fa5-5e152e08ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(losses):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    plt.plot(epochs, losses)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Val Loss Curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4c98aee-9c82-46f8-910b-4ca2ae4b9f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the adversary training function, where we input the student outputs, \n",
    "# with the true labels into the adversary model created previously.\n",
    "def train_adversary(adv, model, optimizer, trainloader, criterion, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_batches = 0\n",
    "        for i, data in enumerate(tqdm(trainloader)):\n",
    "            # get the inputs and labels\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            adv.train()\n",
    "            adv.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # output the student model, join with ohe labels. \n",
    "            model_output = model(inputs)\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((model_output, one_hot_labels), dim=1)\n",
    "            adversary_output = adv(concatenated_output)\n",
    "\n",
    "            adversary_loss = criterion(adversary_output, targets)\n",
    "            adversary_loss.backward()\n",
    "            epoch_loss += adversary_loss.item()\n",
    "            epoch_batches += 1\n",
    "            optimizer.step()\n",
    "        epoch_loss/=epoch_batches\n",
    "        print(\"Average Adversary epoch loss:\", epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "286386b2-d6e9-447e-95b5-b3dd8f18010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the teacher model\n",
    "def train_teacher(model, adv, trainloader, criterion, adv_criterion, optimizer, optimizer_adv, device, \n",
    "                  epochs, lmda, patience=patience_teacher):\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    epoch_losses = [] \n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    val_accuracies = []\n",
    "    best_total_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        adv.train()\n",
    "        model.to(device)\n",
    "        adv.to(device)\n",
    "        running_loss = 0.0\n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0  \n",
    "        \n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "        \n",
    "            # Forward pass for teacher model\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            classification_loss = criterion(outputs, labels)\n",
    "        \n",
    "            # Forward pass for adversary model\n",
    "            optimizer_adv.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs_detached = outputs.detach()\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((teacher_outputs_detached, one_hot_labels), dim=1)\n",
    "            adversary_output = adv(concatenated_output)\n",
    "            adversary_loss = adv_criterion(adversary_output, targets)\n",
    "        \n",
    "            # Calculate the total loss by combining classification and adversary loss\n",
    "            if lmda != 0:\n",
    "                total_loss = classification_loss + classification_loss/adversary_loss - lmda * adversary_loss\n",
    "            else:\n",
    "                total_loss = classification_loss\n",
    "                \n",
    "            total_loss.backward()\n",
    "        \n",
    "            optimizer.step()\n",
    "            optimizer_adv.step()\n",
    "        \n",
    "            running_loss += total_loss.item()\n",
    "            epoch_loss += total_loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches  \n",
    "        epoch_losses.append(epoch_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "                val_targets = val_data['target'].to(device)\n",
    "                \n",
    "                val_outputs = model(val_inputs)\n",
    "                with torch.no_grad():\n",
    "                    teacher_outputs_detached_val = val_outputs.detach()                \n",
    "                one_hot_labels_val = F.one_hot(val_labels, num_classes=num_classes).to(torch.float32)\n",
    "                concatenated_output_val = torch.cat((teacher_outputs_detached_val, one_hot_labels_val), dim=1)\n",
    "                adversary_output_val = adv(concatenated_output_val)\n",
    "                adversary_loss_val = adv_criterion(adversary_output_val, val_targets)\n",
    "                \n",
    "                # Compute validation loss\n",
    "                val_ce_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "                if lmda !=0:\n",
    "                    val_loss = val_ce_loss + val_ce_loss/adversary_loss_val - lmda * adversary_loss_val\n",
    "                else:\n",
    "                    val_loss = val_ce_loss\n",
    "                    \n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "\n",
    "                # Compute recall differences for gender\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(predicted, val_labels, val_targets, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "\n",
    "            total_val_loss /= num_batches\n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "            \n",
    "            epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_losses.append(total_val_loss)\n",
    "            non_zero_abs_values = np.abs(epoch_disparity[epoch_disparity != 0])\n",
    "            mean_non_zero_abs_disparity = np.mean(non_zero_abs_values)\n",
    "            val_disparities.append(mean_non_zero_abs_disparity)\n",
    "            accuracy = total_correct / total_samples\n",
    "            val_accuracies.append(accuracy)\n",
    "            print(f'*****Epoch {epoch + 1}/{epochs}*****\\n' \n",
    "            f'*****Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}*****\\n'\n",
    "            f'*****Validation Accuracy: {accuracy * 100:.2f}%*****\\n'\n",
    "            f'*****Total Avg Disparity: {mean_non_zero_abs_disparity}*****\\n')\n",
    "            class_recall_mapping = {class_name: epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "            \n",
    "            # Print disparities by class label\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                print(f\"Class {class_label}: Recall Difference = {recall_diff}\")\n",
    "        \n",
    "        # Check for early stopping\n",
    "        if abs(total_val_loss) < abs(best_total_val_loss):\n",
    "            best_total_val_loss = total_val_loss\n",
    "            patience_counter = 0 \n",
    "            best_epoch_mean_abs_disparity = mean_non_zero_abs_disparity\n",
    "            torch.save(model.state_dict(), f'teacher_model_weights_ckd_prof_checkpoint{lmda}.pth')\n",
    "            torch.save(model, f'teacher_model_ckd_prof_checkpoint{lmda}.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print('Early stopping')\n",
    "            break  \n",
    "        \n",
    "    plot_loss_curve(val_losses)\n",
    "    print(\"Finished Training Teacher\")\n",
    "    return val_disparities\n",
    "\n",
    "\n",
    "# Function to train the student model with knowledge distillation\n",
    "def train_student_with_distillation_disparity(student, teacher, adv, trainloader, testloader, criterion, adv_criterion, optimizer, \n",
    "                                              device, alpha, temperature, epochs, lmda, patience=patience_student, optimizer_adv=None):\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    best_val_accuracy = 0\n",
    "    best_total_val_loss = float('inf')\n",
    "    best_epoch_accuracy = 0.0\n",
    "    best_epoch_disparity = 0.0\n",
    "    patience_counter = 0 \n",
    "    student_epoch_losses = []\n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Train the adversary at the start of each epoch\n",
    "        train_adversary(adv, student, optimizer_adv, trainloader, adv_criterion, 1)\n",
    "\n",
    "        student.train()\n",
    "        student.to(device)\n",
    "        adv.eval()\n",
    "        adv.to(device)\n",
    "        running_loss = 0.0 \n",
    "        epoch_loss = 0.0  \n",
    "        num_batches = 0 \n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "\n",
    "        for index, data in enumerate(tqdm(trainloader)):\n",
    "            inputs = data['img'].to(device)\n",
    "            labels = data['label'].to(device)\n",
    "            targets = data['target'].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            student_outputs = student(inputs)\n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(inputs)\n",
    "\n",
    "            # detach student_outputs to avoid exploding gradients by passing same inputs (with gradience) into two different models. \n",
    "            studentached = student_outputs.detach()\n",
    "            # One-hot encode labels and concatenate with student's predictions\n",
    "            one_hot_labels = F.one_hot(labels, num_classes=num_classes).to(torch.float32)\n",
    "            concatenated_output = torch.cat((studentached, one_hot_labels), dim=1)\n",
    "\n",
    "            # Run the adversarial model on concatenated true labels, and predicted labels\n",
    "            with torch.no_grad():\n",
    "                adversary_output = adv(concatenated_output)\n",
    "\n",
    "            # Calc adversary loss, which is an MSE loss, because this is a regression output. \n",
    "            adversary_loss = adv_criterion(adversary_output, targets)\n",
    "            ce_loss = criterion(student_outputs, labels)\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "            \n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "\n",
    "            # Now combine the losses, subtract weighted adversary loss because we need to maximize that loss \n",
    "            # goal of the model is to have the adversary not predict gender. \n",
    "            if lmda != 0:\n",
    "                loss = (alpha * kd_loss + (1 - alpha) * ce_loss) + (alpha * kd_loss + (1 - alpha) * ce_loss)/adversary_loss - lmda * adversary_loss\n",
    "            else:\n",
    "                loss = alpha * kd_loss + (1 - alpha) * ce_loss\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        epoch_loss /= num_batches\n",
    "        # print(f'*******Epoch {epoch}: running_recall_with - {running_recall_with/num_batches}  |  running_recall_without - {running_recall_without/num_batches}  |  disparity - {epoch_disparity/num_batches}******')\n",
    "        student_epoch_losses.append(epoch_loss)\n",
    "\n",
    "        student.eval()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        # Validation after each epoch\n",
    "        with torch.no_grad():\n",
    "            for val_data in tqdm(testloader):\n",
    "                val_inputs = val_data['img'].to(device)\n",
    "                val_labels = val_data['label'].to(device)\n",
    "                val_targets = val_data['target'].to(device)\n",
    "                \n",
    "                # Forward pass for validation\n",
    "                val_student_outputs = student(val_inputs)\n",
    "                val_teacher_outputs = teacher(val_inputs)\n",
    "\n",
    "                val_studentached = val_student_outputs.detach()   \n",
    "                val_one_hot_labels = F.one_hot(val_labels, num_classes=num_classes).to(torch.float32)\n",
    "                val_concatenated_output = torch.cat((val_studentached, val_one_hot_labels), dim=1)\n",
    "                \n",
    "                val_adversary_output = adv(val_concatenated_output)\n",
    "                val_adversary_loss = adv_criterion(val_adversary_output, val_targets)\n",
    "                val_ce_loss = criterion(val_student_outputs, val_labels)\n",
    "                val_kd_loss = tkd_kdloss(val_student_outputs, val_teacher_outputs, temperature=temperature)  # Make sure this returns a scalar\n",
    "                \n",
    "                if val_kd_loss.ndim != 0:\n",
    "                    val_kd_loss = val_kd_loss.sum()\n",
    "                if lmda != 0:\n",
    "                    val_loss = (alpha * val_kd_loss + (1 - alpha) * val_ce_loss) + (alpha * val_kd_loss + (1 - alpha) * val_ce_loss)/val_adversary_loss - lmda * val_adversary_loss\n",
    "                else:\n",
    "                    val_loss = alpha * val_kd_loss + (1 - alpha) * val_ce_loss\n",
    "                total_val_loss += val_loss.item()\n",
    "    \n",
    "                # Compute the validation accuracy\n",
    "                _, predicted = torch.max(val_student_outputs, 1)\n",
    "                total_samples += val_labels.size(0)\n",
    "                total_correct += (predicted == val_labels).sum().item()\n",
    "                num_batches += 1\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(predicted, val_labels, val_targets, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "    \n",
    "            total_val_loss /= num_batches\n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "\n",
    "            epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_losses.append(total_val_loss)\n",
    "            non_zero_abs_values = np.abs(epoch_disparity[epoch_disparity != 0])\n",
    "            mean_non_zero_abs_disparity = np.mean(non_zero_abs_values)\n",
    "            val_disparities.append(mean_non_zero_abs_disparity)\n",
    "            accuracy = total_correct / total_samples\n",
    "            val_accuracies.append(accuracy)\n",
    "            print(f'*****Epoch {epoch + 1}/{epochs}*****\\n' \n",
    "            f'*****Train Loss: {epoch_loss: .6f} Val Loss: {total_val_loss: .6f}*****\\n'\n",
    "            f'*****Validation Accuracy: {accuracy * 100:.2f}%*****\\n'\n",
    "            f'*****Total Avg Disparity: {mean_non_zero_abs_disparity}*****\\n')\n",
    "            class_recall_mapping = {class_name: epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "            \n",
    "            # Print disparities by class label\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                print(f\"Class {class_label}: Recall Difference = {recall_diff}\")\n",
    "\n",
    "        # Check for early stopping\n",
    "        if abs(total_val_loss) < abs(best_total_val_loss):\n",
    "            best_total_val_loss = total_val_loss\n",
    "            patience_counter = 0\n",
    "            best_epoch_mean_abs_disparity = mean_non_zero_abs_disparity\n",
    "            torch.save(student.state_dict(), f'student_model_weights_ckd_wider_checkpoint_lambda{lmda}.pth')\n",
    "            torch.save(student, f'student_model_ckd_wider_checkpoint_lambda{lmda}.pth')\n",
    "        else:\n",
    "            patience_counter += 1 \n",
    "\n",
    "    \n",
    "        file_path = os.path.join(output_dir, f'validation_{lmda}.txt')\n",
    "        \n",
    "        # Append data to the text file\n",
    "        with open(file_path, 'a') as file:\n",
    "            file.write(f'********Epoch: {epochs}***********')\n",
    "            \n",
    "            file.write(\"Val Accuracies:\\n\")\n",
    "            for accuracy in val_accuracies:\n",
    "                file.write(f\"{accuracy}\\n\")\n",
    "        \n",
    "            file.write(\"\\nVal Disparities:\\n\")\n",
    "            for disparity in val_disparities:\n",
    "                file.write(f\"{disparity}\\n\")\n",
    "\n",
    "            for class_label, recall_diff in class_recall_mapping.items():\n",
    "                file.write(f\"Class {class_label}: Recall Difference = {recall_diff}\\n\")\n",
    "        \n",
    "        \n",
    "        print(f\"Data has been appended to {file_path}\")\n",
    "    plot_loss_curve(val_losses)\n",
    "                \n",
    "    return best_epoch_mean_abs_disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17a06902-9ad4-47a6-9a67-181e2dc43218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:09<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 0: loss - 2.8391029680928876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 1: loss - 2.554234581608926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 2: loss - 2.479052443658152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:05<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Pretrain Adversary epoch loss:  0.3419953575057368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:04<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Pretrain Adversary epoch loss:  0.34247224753902805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:04<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Pretrain Adversary epoch loss:  0.3417944244800075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.22s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 1/300*****\n",
      "*****Train Loss:  2.413507 Val Loss:  2.410408*****\n",
      "*****Validation Accuracy: 24.09%*****\n",
      "*****Total Avg Disparity: 0.0788982939130464*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.02922425426962627\n",
      "Class Celebration: Recall Difference = 0.007765151515151517\n",
      "Class Parade: Recall Difference = -0.0625\n",
      "Class Waiter_Or_Waitress: Recall Difference = 0.21333333333333337\n",
      "Class Individual_Sports: Recall Difference = -0.1470051687442992\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = 0.0\n",
      "Class Law_Enforcement: Recall Difference = 0.013698630136986304\n",
      "Class Business: Recall Difference = 0.0\n",
      "Class Dresses: Recall Difference = 0.0\n",
      "Class Water_Activities: Recall Difference = 0.1186813186813187\n",
      "Class Picnic: Recall Difference = 0.0\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.03897849462365591\n",
      "Class Family: Recall Difference = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.23s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 2/300*****\n",
      "*****Train Loss:  2.368456 Val Loss:  2.309304*****\n",
      "*****Validation Accuracy: 26.28%*****\n",
      "*****Total Avg Disparity: 0.032066282141888856*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.03392433337986889\n",
      "Class Celebration: Recall Difference = 0.012689393939393931\n",
      "Class Parade: Recall Difference = -0.009469696969696961\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.08\n",
      "Class Individual_Sports: Recall Difference = 0.006840985101854685\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = 0.0\n",
      "Class Law_Enforcement: Recall Difference = 0.029843444227005855\n",
      "Class Business: Recall Difference = 0.005627705627705624\n",
      "Class Dresses: Recall Difference = -0.006172839506172811\n",
      "Class Water_Activities: Recall Difference = 0.026373626373626335\n",
      "Class Picnic: Recall Difference = 0.0\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.03773584905660378\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.05040322580645164\n",
      "Class Family: Recall Difference = -0.08571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:09<00:00,  4.18s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 3/300*****\n",
      "*****Train Loss:  2.328586 Val Loss:  2.417319*****\n",
      "*****Validation Accuracy: 22.48%*****\n",
      "*****Total Avg Disparity: 0.05880519651823477*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.06733677695565166\n",
      "Class Celebration: Recall Difference = -0.023484848484848487\n",
      "Class Parade: Recall Difference = 0.02651515151515149\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.1\n",
      "Class Individual_Sports: Recall Difference = 0.01702645180906051\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = 0.0\n",
      "Class Law_Enforcement: Recall Difference = -0.04696673189823877\n",
      "Class Business: Recall Difference = 0.07142857142857142\n",
      "Class Dresses: Recall Difference = 0.1419753086419753\n",
      "Class Water_Activities: Recall Difference = 0.05934065934065935\n",
      "Class Picnic: Recall Difference = -0.08695652173913043\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.05510752688172044\n",
      "Class Family: Recall Difference = -0.009523809523809525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.22s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 4/300*****\n",
      "*****Train Loss:  2.281300 Val Loss:  2.320005*****\n",
      "*****Validation Accuracy: 25.76%*****\n",
      "*****Total Avg Disparity: 0.12124848260306823*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.02266275768998094\n",
      "Class Celebration: Recall Difference = 0.007575757575757569\n",
      "Class Parade: Recall Difference = -0.13068181818181815\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.19666666666666663\n",
      "Class Individual_Sports: Recall Difference = -0.013529948312556939\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = -0.6\n",
      "Class Law_Enforcement: Recall Difference = 0.01027397260273974\n",
      "Class Business: Recall Difference = 0.023809523809523815\n",
      "Class Dresses: Recall Difference = 0.030864197530864168\n",
      "Class Water_Activities: Recall Difference = 0.08571428571428569\n",
      "Class Picnic: Recall Difference = 0.09937888198757763\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = -0.021739130434782608\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.0\n",
      "Class Family: Recall Difference = 0.33333333333333337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:09<00:00,  4.19s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 5/300*****\n",
      "*****Train Loss:  2.246456 Val Loss:  2.244471*****\n",
      "*****Validation Accuracy: 27.78%*****\n",
      "*****Total Avg Disparity: 0.08673542464378678*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.001489133975522361\n",
      "Class Celebration: Recall Difference = -0.07821969696969697\n",
      "Class Parade: Recall Difference = -0.05492424242424243\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.19666666666666666\n",
      "Class Individual_Sports: Recall Difference = -0.15475828519306775\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = -0.16\n",
      "Class Law_Enforcement: Recall Difference = 0.10029354207436397\n",
      "Class Business: Recall Difference = -0.01255411255411256\n",
      "Class Dresses: Recall Difference = -0.20370370370370375\n",
      "Class Water_Activities: Recall Difference = 0.09010989010989012\n",
      "Class Picnic: Recall Difference = -0.07453416149068323\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = -0.02173913043478261\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.055779569892473124\n",
      "Class Family: Recall Difference = 0.009523809523809545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:09<00:00,  4.18s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 6/300*****\n",
      "*****Train Loss:  2.220496 Val Loss:  2.229476*****\n",
      "*****Validation Accuracy: 30.66%*****\n",
      "*****Total Avg Disparity: 0.08052699749122351*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.03792638093908507\n",
      "Class Celebration: Recall Difference = -0.03920454545454546\n",
      "Class Parade: Recall Difference = -0.10037878787878796\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.19666666666666663\n",
      "Class Individual_Sports: Recall Difference = -0.08650045606567347\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = -0.16\n",
      "Class Law_Enforcement: Recall Difference = 0.03131115459882583\n",
      "Class Business: Recall Difference = -0.17056277056277055\n",
      "Class Dresses: Recall Difference = 0.018518518518518545\n",
      "Class Water_Activities: Recall Difference = 0.09670329670329669\n",
      "Class Picnic: Recall Difference = 0.012422360248447256\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.016129032258064516\n",
      "Class Family: Recall Difference = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.21s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 7/300*****\n",
      "*****Train Loss:  2.198964 Val Loss:  2.192185*****\n",
      "*****Validation Accuracy: 30.78%*****\n",
      "*****Total Avg Disparity: 0.09983332493210219*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.03992740471869338\n",
      "Class Celebration: Recall Difference = -0.04185606060606059\n",
      "Class Parade: Recall Difference = -0.026515151515151436\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.09666666666666665\n",
      "Class Individual_Sports: Recall Difference = -0.10276679841897246\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = -0.52\n",
      "Class Law_Enforcement: Recall Difference = -0.012720156555772966\n",
      "Class Business: Recall Difference = -0.14112554112554113\n",
      "Class Dresses: Recall Difference = -0.08641975308641975\n",
      "Class Water_Activities: Recall Difference = 0.14065934065934066\n",
      "Class Picnic: Recall Difference = 0.05590062111801243\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.0047043010752688165\n",
      "Class Family: Recall Difference = 0.028571428571428567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:12<00:00,  4.28s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 8/300*****\n",
      "*****Train Loss:  2.153351 Val Loss:  2.352193*****\n",
      "*****Validation Accuracy: 29.39%*****\n",
      "*****Total Avg Disparity: 0.05874396979440754*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.0363907115268276\n",
      "Class Celebration: Recall Difference = -0.07329545454545455\n",
      "Class Parade: Recall Difference = 0.013257575757575635\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.15666666666666668\n",
      "Class Individual_Sports: Recall Difference = -0.07798723016114317\n",
      "Class Surgeons: Recall Difference = 0.0\n",
      "Class Spa: Recall Difference = 0.0\n",
      "Class Law_Enforcement: Recall Difference = 0.09589041095890409\n",
      "Class Business: Recall Difference = -0.018181818181818184\n",
      "Class Dresses: Recall Difference = -0.17901234567901234\n",
      "Class Water_Activities: Recall Difference = -0.013186813186813223\n",
      "Class Picnic: Recall Difference = 0.0124223602484472\n",
      "Class Rescue: Recall Difference = 0.010000000000000002\n",
      "Class Cheering: Recall Difference = -0.04347826086956522\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.045026881720430095\n",
      "Class Family: Recall Difference = -0.04761904761904759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.23s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 9/300*****\n",
      "*****Train Loss:  2.122315 Val Loss:  2.158688*****\n",
      "*****Validation Accuracy: 31.93%*****\n",
      "*****Total Avg Disparity: 0.07982437376488595*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.0012564567918470493\n",
      "Class Celebration: Recall Difference = -0.039393939393939426\n",
      "Class Parade: Recall Difference = 0.07007575757575757\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.13666666666666671\n",
      "Class Individual_Sports: Recall Difference = -0.1991486774095469\n",
      "Class Surgeons: Recall Difference = -0.00882352941176471\n",
      "Class Spa: Recall Difference = -0.08\n",
      "Class Law_Enforcement: Recall Difference = 0.16144814090019569\n",
      "Class Business: Recall Difference = -0.12294372294372294\n",
      "Class Dresses: Recall Difference = -0.08024691358024691\n",
      "Class Water_Activities: Recall Difference = 0.08791208791208793\n",
      "Class Picnic: Recall Difference = 0.1118012422360248\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = -0.002871205906480722\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.03763440860215053\n",
      "Class Family: Recall Difference = -0.05714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.22s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 10/300*****\n",
      "*****Train Loss:  2.100395 Val Loss:  2.241641*****\n",
      "*****Validation Accuracy: 28.01%*****\n",
      "*****Total Avg Disparity: 0.14557368293350129*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.052864256131043785\n",
      "Class Celebration: Recall Difference = -0.02102272727272725\n",
      "Class Parade: Recall Difference = -0.09280303030303039\n",
      "Class Waiter_Or_Waitress: Recall Difference = 0.053333333333333344\n",
      "Class Individual_Sports: Recall Difference = -0.1152325934934631\n",
      "Class Surgeons: Recall Difference = -0.044117647058823484\n",
      "Class Spa: Recall Difference = -0.32\n",
      "Class Law_Enforcement: Recall Difference = 0.15557729941291581\n",
      "Class Business: Recall Difference = 0.08701298701298701\n",
      "Class Dresses: Recall Difference = -0.4012345679012347\n",
      "Class Water_Activities: Recall Difference = 0.13186813186813184\n",
      "Class Picnic: Recall Difference = -0.07453416149068323\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.0\n",
      "Class Family: Recall Difference = -0.34285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.25s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 11/300*****\n",
      "*****Train Loss:  2.083776 Val Loss:  2.050118*****\n",
      "*****Validation Accuracy: 34.81%*****\n",
      "*****Total Avg Disparity: 0.0845253000384159*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.05477220903718194\n",
      "Class Celebration: Recall Difference = -0.13579545454545458\n",
      "Class Parade: Recall Difference = -0.04734848484848475\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.03666666666666667\n",
      "Class Individual_Sports: Recall Difference = -0.13073882639100037\n",
      "Class Surgeons: Recall Difference = -0.026470588235294107\n",
      "Class Spa: Recall Difference = -0.04\n",
      "Class Law_Enforcement: Recall Difference = 0.06800391389432486\n",
      "Class Business: Recall Difference = -0.11168831168831167\n",
      "Class Dresses: Recall Difference = -0.2777777777777777\n",
      "Class Water_Activities: Recall Difference = 0.10109890109890107\n",
      "Class Picnic: Recall Difference = 0.0124223602484472\n",
      "Class Rescue: Recall Difference = 0.025\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.0477150537634409\n",
      "Class Family: Recall Difference = -0.1523809523809524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:12<00:00,  4.26s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 12/300*****\n",
      "*****Train Loss:  2.039102 Val Loss:  2.113349*****\n",
      "*****Validation Accuracy: 33.37%*****\n",
      "*****Total Avg Disparity: 0.09687340797956222*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.020940946530783155\n",
      "Class Celebration: Recall Difference = -0.060416666666666674\n",
      "Class Parade: Recall Difference = 0.06060606060606066\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.15666666666666665\n",
      "Class Individual_Sports: Recall Difference = -0.08422012769838849\n",
      "Class Surgeons: Recall Difference = 0.09117647058823529\n",
      "Class Spa: Recall Difference = -0.2\n",
      "Class Law_Enforcement: Recall Difference = 0.3067514677103718\n",
      "Class Business: Recall Difference = -0.08095238095238097\n",
      "Class Dresses: Recall Difference = -0.12345679012345677\n",
      "Class Water_Activities: Recall Difference = -0.019780219780219765\n",
      "Class Picnic: Recall Difference = -0.031055900621118043\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.053732567678424936\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.04905913978494625\n",
      "Class Family: Recall Difference = -0.11428571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.20s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 13/300*****\n",
      "*****Train Loss:  2.014832 Val Loss:  2.142711*****\n",
      "*****Validation Accuracy: 30.72%*****\n",
      "*****Total Avg Disparity: 0.1187706372003072*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.19335473963423133\n",
      "Class Celebration: Recall Difference = 0.04640151515151514\n",
      "Class Parade: Recall Difference = 0.003787878787878729\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.21666666666666667\n",
      "Class Individual_Sports: Recall Difference = 0.013833992094861608\n",
      "Class Surgeons: Recall Difference = 0.05\n",
      "Class Spa: Recall Difference = -0.16\n",
      "Class Law_Enforcement: Recall Difference = 0.19667318982387477\n",
      "Class Business: Recall Difference = 0.033766233766233764\n",
      "Class Dresses: Recall Difference = -0.33333333333333337\n",
      "Class Water_Activities: Recall Difference = 0.10109890109890107\n",
      "Class Picnic: Recall Difference = 0.006211180124223614\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.040994623655914\n",
      "Class Family: Recall Difference = 0.2666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.23s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 14/300*****\n",
      "*****Train Loss:  2.007445 Val Loss:  1.993185*****\n",
      "*****Validation Accuracy: 38.16%*****\n",
      "*****Total Avg Disparity: 0.1178080330626106*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.05737819349434581\n",
      "Class Celebration: Recall Difference = -0.08636363636363636\n",
      "Class Parade: Recall Difference = 0.0018939393939393923\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.10333333333333322\n",
      "Class Individual_Sports: Recall Difference = -0.13241106719367585\n",
      "Class Surgeons: Recall Difference = -0.017647058823529405\n",
      "Class Spa: Recall Difference = -0.27999999999999997\n",
      "Class Law_Enforcement: Recall Difference = 0.16634050880626222\n",
      "Class Business: Recall Difference = -0.154978354978355\n",
      "Class Dresses: Recall Difference = -0.4197530864197531\n",
      "Class Water_Activities: Recall Difference = 0.10989010989010989\n",
      "Class Picnic: Recall Difference = 0.06832298136645965\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = -0.0028712059064807255\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.004032258064516181\n",
      "Class Family: Recall Difference = -0.1619047619047619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.20s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 15/300*****\n",
      "*****Train Loss:  1.970628 Val Loss:  2.051366*****\n",
      "*****Validation Accuracy: 36.37%*****\n",
      "*****Total Avg Disparity: 0.10452201604787421*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.002978267951044722\n",
      "Class Celebration: Recall Difference = 0.015151515151515166\n",
      "Class Parade: Recall Difference = -0.026515151515151436\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.09666666666666666\n",
      "Class Individual_Sports: Recall Difference = -0.16114320462146542\n",
      "Class Surgeons: Recall Difference = 0.01470588235294118\n",
      "Class Spa: Recall Difference = -0.27999999999999997\n",
      "Class Law_Enforcement: Recall Difference = 0.10909980430528379\n",
      "Class Business: Recall Difference = -0.07662337662337668\n",
      "Class Dresses: Recall Difference = -0.22839506172839505\n",
      "Class Water_Activities: Recall Difference = 0.1384615384615384\n",
      "Class Picnic: Recall Difference = 0.1118012422360248\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = 0.0\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.07795698924731184\n",
      "Class Family: Recall Difference = 0.12380952380952379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.25s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 16/300*****\n",
      "*****Train Loss:  1.931424 Val Loss:  2.045080*****\n",
      "*****Validation Accuracy: 37.75%*****\n",
      "*****Total Avg Disparity: 0.1125869680524139*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08506677835171472\n",
      "Class Celebration: Recall Difference = -0.00303030303030305\n",
      "Class Parade: Recall Difference = 0.032196969696969724\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.13\n",
      "Class Individual_Sports: Recall Difference = -0.2543326238978413\n",
      "Class Surgeons: Recall Difference = -0.026470588235294107\n",
      "Class Spa: Recall Difference = -0.24\n",
      "Class Law_Enforcement: Recall Difference = 0.10616438356164387\n",
      "Class Business: Recall Difference = -0.13809523809523805\n",
      "Class Dresses: Recall Difference = -0.4444444444444445\n",
      "Class Water_Activities: Recall Difference = -0.01318681318681314\n",
      "Class Picnic: Recall Difference = 0.09937888198757763\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = -0.005742411812961437\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.015456989247311814\n",
      "Class Family: Recall Difference = -0.09523809523809523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.21s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 17/300*****\n",
      "*****Train Loss:  1.916186 Val Loss:  1.936389*****\n",
      "*****Validation Accuracy: 37.98%*****\n",
      "*****Total Avg Disparity: 0.11815469140801778*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.02759551398389859\n",
      "Class Celebration: Recall Difference = -0.03162878787878787\n",
      "Class Parade: Recall Difference = 0.030303030303030387\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.31\n",
      "Class Individual_Sports: Recall Difference = -0.09972636059592577\n",
      "Class Surgeons: Recall Difference = 0.07352941176470587\n",
      "Class Spa: Recall Difference = -0.24\n",
      "Class Law_Enforcement: Recall Difference = 0.13600782778864973\n",
      "Class Business: Recall Difference = -0.15194805194805183\n",
      "Class Dresses: Recall Difference = -0.39506172839506176\n",
      "Class Water_Activities: Recall Difference = -0.015384615384615441\n",
      "Class Picnic: Recall Difference = 0.12422360248447206\n",
      "Class Rescue: Recall Difference = 0.0\n",
      "Class Cheering: Recall Difference = -0.04347826086956522\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.03629032258064521\n",
      "Class Family: Recall Difference = -0.05714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:12<00:00,  4.26s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 18/300*****\n",
      "*****Train Loss:  1.892877 Val Loss:  1.977411*****\n",
      "*****Validation Accuracy: 36.66%*****\n",
      "*****Total Avg Disparity: 0.13301025911959663*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.13797756991949384\n",
      "Class Celebration: Recall Difference = 0.07234848484848486\n",
      "Class Parade: Recall Difference = 0.026515151515151603\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.13\n",
      "Class Individual_Sports: Recall Difference = -0.12222560048647002\n",
      "Class Surgeons: Recall Difference = 0.19117647058823528\n",
      "Class Spa: Recall Difference = -0.27999999999999997\n",
      "Class Law_Enforcement: Recall Difference = 0.27299412915851284\n",
      "Class Business: Recall Difference = -0.033333333333333354\n",
      "Class Dresses: Recall Difference = -0.4938271604938271\n",
      "Class Water_Activities: Recall Difference = -0.04835164835164829\n",
      "Class Picnic: Recall Difference = -0.018633540372670787\n",
      "Class Rescue: Recall Difference = -0.04\n",
      "Class Cheering: Recall Difference = -0.05496308449548809\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.024865591397849496\n",
      "Class Family: Recall Difference = -0.18095238095238095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.20s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 19/300*****\n",
      "*****Train Loss:  1.860727 Val Loss:  2.037374*****\n",
      "*****Validation Accuracy: 36.89%*****\n",
      "*****Total Avg Disparity: 0.12924982106231817*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.07934291963330065\n",
      "Class Celebration: Recall Difference = 0.025378787878787834\n",
      "Class Parade: Recall Difference = -0.0018939393939393367\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.15000000000000008\n",
      "Class Individual_Sports: Recall Difference = -0.0585284280936455\n",
      "Class Surgeons: Recall Difference = 0.12352941176470589\n",
      "Class Spa: Recall Difference = -0.27999999999999997\n",
      "Class Law_Enforcement: Recall Difference = 0.1545988258317027\n",
      "Class Business: Recall Difference = -0.22207792207792207\n",
      "Class Dresses: Recall Difference = -0.4691358024691358\n",
      "Class Water_Activities: Recall Difference = -0.08571428571428569\n",
      "Class Picnic: Recall Difference = -0.11801242236024842\n",
      "Class Rescue: Recall Difference = 0.025\n",
      "Class Cheering: Recall Difference = -0.030352748154224785\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.14919354838709675\n",
      "Class Family: Recall Difference = -0.0952380952380952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:09<00:00,  4.18s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 20/300*****\n",
      "*****Train Loss:  1.844275 Val Loss:  2.037584*****\n",
      "*****Validation Accuracy: 39.37%*****\n",
      "*****Total Avg Disparity: 0.10831227830840101*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = -0.011726930057238572\n",
      "Class Celebration: Recall Difference = -0.1460227272727273\n",
      "Class Parade: Recall Difference = 0.07575757575757591\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.06000000000000005\n",
      "Class Individual_Sports: Recall Difference = -0.21313469139556096\n",
      "Class Surgeons: Recall Difference = 0.032352941176470584\n",
      "Class Spa: Recall Difference = -0.24\n",
      "Class Law_Enforcement: Recall Difference = 0.14677103718199613\n",
      "Class Business: Recall Difference = -0.18008658008658007\n",
      "Class Dresses: Recall Difference = -0.20987654320987656\n",
      "Class Water_Activities: Recall Difference = 0.052747252747252726\n",
      "Class Picnic: Recall Difference = 0.19875776397515527\n",
      "Class Rescue: Recall Difference = -0.015\n",
      "Class Cheering: Recall Difference = -0.024610336341263334\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.03091397849462363\n",
      "Class Family: Recall Difference = -0.09523809523809522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.24s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 21/300*****\n",
      "*****Train Loss:  1.809711 Val Loss:  2.007633*****\n",
      "*****Validation Accuracy: 36.14%*****\n",
      "*****Total Avg Disparity: 0.09401604266927972*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08027362836800228\n",
      "Class Celebration: Recall Difference = -0.047537878787878796\n",
      "Class Parade: Recall Difference = -0.045454545454545414\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.23333333333333334\n",
      "Class Individual_Sports: Recall Difference = -0.03602918820310119\n",
      "Class Surgeons: Recall Difference = 0.02352941176470591\n",
      "Class Spa: Recall Difference = -0.32\n",
      "Class Law_Enforcement: Recall Difference = 0.09442270058708424\n",
      "Class Business: Recall Difference = -0.05974025974025976\n",
      "Class Dresses: Recall Difference = -0.26543209876543206\n",
      "Class Water_Activities: Recall Difference = -0.00879120879120876\n",
      "Class Picnic: Recall Difference = -0.006211180124223614\n",
      "Class Rescue: Recall Difference = 0.060000000000000005\n",
      "Class Cheering: Recall Difference = -0.052091878589007407\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.05712365591397851\n",
      "Class Family: Recall Difference = -0.11428571428571432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:09<00:00,  4.16s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 22/300*****\n",
      "*****Train Loss:  1.788129 Val Loss:  1.982721*****\n",
      "*****Validation Accuracy: 38.33%*****\n",
      "*****Total Avg Disparity: 0.1340766413280454*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.07515473032714415\n",
      "Class Celebration: Recall Difference = -0.008333333333333304\n",
      "Class Parade: Recall Difference = -0.10416666666666669\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.04333333333333328\n",
      "Class Individual_Sports: Recall Difference = -0.12617816965643053\n",
      "Class Surgeons: Recall Difference = 0.18235294117647055\n",
      "Class Spa: Recall Difference = -0.32\n",
      "Class Law_Enforcement: Recall Difference = 0.1394324853228963\n",
      "Class Business: Recall Difference = -0.12424242424242427\n",
      "Class Dresses: Recall Difference = -0.38888888888888884\n",
      "Class Water_Activities: Recall Difference = 0.04175824175824172\n",
      "Class Picnic: Recall Difference = -0.06211180124223603\n",
      "Class Rescue: Recall Difference = 0.16\n",
      "Class Cheering: Recall Difference = 0.03486464315012304\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.13440860215053757\n",
      "Class Family: Recall Difference = -0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.21s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 23/300*****\n",
      "*****Train Loss:  1.770953 Val Loss:  1.931877*****\n",
      "*****Validation Accuracy: 39.77%*****\n",
      "*****Total Avg Disparity: 0.12641167706103906*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.0724091395597748\n",
      "Class Celebration: Recall Difference = 0.02026515151515146\n",
      "Class Parade: Recall Difference = 0.04166666666666663\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.10333333333333328\n",
      "Class Individual_Sports: Recall Difference = -0.20234113712374585\n",
      "Class Surgeons: Recall Difference = 0.06470588235294117\n",
      "Class Spa: Recall Difference = -0.32\n",
      "Class Law_Enforcement: Recall Difference = -0.04452054794520546\n",
      "Class Business: Recall Difference = -0.017748917748917736\n",
      "Class Dresses: Recall Difference = -0.43827160493827155\n",
      "Class Water_Activities: Recall Difference = -0.00439560439560438\n",
      "Class Picnic: Recall Difference = -0.42236024844720493\n",
      "Class Rescue: Recall Difference = 0.08499999999999999\n",
      "Class Cheering: Recall Difference = -0.049220672682526674\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.031586021505376344\n",
      "Class Family: Recall Difference = -0.10476190476190472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:12<00:00,  4.28s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 24/300*****\n",
      "*****Train Loss:  1.728467 Val Loss:  1.954864*****\n",
      "*****Validation Accuracy: 38.44%*****\n",
      "*****Total Avg Disparity: 0.11271671247572276*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.1499837125971425\n",
      "Class Celebration: Recall Difference = -0.06818181818181818\n",
      "Class Parade: Recall Difference = 0.06060606060606066\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.0633333333333333\n",
      "Class Individual_Sports: Recall Difference = -0.2091821222256005\n",
      "Class Surgeons: Recall Difference = -0.044117647058823484\n",
      "Class Spa: Recall Difference = -0.08\n",
      "Class Law_Enforcement: Recall Difference = 0.14774951076320936\n",
      "Class Business: Recall Difference = 0.051948051948051965\n",
      "Class Dresses: Recall Difference = -0.5679012345679013\n",
      "Class Water_Activities: Recall Difference = -0.008791208791208815\n",
      "Class Picnic: Recall Difference = -0.14906832298136635\n",
      "Class Rescue: Recall Difference = 0.034999999999999996\n",
      "Class Cheering: Recall Difference = -0.03609515996718621\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.09341397849462363\n",
      "Class Family: Recall Difference = -0.0380952380952381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.25s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 25/300*****\n",
      "*****Train Loss:  1.738061 Val Loss:  1.853717*****\n",
      "*****Validation Accuracy: 43.34%*****\n",
      "*****Total Avg Disparity: 0.1365319493406673*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.1202010330866955\n",
      "Class Celebration: Recall Difference = -0.07367424242424231\n",
      "Class Parade: Recall Difference = 0.03598484848484845\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.0633333333333333\n",
      "Class Individual_Sports: Recall Difference = -0.11842505320766195\n",
      "Class Surgeons: Recall Difference = 0.11470588235294116\n",
      "Class Spa: Recall Difference = -0.24\n",
      "Class Law_Enforcement: Recall Difference = 0.09197651663405082\n",
      "Class Business: Recall Difference = -0.08917748917748919\n",
      "Class Dresses: Recall Difference = -0.5185185185185185\n",
      "Class Water_Activities: Recall Difference = 0.02857142857142858\n",
      "Class Picnic: Recall Difference = -0.10559006211180127\n",
      "Class Rescue: Recall Difference = 0.08499999999999999\n",
      "Class Cheering: Recall Difference = -0.09557013945857262\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.07997311827956985\n",
      "Class Family: Recall Difference = -0.3238095238095238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:10<00:00,  4.22s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 26/300*****\n",
      "*****Train Loss:  1.674532 Val Loss:  1.857973*****\n",
      "*****Validation Accuracy: 43.05%*****\n",
      "*****Total Avg Disparity: 0.09270660348232028*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.10307599236818854\n",
      "Class Celebration: Recall Difference = 0.03579545454545449\n",
      "Class Parade: Recall Difference = 0.03598484848484851\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.08666666666666673\n",
      "Class Individual_Sports: Recall Difference = -0.1059592581331712\n",
      "Class Surgeons: Recall Difference = 0.11470588235294116\n",
      "Class Spa: Recall Difference = -0.27999999999999997\n",
      "Class Law_Enforcement: Recall Difference = 0.03718199608610556\n",
      "Class Business: Recall Difference = -0.11991341991341992\n",
      "Class Dresses: Recall Difference = -0.2839506172839507\n",
      "Class Water_Activities: Recall Difference = -0.06813186813186822\n",
      "Class Picnic: Recall Difference = 0.0248447204968944\n",
      "Class Rescue: Recall Difference = 0.075\n",
      "Class Cheering: Recall Difference = 0.06111566858080397\n",
      "Class Performance_And_Entertainment: Recall Difference = 0.003360215053763438\n",
      "Class Family: Recall Difference = -0.047619047619047616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.23s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 27/300*****\n",
      "*****Train Loss:  1.652323 Val Loss:  2.055117*****\n",
      "*****Validation Accuracy: 38.04%*****\n",
      "*****Total Avg Disparity: 0.13983395778617289*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.06654567453115551\n",
      "Class Celebration: Recall Difference = 0.04375000000000004\n",
      "Class Parade: Recall Difference = -0.026515151515151436\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.15666666666666662\n",
      "Class Individual_Sports: Recall Difference = -0.15643052599574336\n",
      "Class Surgeons: Recall Difference = -0.044117647058823484\n",
      "Class Spa: Recall Difference = -0.24\n",
      "Class Law_Enforcement: Recall Difference = 0.15851272015655585\n",
      "Class Business: Recall Difference = -0.05714285714285716\n",
      "Class Dresses: Recall Difference = -0.6296296296296297\n",
      "Class Water_Activities: Recall Difference = 0.14065934065934071\n",
      "Class Picnic: Recall Difference = -0.23602484472049684\n",
      "Class Rescue: Recall Difference = 0.1\n",
      "Class Cheering: Recall Difference = -0.004101722723543838\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.024865591397849468\n",
      "Class Family: Recall Difference = -0.15238095238095228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.24s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 28/300*****\n",
      "*****Train Loss:  1.632937 Val Loss:  1.995400*****\n",
      "*****Validation Accuracy: 40.12%*****\n",
      "*****Total Avg Disparity: 0.11524547930652415*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.03345897901251804\n",
      "Class Celebration: Recall Difference = -0.02102272727272725\n",
      "Class Parade: Recall Difference = 0.06628787878787873\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.10333333333333333\n",
      "Class Individual_Sports: Recall Difference = -0.06552143508665254\n",
      "Class Surgeons: Recall Difference = 0.24117647058823527\n",
      "Class Spa: Recall Difference = -0.04\n",
      "Class Law_Enforcement: Recall Difference = 0.034735812133072363\n",
      "Class Business: Recall Difference = -0.11168831168831167\n",
      "Class Dresses: Recall Difference = -0.4444444444444445\n",
      "Class Water_Activities: Recall Difference = -0.00879120879120876\n",
      "Class Picnic: Recall Difference = -0.11801242236024842\n",
      "Class Rescue: Recall Difference = 0.2\n",
      "Class Cheering: Recall Difference = 0.08285479901558654\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.015456989247311814\n",
      "Class Family: Recall Difference = -0.2571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:12<00:00,  4.27s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 29/300*****\n",
      "*****Train Loss:  1.572598 Val Loss:  2.012973*****\n",
      "*****Validation Accuracy: 41.27%*****\n",
      "*****Total Avg Disparity: 0.09495623245016796*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.00944669365721984\n",
      "Class Celebration: Recall Difference = -0.010795454545454497\n",
      "Class Parade: Recall Difference = -0.0037878787878787845\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.1466666666666666\n",
      "Class Individual_Sports: Recall Difference = -0.11234417756156878\n",
      "Class Surgeons: Recall Difference = 0.15\n",
      "Class Spa: Recall Difference = -0.27999999999999997\n",
      "Class Law_Enforcement: Recall Difference = 0.10078277886497056\n",
      "Class Business: Recall Difference = -0.05021645021645024\n",
      "Class Dresses: Recall Difference = -0.38888888888888884\n",
      "Class Water_Activities: Recall Difference = 0.04395604395604402\n",
      "Class Picnic: Recall Difference = -0.07453416149068326\n",
      "Class Rescue: Recall Difference = 0.075\n",
      "Class Cheering: Recall Difference = -0.004101722723543866\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.049731182795698936\n",
      "Class Family: Recall Difference = 0.019047619047619035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:08<00:00,  4.14s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 30/300*****\n",
      "*****Train Loss:  1.556094 Val Loss:  1.955754*****\n",
      "*****Validation Accuracy: 40.81%*****\n",
      "*****Total Avg Disparity: 0.11742934416115985*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.08716087300479314\n",
      "Class Celebration: Recall Difference = 0.04375000000000004\n",
      "Class Parade: Recall Difference = 0.04356060606060613\n",
      "Class Waiter_Or_Waitress: Recall Difference = 0.09666666666666668\n",
      "Class Individual_Sports: Recall Difference = -0.11842505320766189\n",
      "Class Surgeons: Recall Difference = 0.18235294117647058\n",
      "Class Spa: Recall Difference = -0.44000000000000006\n",
      "Class Law_Enforcement: Recall Difference = 0.15019569471624264\n",
      "Class Business: Recall Difference = 0.010389610389610393\n",
      "Class Dresses: Recall Difference = -0.15432098765432098\n",
      "Class Water_Activities: Recall Difference = 0.04835164835164846\n",
      "Class Picnic: Recall Difference = -0.2919254658385093\n",
      "Class Rescue: Recall Difference = 0.024999999999999994\n",
      "Class Cheering: Recall Difference = 0.004511894995898269\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.11559139784946237\n",
      "Class Family: Recall Difference = -0.06666666666666668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:11<00:00,  4.23s/it]\n",
      "100%|| 5/5 [00:09<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****Epoch 31/300*****\n",
      "*****Train Loss:  1.505386 Val Loss:  1.869605*****\n",
      "*****Validation Accuracy: 43.75%*****\n",
      "*****Total Avg Disparity: 0.12965992450859548*****\n",
      "\n",
      "Class Team_Sports: Recall Difference = 0.14007166457257192\n",
      "Class Celebration: Recall Difference = -0.027083333333333293\n",
      "Class Parade: Recall Difference = 0.125\n",
      "Class Waiter_Or_Waitress: Recall Difference = -0.030000000000000027\n",
      "Class Individual_Sports: Recall Difference = -0.07646701124961991\n",
      "Class Surgeons: Recall Difference = 0.17352941176470585\n",
      "Class Spa: Recall Difference = -0.32\n",
      "Class Law_Enforcement: Recall Difference = 0.03669275929549887\n",
      "Class Business: Recall Difference = -0.03722943722943722\n",
      "Class Dresses: Recall Difference = -0.5432098765432098\n",
      "Class Water_Activities: Recall Difference = -0.03516483516483515\n",
      "Class Picnic: Recall Difference = -0.2919254658385093\n",
      "Class Rescue: Recall Difference = 0.020000000000000018\n",
      "Class Cheering: Recall Difference = -0.06357670221493028\n",
      "Class Performance_And_Entertainment: Recall Difference = -0.040322580645161366\n",
      "Class Family: Recall Difference = -0.11428571428571421\n",
      "Early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpcklEQVR4nO3deXhTZdoG8PskTdItTfeN7uxQqMhadgQRRhTEBZURdFxGKTMyo34zfPO5ziiOo86iDq4jKiKIirswyKrsW1kUCpSlLXQvTdekaXK+P9KTttAlbZOcLPfvunJJk7M8DZE+fd/nfV5BFEURRERERF5CIXcARERERI7E5IaIiIi8CpMbIiIi8ipMboiIiMirMLkhIiIir8LkhoiIiLwKkxsiIiLyKkxuiIiIyKswuSEiIiKvwuSGiLrs3LlzEAQBK1askDsUIqIrMLkh8nI33ngjAgMDUV1d3e4x8+fPh1qtRnl5uUPvvXXrVgiCgE8++cSh13WW3Nxc/PrXv0ZaWhr8/f0REhKCcePG4Z///Cfq6+vlDo+I7MTkhsjLzZ8/H/X19Vi3bl2br9fV1eGLL77AjBkzEBER4eLo3Mc333yDIUOG4OOPP8YNN9yAV155BcuWLUNSUhIee+wxPPzww3KHSER28pM7ACJyrhtvvBFarRarVq3CggULrnj9iy++QG1tLebPny9DdO7h7NmzuP3225GcnIzNmzcjLi7O9lpWVhZOnz6Nb775xiH3qq2tRVBQkEOuRURt48gNkZcLCAjA3LlzsWnTJpSUlFzx+qpVq6DVanHjjTeioqICjz76KIYMGYLg4GCEhIRg5syZOHz4sFNjPHPmDG699VaEh4cjMDAQY8aMaTOZeOWVVzB48GAEBgYiLCwMI0aMwKpVq2yvV1dXY8mSJUhJSYFGo0F0dDSuvfZaHDx4sMP7v/DCC6ipqcE777zTKrGR9OnTxzZy01G9kSAIeOqpp2xfP/XUUxAEAT///DPuvPNOhIWFYfz48XjxxRchCALOnz9/xTWWLl0KtVqNS5cu2Z7bs2cPZsyYAZ1Oh8DAQEyaNAk7duzo8Hsi8mVMboh8wPz589HY2IiPP/641fMVFRXYsGEDbrrpJgQEBODMmTP4/PPPMWvWLLz88st47LHHcPToUUyaNAkXL150SmzFxcUYO3YsNmzYgEWLFuHZZ5+FwWDAjTfe2Goq7a233sJvf/tbDBo0CP/4xz/w9NNP46qrrsKePXtsxzz44INYvnw5br75Zvz73//Go48+ioCAABw/frzDGL766iukpaVh7NixTvkeb731VtTV1eG5557D/fffj9tuuw2CIFzx9wEAH3/8MaZPn46wsDAAwObNmzFx4kRUVVXhySefxHPPPYfKykpcc8012Lt3r1PiJfJ4IhF5vcbGRjEuLk7MzMxs9fzrr78uAhA3bNggiqIoGgwG0Ww2tzrm7NmzokajEZ955plWzwEQ33333Q7vu2XLFhGAuHbt2naPWbJkiQhA/OGHH2zPVVdXi6mpqWJKSootntmzZ4uDBw/u8H46nU7Mysrq8JjL6fV6EYA4e/Zsu47v6HsHID755JO2r5988kkRgHjHHXdccWxmZqY4fPjwVs/t3btXBCC+//77oiiKosViEfv27Sted911osVisR1XV1cnpqamitdee61dMRP5Go7cEPkApVKJ22+/Hbt27cK5c+dsz69atQoxMTGYOnUqAECj0UChsP6zYDabUV5ejuDgYPTv37/TqZ3u+vbbbzFq1CiMHz/e9lxwcDAeeOABnDt3Dj///DMAIDQ0FAUFBdi3b1+71woNDcWePXu6NMpUVVUFANBqtd38Djr34IMPXvHcvHnzcODAAeTm5tqeW7NmDTQaDWbPng0AyM7OxqlTp3DnnXeivLwcZWVlKCsrQ21tLaZOnYrt27fDYrE4LW4iT8XkhshHSAXDUo1KQUEBfvjhB9x+++1QKpUAAIvFgr///e/o27cvNBoNIiMjERUVhSNHjkCv1zslrvPnz6N///5XPD9w4EDb6wDwhz/8AcHBwRg1ahT69u2LrKysK+pOXnjhBRw7dgyJiYkYNWoUnnrqKZw5c6bD+4eEhABAh0vleyo1NfWK52699VYoFAqsWbMGACCKItauXYuZM2faYjp16hQAYOHChYiKimr1ePvtt2E0Gp3290LkyZjcEPmI4cOHY8CAAfjoo48AAB999BFEUWy1Suq5557D73//e0ycOBErV67Ehg0bsHHjRgwePFj2EYKBAwciJycHq1evxvjx4/Hpp59i/PjxePLJJ23H3HbbbThz5gxeeeUVxMfH429/+xsGDx6M7777rt3rhoSEID4+HseOHbMrDkEQ2nzebDa3e05AQMAVz8XHx2PChAm2upvdu3cjLy8P8+bNsx0jved/+9vfsHHjxjYfwcHBdsVN5Eu4FJzIh8yfPx+PP/44jhw5glWrVqFv374YOXKk7fVPPvkEU6ZMwTvvvNPqvMrKSkRGRjolpuTkZOTk5Fzx/IkTJ2yvS4KCgjBv3jzMmzcPDQ0NmDt3Lp599lksXboU/v7+AIC4uDgsWrQIixYtQklJCa6++mo8++yzmDlzZrsxzJo1C2+++SZ27dqFzMzMDuOVCn0rKytbPd/WyqfOzJs3D4sWLUJOTg7WrFmDwMBA3HDDDbbXe/fuDcCagE2bNq3L1yfyVRy5IfIh0ijNE088gezs7Ct62yiVSoii2Oq5tWvX4sKFC06L6Re/+AX27t2LXbt22Z6rra3Fm2++iZSUFAwaNAgAruierFarMWjQIIiiCJPJBLPZfMUUTXR0NOLj42E0GjuM4X/+538QFBSE++67D8XFxVe8npubi3/+858ArIlGZGQktm/f3uqYf//73/Z/001uvvlmKJVKfPTRR1i7di1mzZrVqgfO8OHD0bt3b7z44ouoqam54vzS0tIu35PIF3DkhsiHpKamYuzYsfjiiy8A4IrkZtasWXjmmWdwzz33YOzYsTh69Cg+/PBDpKWl9ei+n376qW0kpqWFCxfij3/8Iz766CPMnDkTv/3tbxEeHo733nsPZ8+exaeffmorcJ4+fTpiY2Mxbtw4xMTE4Pjx43j11Vdx/fXXQ6vVorKyEgkJCbjllluQkZGB4OBgfP/999i3bx9eeumlDuPr3bs3Vq1ahXnz5mHgwIFYsGAB0tPT0dDQgJ07d2Lt2rW4++67bcffd999eP7553HfffdhxIgR2L59O06ePNnl9yU6OhpTpkzByy+/jOrq6lZTUgCgUCjw9ttvY+bMmRg8eDDuuece9OrVCxcuXMCWLVsQEhKCr776qsv3JfJ68i7WIiJXe+2110QA4qhRo654zWAwiI888ogYFxcnBgQEiOPGjRN37dolTpo0SZw0aZLtuK4uBW/vIS3/zs3NFW+55RYxNDRU9Pf3F0eNGiV+/fXXra71xhtviBMnThQjIiJEjUYj9u7dW3zsscdEvV4viqIoGo1G8bHHHhMzMjJErVYrBgUFiRkZGeK///1vu9+bkydPivfff7+YkpIiqtVqUavViuPGjRNfeeUV0WAw2I6rq6sT7733XlGn04larVa87bbbxJKSknaXgpeWlrZ7z7feeksEIGq1WrG+vr7NYw4dOiTOnTvX9r0nJyeLt912m7hp0ya7vzciXyKI4mVj0EREREQejDU3RERE5FWY3BAREZFXYXJDREREXoXJDREREXkVJjdERETkVZjcEBERkVfxuSZ+FosFFy9ehFarbXePGCIiInIvoiiiuroa8fHxtuae7fG55ObixYtITEyUOwwiIiLqhvz8fCQkJHR4jM8lN1qtFoD1zQkJCZE5GiIiIrJHVVUVEhMTbT/HO+JzyY00FRUSEsLkhoiIyMPYU1LCgmIiIiLyKkxuiIiIyKswuSEiIiKvwuSGiIiIvAqTGyIiIvIqTG6IiIjIqzC5ISIiIq/C5IaIiIi8CpMbIiIi8ipMboiIiMirMLkhIiIir8LkhoiIiLwKkxsvYLGIMFtEucMgIiJyC0xuPFyj2YJf/OsHzPjHdjQ0WuQOh4iISHZMbjzciaJqnCiqxqmSGhwpqJQ7HCIiItkxufFw+85V2P6843S5jJEQERG5ByY3DiSKIoqrDC695/5zl2x/3plb5tJ7ExERuSMmNw5yvLAKw//yPW56bQdE0TXFvaIothq5OZRXifoGs0vuTURE5K6Y3DhIckQgqg0mXNQbkF9R75J7FlyqR0m1ESqlgGitBg1mC/afr+j8RCIiIi/G5MZBAtV+yEgIBQDsPuOa2hdp1Ca9lw4T+kYBAHbmsu6GiIh8m6zJzbJlyzBy5EhotVpER0djzpw5yMnJsfv81atXQxAEzJkzx3lBdsGYtAgArkxurPU2I1PCMa6P9d5MboiIyNfJmtxs27YNWVlZ2L17NzZu3AiTyYTp06ejtra203PPnTuHRx99FBMmTHBBpPZpmdy4ou5mf9PIzYjkMGT2tt77aEEl9PUmp9+biIjIXfnJefP169e3+nrFihWIjo7GgQMHMHHixHbPM5vNmD9/Pp5++mn88MMPqKysdHKk9rk6ORR+CsFWd5MUEei0e1XWNeBUSQ0AYHhyGCKCNUiLDMKZslrsPVuBawfFOO3eRERE7sytam70ej0AIDw8vMPjnnnmGURHR+Pee+/t9JpGoxFVVVWtHs4SqPZDRmIoAGD3WedODx04b52SSosKQkSwBgAw1jY1xSXhRETku9wmubFYLFiyZAnGjRuH9PT0do/78ccf8c477+Ctt96y67rLli2DTqezPRITEx0VcpvGpFkTM2fX3djqbZKbE8GxvSMBADvZzI+IiHyY2yQ3WVlZOHbsGFavXt3uMdXV1bjrrrvw1ltvITIy0q7rLl26FHq93vbIz893VMhtkupu9pypcGrdja3eJiXsinvnFFejtNrotHsTERG5M1lrbiSLFy/G119/je3btyMhIaHd43Jzc3Hu3DnccMMNtucsFutmkX5+fsjJyUHv3r1bnaPRaKDRaJwTeBuGJ4fBTyHgQmU9Ci7VIzHc8XU3BpMZRwqsU3gjU5pHbsKD1BgUF4KfC6uw+0w5bsiId/i9iYiI3J2sIzeiKGLx4sVYt24dNm/ejNTU1A6PHzBgAI4ePYrs7Gzb48Ybb8SUKVOQnZ3t9Ckne7Ssu9nlpKmpYxf0aDBbEBmsRvJlRctje7PuhoiIfJusyU1WVhZWrlyJVatWQavVoqioCEVFRaivb+7wu2DBAixduhQA4O/vj/T09FaP0NBQaLVapKenQ61Wy/WttDI61bl1N1K9zYjkcAiC0Oq1sex3Q0REPk7W5Gb58uXQ6/WYPHky4uLibI81a9bYjsnLy0NhYaGMUXZdy7obZ2ir3kYyKjUCSoWA8+V1KLhU55T7ExERuTNZa27sKbjdunVrh6+vWLHCMcE4UMu6m/yKOofW3VgsIg7kNXcmvlywxg8ZCToczKvEztxy3DbCeb12iIiI3JHbrJbyJkEaPwxN0AFw/NRUbmkNKutMCFApMSg+pM1jpCXhuzg1RUREPojJjZM0b8Xg2Kkpqd7mqsRQqJRt//W1LCp2xTYQRERE7oTJjZM4axNNqd5mZBv1NpKrk8Og9lOguMqI3NLO9+kiIiLyJkxunOTyuhtH2XdeKiZuf4sKf5USI5Ktyc8uLgknIiIfw+TGSYI0fhji4Lqb4irrhpwKARiWFNrhsc1TU6y7ISIi38LkxolsS8LPOqbuZn9Tvc2A2BBo/VUdHju2T1NR8ZlyWCysuyEiIt/B5MaJHF13s8+OehvJ0F46BGv8UFlnws+FztsJnYiIyN0wuXGiEclhUCoEFFxyTN3NfjvqbSR+SgVGNXVK5pJwIiLyJUxunKhlv5ueTk3VGBvx80XrCExbnYnbItXd7GBRMRER+RAmN07mqKmp7LxKWESgV2gA4nQBdp0jNfPbe7YCJrOlR/cnIiLyFExunMxRyU1X6m0kA2K1CA9So67BjCMFlT26PxERkadgcuNkw1vU3fRkI8uu1NtIFAoBmU3J1Y7TrLshIiLfwOTGyYI1fhjSq6nupptbMTSaLTiUVwmg7c0yO5LZYisGIiIiX8DkxgV6OjV1vLAadQ1mhPj7oW90cJfOlYqKD56vhMFk7tb9iYiIPAmTGxcYk2Ydbdl9tnvJjVRvMzw5DAqF0KVzUyODEKfzR4PZYmsCSERE5M2Y3LjAiJRwKBUC8iu6V3fTnXobiSAInJoiIiKfwuTGBXpSdyOKom3Epav1NhJpSTj3mSIiIl/A5MZFRjdNTe3p4tRUfkU9SqqNUCkFW0PArpLqbo4UVKLKYOrWNYiIiDwFkxsXaS4q7trIjVRvM6SXDv4qZbfuHR8agNTIIFhEYG83V2wRERF5CiY3LiLtM5VXUYcLlfV2nyfV23R3SkrSXHfDqSkiIvJuTG5cROuvQrqt7sb+BEOqt+lOMXFLY1lUDAC4VNuA0yU1codBREROxOTGhWxLwu1Mbi7VNuBU0w/i4cn2b7vQFqlT8YmiapTVGHt0LU9294p9uO4f23vULZqIiNwbkxsX6mrdzYHz1lGb3lFBCA9S9+jeEcEaDIjVNt3fN6emDCYzjhZUwmwRcbywWu5wiIjISZjcuFDLupuLdtTd7HNQvY1EWhLuq/tMnS+vg0W0/jmvgiM3RETeismNC2n9VUiPDwFg35LwAw6qt5GM62MdOdrlo3U3uaXNtTb5TG6IiLwWkxsXs01N5XY8NWUwmXGkQA/AOuLjCKNSrZ2Sz5V3bcWWt2hZSMyaGyIi78XkxsVsyU0nIzdHL+jRYLYgMliD5IhAh9xb66+ydUreedr3Rm9ajtxwWoqIyHsxuXGxESlhUAjW+o+O6m6k5n0jU8IgCF3bLLMjzVNTvld303paqh6iKMoYDREROQuTGxdrOXrSUd2No+ttJC33mfKlH+4Wi4jcklrb1/UmM8pqGmSMiIiInIXJjQykqan2NtG0WETsb1oG7qh6G8nw5DCo/RQoqjLgTFlt5yd4icIqA+pNZvgpBERrNQCAfNbdEBF5JSY3Mmjud9P2yM3p0hro600IUCkxqGl1laP4q5QYnmRNmHxpK4bcpmLilMggpEQGAeCKKSIib8XkRgZS3c258joU6q+su5HqbYYlhUKldPxfkbQVgy8tCZdWSvWJCkZimLVAm8kNEZF3YnIjg9b7TF05NeWsehvJ2BZFxRaLb9TdSMXEvaODkBQuJTe+txyeiMgXMLmRSUdTU82diR1bbyMZmhCKILUSl+pMOF5U5ZR7uBtbchMVjMTwAACsuSEi8lZMbmTS3iaaRXoD8ivqoRCAYUnOSW5USgVGpVrv7ytLwk83rZTqEx1sG7lhrxsiIu/E5EYmI1LCbXU3RXqD7fn9TaM2A+NCEKzxc9r9m/eZ8v66G32dybYTelpUMBKbkptCvQGNZoucoRERkRMwuZFJSMu6mxb9bvY31ds4arPM9mQ2FRXvPVsBk5f/gM8ts05JxYb4I1jjh6hgDdR+CpgtIgpbJJZEROQdmNzIaHTqlVNT0sjNCCfV20gGxYUgNFCF2obmPay8lW2lVHQwAEChEJAYZq274dQUEZH3YXIjo+aiYmtCU2NsxM8XrQW+I5KdO3KjUAjIbLq/t+8z1VxMHGR7LjGcy8GJiLwVkxsZSXU3Z8tqUaQ34FDeJVhEICEsALE6f6ffX+p34+3N/KRtF3o3jdwAaO51wxVTREReh8mNjHQBKgyOb667cVW9jWRsH2tR8YG8S6hvMLvknnKQRm76RDUnN80rptjrhojI2zC5kVnLJeGuqreRpEUGISEsAA2NFmzNKXHJPV3N2Gi21dW0GrmRet1wWoqIyOswuZGZVHez43Q5DuVVAnB+vY1EEAT8YkgcAODro4Uuuaer5ZXXwWwREazxs22YCQAJTdNSBZyWIiLyOkxuZCbV3eRV1KGuwYwQfz/0bTHC4GzXNyU3m4+XeOXUlLRSqnd0MARBsD2fFGFNbspqGlBrbJQlNiIicg4mNzLTBaha7fw9IiUcCoXQwRmONTRBh4SwANSbzNjihVNTba2UAqx9hnQBKgBAwSXW3RAReRMmN25gTGqE7c+uqreRCIJgG735xgunpnJLm1ZKRV05GibV3bDXDRGRd2Fy4wakuhvAdfU2Lf3Ci6emLm/g11ISe90QEXklJjduYGRqOLT+fggPUmNogs7l9/fWqSlRFFvtBn459rohIvJOTG7cgC5AhS+yxmHdorHwVyldfn9vnZoqqjKgrsEMP4WA5KYC4pYSOHJDROSVZE1uli1bhpEjR0Kr1SI6Ohpz5sxBTk5Oh+d89tlnGDFiBEJDQxEUFISrrroKH3zwgYsidp60qGAkRwR1fqCTXD/U+6ampCmp5IhAqJRXftSbp6VYUExE5E1kTW62bduGrKws7N69Gxs3boTJZML06dNRW1vb7jnh4eH405/+hF27duHIkSO45557cM8992DDhg0ujNz7DOnlfVNTuSXtT0kBsG2emX+pDqIouiwuIiJyLj85b75+/fpWX69YsQLR0dE4cOAAJk6c2OY5kydPbvX1ww8/jPfeew8//vgjrrvuOmeF6vUEQcD1Q+PwxrYz+OZIoa3I2JPZVkq10zeoV1gABAGoazCjvLYBkcGaNo8jIiLP4lY1N3q9HoB1dMYeoihi06ZNyMnJaTcZMhqNqKqqavWgttka+p3wjqkp20qpdkZuNH5KxIZYNyhl3Q0Rkfdwm+TGYrFgyZIlGDduHNLT0zs8Vq/XIzg4GGq1Gtdffz1eeeUVXHvttW0eu2zZMuh0OtsjMTHRGeF7BW+bmrKtlOqg43PziinW3RAReQu3SW6ysrJw7NgxrF69utNjtVotsrOzsW/fPjz77LP4/e9/j61bt7Z57NKlS6HX622P/Px8B0fuPaSpKQD45ohnr5qqMphQUm0EAKRFtV+oncgVU0REXkfWmhvJ4sWL8fXXX2P79u1ISEjo9HiFQoE+ffoAAK666iocP34cy5Ytu6IeBwA0Gg00GtZS2Ov6Ida6m80nSlDX0IhAtVt8RLpMKiaOCdEgxF/V7nHcHZyIyPvIOnIjiiIWL16MdevWYfPmzUhNTe3WdSwWC4xGo4Oj801DeumQGN40NXWiVO5wuq2jbRdaYiM/IiLvI2tyk5WVhZUrV2LVqlXQarUoKipCUVER6uub6x8WLFiApUuX2r5etmwZNm7ciDNnzuD48eN46aWX8MEHH+CXv/ylHN+C1xEEwbZS6lsPbuh3upNl4BJpd3DuL0VE5D1knXNYvnw5gCuXd7/77ru4++67AQB5eXlQKJpzsNraWixatAgFBQUICAjAgAEDsHLlSsybN89VYXu9WUPi8ca2M9h0othjp6akYuK29pRqSRq5uVhpQKPZAr82mv0REZFnkfWnlj2N0y4vFP7LX/6Cv/zlL06KiAAgvVcIEsMDkF9Rjy0nSm1Fxp6koz2lWorWaqD2U6Ch0YJCvcFWYExERJ6Lv6bSFax7TcUDAL45elHmaLquodGC8+XWaabe0R1vaaFQCEgIY1ExEZE3YXJDbWrZ0K+uoVHmaLomr6IWZouIIHVzk76OsKiYiMi7MLmhNqX3CkFSeCAMJovHrZo6XdK87YIgCJ0eLy0HZ1ExEZF3YHJDbWq5asrTpqbsrbeRcHdwIiLvwuSG2uWpU1NSA7/OVkpJOC1FRORdmNxQu1pOTW0+4Tl7TTWP3HRcTCzhFgxERN6FyQ21yxMb+omiaHd3YomU3JTVNHjUCBUREbWNyQ11aNZQz5qaKq4yosbYCKVCQHKEfSM3ugAVQvytLZ8KuDs4EZHHY3JDHRoc71lTU9KUVHJ4INR+9n+8pdGbvHJOTREReTomN9QhQRBsHYo9YWpK2lMqzc4pKYltxRSLiomIPB6TG+qUJ62asndPqcslcjk4EZHXYHJDnRocH4LkCM+YmurqSimJbVqKK6aIiDwekxvqVKuGfkfce2pKmpbq3dWRm6b9pQo4LUVE5PGY3JBdpKmpLTklqDW659RUtcGE4iojAPuXgUta9rqxZ7d6IiJyX0xuyC6eMDV1pqm/TZRWA12Aqkvn9goNgCAAtQ1mVNQ2OCM8IiJyESY3ZBdBEGyjN+66aso2JdXFehsA8FcpEaO17iCez143REQejckN2e0XLVZNuePUVHdXSkm4OzgRkXdgckN2k6amjI3uOTXV1d3AL8c9poiIvAOTG7Kbu09NNU9LdTO5adodnCumiIg8G5Mb6hJ3nZoymS0437R1QvenpdjrhojIGzC5oS4ZHB+CFDecmsqrqEOjRUSgWonYEP9uXSOJXYqJiLwCkxvqEndt6Ne8p1QQFAqhW9eQCoovVtaj0WxxWGxERORaTG6oy6SNNN2poZ9tpVQ3620AIEbrD7VSgUaLiEK9wVGhERGRizG5oS4bFNc8NbXJTaamckusDfy6W0wMAAqFgISmbRi4OzgRkedickNdJgiCbfTmWzeZmjpd2r09pS6X0FR3U8C6GyIij8XkhrrFtmoqpwQf7c2D2SLffkyiKOJMSc8a+EmkDTS5YoqIyHMxuaFuGRQXgvF9ItHQaMHSz47ipn/vQHZ+pSyxlFYbUW1shEIAkiMCe3Qt24opB09LlVQZcOB8hUOvSUREbWNyQ90iCALevWckHp81CFqNH44U6DHntR34wydHUF5jdGks0kqppPBAaPyUPbqWs7oU3//BAdy8fBd+uqh36HWJiOhKTG6o21RKBe4dn4pNj07CzVcnAADW7M/HlBe34r2d51y2nLqne0q1lGRr5Oe4mpu88jocbhrV+ulClcOuS0REbWNyQz0WrfXHS7dl4JMHMzEoLgRVhkY8+eVPuOHVHdh3zvlTMbmlPV8pJZG2YCirMaK+wdzj6wHA98eLbX/mKiwiIudjckMOMyIlHF/9Zjz+PCcdugAVjhdW4dbXd+F3a7JRUuW8vjE93VOqJV2gClp/PwCO22OqZXLDQmUiIudjckMOpVQIuGtMMrY8Ohl3jEqCIADrDl3ANS9tw1vbz8DkhKmqXActA5ckOXCPKX29CXvPNo9eMbkhInI+JjfkFOFBaiybOwSfLxqHjMRQ1Bgb8ey3xzHznz9gx+kyh92nxtho6ybcOyrIIdeUpqYcUVS87WQpGi0i/FWKpmuyfw4RkbMxuSGnykgMxbqHxuKFm4ciPEiN0yU1mP/2HmR9eBAXK3v+g/5M06hNZLAaoYHqHl8PaN5jyhFFxd//bJ2SmttUcF1WY0Rdg3tsWUFE5K2Y3JDTKRQCbhuZiC2PTMbCzGQoBOCbo4WY8Y/tPR4dsU1JOaDeRuKoXjcmswVbcqzbU9x8dS/oAlTW63L0hojIqZjckMvoAlV4enY6vv7NBAxsWlX16NrDsPSgu7GtmNhB9TZA8xYMPU289p2tQLWhERFBalyVGNZiRIh1N0REzsTkhlxuUHwI3vjlcASqldhztgIrdp7r9rUcsWHm5VrW3Ihi9xOv749bR22mDIiGUiE0jwgxuSEiciomNySLpIhALP3FQADACxtO2GpnusqRDfwk0s7gtQ1mXKozdesaoihi4/EiAMC0gTEAmrsfc+SGiMi5mNyQbH45Ognj+0TCYLLg0bWHu7z5ZqPZgnPl0siNY1ZKAYC/SomYEA2A7o+ynCqpQX5FPdR+CkzoGwnAsauwiIiofUxuSDaCIOCvtwyFVuOHg3mVeOuHM106P6+iDiaziACVEvG6AIfGJiUi3R1l2di0Smpc7wgEaaxNAZ21KScREbXG5IZk1Ss0AI/fMAgA8PJ/T+JkcbXd50rbLqRFBUGhEBwaV08TEakr8bRBMVdcM6+HtTxERNQxJjcku1uHJ2DqgGg0mC145OPDdncxduS2C5drXjHV9WXbpdVGZDdtlDl1QHNyEx8aAEEADCYLSl28czoRkS9hckOyEwQBy+YOgS5AhaMX9Fi+Ndeu85zR40aS2FRU3J36mC0nSiCKwJBeOsTq/G3Pq/0Utukz9rohInIeJjfkFqJD/PHM7MEAgH9tOoWfLuo7PccZK6UkPZmW2ihNSQ2MueI1qdcNi4qJiJyHyQ25jRsz4jFjcCwaLSIe+fgwGhrbn54SRbFFAz/HrZSSSMu2L1yq79IqLoPJjB9OlQIApg2KvuJ1R27KSUREbWNyQ25DEAT85aZ0hAepcaKoGv/adKrdY0trjKg2NEIhACkRjk9uYkL8oVYq0GgRUai3fwppx+kyGEwWxOv8MSgu5IrXe7oKi4iIOsfkhtxKZLAGz85JBwAs35aLw02FuZeTOhMnhgfCX6V0eBxKhYBeYV2vj5G6Ek8dGANBuHIFV1IEe90QETkbkxtyOzOHxOHGjHiYLSIeWXsYBpP5imNOO7GYWJLQxaJii0XEpjaWgLeUyC0YiIicTtbkZtmyZRg5ciS0Wi2io6MxZ84c5OTkdHjOW2+9hQkTJiAsLAxhYWGYNm0a9u7d66KIyVWemT0YUVoNTpfU4OWNJ694Pde2DNzxU1KSrhYVH72gR0m1EUFqJcakhbd5jDQtVVhlgLHxyqSNiIh6TtbkZtu2bcjKysLu3buxceNGmEwmTJ8+HbW1te2es3XrVtxxxx3YsmULdu3ahcTEREyfPh0XLlxwYeTkbKGBajw/dwgA4K0fzmDfuYpWrztzpZSkq6MsUuO+Sf2joPFre6osMliNAJUSoghcrDQ4JlAiImpF1uRm/fr1uPvuuzF48GBkZGRgxYoVyMvLw4EDB9o958MPP8SiRYtw1VVXYcCAAXj77bdhsViwadMmF0ZOrjB1YAxuGZ4AUQQeXXsYdQ2NttdyndjAT9LV4l9py4W2loBLBEHgiikiIidzq5obvd7a2yQ8vO0h/bbU1dXBZDK1e47RaERVVVWrB3mOJ24YhDidP86X1+Gv350AANQaG3FRbx31cGZy0zwt1XlBccGlOpwoqoZCAKb0v3IJeEtSrxsmN0REzuE2yY3FYsGSJUswbtw4pKen233eH/7wB8THx2PatGltvr5s2TLodDrbIzEx0VEhkwuE+Kvw15uHAgDe23UeO0+X4WyZddoyIkiNsCC10+4tJSGl1UbUN3RcH7OpaZXUiOTwTmOSprsKmNwQETmF2yQ3WVlZOHbsGFavXm33Oc8//zxWr16NdevWwd/fv81jli5dCr1eb3vk5+c7KmRykYn9onDn6CQAwGOfHLHt2+TMURsA0AWooG3a0bugk6Li5o0yOx61AdjIj4jI2dwiuVm8eDG+/vprbNmyBQkJCXad8+KLL+L555/Hf//7XwwdOrTd4zQaDUJCQlo9yPP87y8GIiEsABcq6/F80/SUMzoTtyQIQnNRcQfJTZXBhN1nygF0XG8jYXJDRORcsiY3oihi8eLFWLduHTZv3ozU1FS7znvhhRfw5z//GevXr8eIESOcHCW5g2CNH/52SwYAoMZoLSx29sgN0HIvqPbrbrafLIXJLCItKghpdsTEXjdERM4la3KTlZWFlStXYtWqVdBqtSgqKkJRURHq65t/kCxYsABLly61ff3Xv/4Vjz/+OP7zn/8gJSXFdk5NTY0c3wK5UGbvCNw9NsX2dW8nLgOX2LNiSqq3udaOUZuW16wyNEJfZ+phhEREdDlZk5vly5dDr9dj8uTJiIuLsz3WrFljOyYvLw+FhYWtzmloaMAtt9zS6pwXX3xRjm+BXOwPMwZgQKwWWo0fMhJCnX6/zrZLaDRbsPlE85YL9ghQKxGl1QDg1BQRkTP4yXlzUex8t+WtW7e2+vrcuXPOCYY8QoBaic+zxqHRIiJY4/yPrzTK0t5y8P3nL0Ffb0JYoApXJ4V24boBKK02Iq+iDkMSdI4IlYiImrhFQTFRV/irlC5JbICWNTd1bSbj3zc17psyIBp+Svv/d+rq1g5ERGQ/JjdEHUhoGrmpMTai8rL6GFEUbUvA7a23kXDFFBGR8zC5IeqAv0qJ6Kb6mMtHWXJLa3GuvA5qpQIT+kV16boJXDFFROQ0TG6IOpHYziiLNGozpndEl6fJkpjcEBE5DZMbok40JyKti4qleptrB3belbi9axZcqofZ0nlhPRER2Y/JDVEnEsOu3OiyvMaIA3mXANi/BLylmBB/qJUKNFpEFOo735iTiIjsx+SGqBO2jS5b1NxsPlECUQQGx4cgPjSgy9dUKgT0Cuu8+zEREXUdkxuiTrS1XYLUldievaS6cl0iIuo5WZv4EXkCKQm5UGmtjzGZLdh+qhRAz5KbpPArp7uIiKjnmNwQdSI2xB8qpQCTWURRlQEni6tR12BGTIgG6b26v8u8PftWERFR13FaiqgTSoWAXqHNnYqlVVLTBsZAEIRuX5ddiomInIPJDZEdbL1uyuua620GdX9KquU1WXNDRORYTG6I7CAlIut/KkJRlQGBaiUy0yIccs2ymgbUGht7HCMREVkxuSGyg1Qfs/mEddRmQt9I+KuUPbqmLkAFXYAKgLWZHxEROQaTGyI7SLuDS3qySqolbqBJROR4TG6I7CAlIQAgCMA1A7q+5UJH12VyQ0TkOExuiOwgTUsBwPCkMEQEaxxy3YTw5lVYRETkGExuiOwQGqiy7fzd01VSLXF3cCIix2NyQ2QHQRAwqX8UdAEqzBoa57DrclqKiMjx2KGYyE6v3D4MDWZLj1dJtSRNd+VfqoMoij1qCkhERFbdGrnJz89HQUGB7eu9e/diyZIlePPNNx0WGJG7USgEhyY2ABAfGgCFABhMFpTWGB16bSIiX9Wt5ObOO+/Eli1bAABFRUW49tprsXfvXvzpT3/CM88849AAibyZ2k+BOB2LiomIHKlbyc2xY8cwatQoAMDHH3+M9PR07Ny5Ex9++CFWrFjhyPiIvF4idwcnInKobiU3JpMJGo11Kez333+PG2+8EQAwYMAAFBYWOi46Ih/QvGKKXYqJiByhW8nN4MGD8frrr+OHH37Axo0bMWPGDADAxYsXERHRs/12iHwNV0wRETlWt5Kbv/71r3jjjTcwefJk3HHHHcjIyAAAfPnll7bpKiKyTyKTGyIih+rWUvDJkyejrKwMVVVVCAsLsz3/wAMPIDAwsIMziehyUnJT4GbJTXmNEYfyKjF1YDSXqBORR+nWyE19fT2MRqMtsTl//jz+8Y9/ICcnB9HRjtlzh8hXSNNShVUGGBvNMkdjVV5jxJx/78B97+/HpuMlcodDRNQl3UpuZs+ejffffx8AUFlZidGjR+Oll17CnDlzsHz5cocGSOTtIoLUCFQrIYrAhUvyFxUbTGbc//5+W4Fzdn6lvAEREXVRt5KbgwcPYsKECQCATz75BDExMTh//jzef/99/Otf/3JogETeThCEFp2K5U1uLBYRj6w9jIN5lbbnThZXyxcQEVE3dCu5qaurg1arBQD897//xdy5c6FQKDBmzBicP3/eoQES+QJ3KSp+aWMOvjlSCJVSwG+u6QMAOFVSI2tMRERd1a3kpk+fPvj888+Rn5+PDRs2YPr06QCAkpIShISEODRAIl/gDruDf7wvH69tyQUAPD93KO4akwwAOF9eC4PJPWqBiIjs0a3k5oknnsCjjz6KlJQUjBo1CpmZmQCsozjDhg1zaIBEvsDWpbhcnuRmx+ky/O+6owCA307ti5uHJyBKq4EuQAWLCOSWcvSGiDxHt5KbW265BXl5edi/fz82bNhge37q1Kn4+9//7rDgiHyFbeTmkuuTm1PF1Xhw5QE0WkTMvioev5vWF4C1FqhfTDAA1t0QkWfpVp8bAIiNjUVsbKxtd/CEhAQ28CPqJluX4vI6iKLosr4ypdVG3LNiH6oNjRiZEoYXbhna6t59Y7TYd+4SThZz5IaIPEe3Rm4sFgueeeYZ6HQ6JCcnIzk5GaGhofjzn/8Mi8Xi6BiJvF5C02qpamMj9PUml9xTWvJdcKkeKRGBeOOuEdD4KVsd0z/GunDgFEduiMiDdGvk5k9/+hPeeecdPP/88xg3bhwA4Mcff8RTTz0Fg8GAZ5991qFBEnm7ALUSUVoNSquNyK+oR2ig2qn3s1hE/P7jbGTnVyI0UIV37xmF8KAr79nXNi3FkRsi8hzdSm7ee+89vP3227bdwAFg6NCh6NWrFxYtWsTkhqgbksIDUVptRF5FHYYk6Jx6rxc25ODbo0VQKxV4864RSI0MavO4fk0jN/mX6lDfYEaAWtnmcURE7qRb01IVFRUYMGDAFc8PGDAAFRUVPQ6KyBe5anfwj/bm4fVt1iXfL9wyFKNSw9s9NjJYg/AgNUQROM1+N0TkIbqV3GRkZODVV1+94vlXX30VQ4cO7XFQRL4oMcy6HNyZK6Z+OFWK//v8GABgybS+mDOsV6fn9I22Tk3lsO6GiDxEt6alXnjhBVx//fX4/vvvbT1udu3ahfz8fHz77bcODZDIVyQ6uZFfTlE1Fq08CLNFxE3DeuHhqX3tOq9fjBZ7zlawqJiIPEa3Rm4mTZqEkydP4qabbkJlZSUqKysxd+5c/PTTT/jggw8cHSORT3DmtFRJtQG/WrEP1cZGjEoNx/M3D7F7uXm/WGvdDXvdEJGn6Hafm/j4+CsKhw8fPox33nkHb775Zo8DI/I10sjNhUv1MFtEKBWO6XVT32DG/e/tx4XKeqRFBuHNu4ZfseS7I/2iuWKKiDxLt0ZuiMjxYkL8oVYq0GgRUah3zO7gFouIJWsO4XCBHmGBKvzn7pFdXmYurZi6UFmPWmOjQ+IiInImJjdEbkKpEJDQVFTsqKmpf246hQ0/FVuXfC8YgZR2lnx3JCxIjchgDQDuEE5EnoHJDZEbcWRRca2xEe/8eBYAsGzuEIxMaX/Jd2dse0wVse6GiNxfl2pu5s6d2+HrlZWVPYmFyOdJu4PnV/R8WurrIxdRY2xESkQgbrJjyXdH+sVosTO3nEXFROQRupTc6HQdd03V6XRYsGBBjwIi8mWOXDG1am8+AOD2UUlQ9LA4Waq7OclpKSLyAF1Kbt59911nxUFEcFxy89NFPQ7nV0KlFHDL8IQexyVNS7HXDRF5AllrbpYtW4aRI0dCq9UiOjoac+bMQU5OTofn/PTTT7j55puRkpICQRDwj3/8wzXBErmAtDt4QQ+7FK9uGrWZPjjWVgzcE32bRm4K9QZUGVyzazkRUXfJmtxs27YNWVlZ2L17NzZu3AiTyYTp06ejtra23XPq6uqQlpaG559/HrGxsS6Mlsj5kiKsyU1ZTUO3l13XNTTi80MXAAB3jkpySFy6ABViQppWTLHfDRG5uW438XOE9evXt/p6xYoViI6OxoEDBzBx4sQ2zxk5ciRGjhwJAPjjH//o9BiJXCnEX4XQQBUq60zIv1SHAbEhXb7G10cKUW1sRHJEIDLTIhwWW78YLYqrjDhZXI3hyWEOuy4RkaO51VJwvV4PAAgP7/6S1csZjUZUVVW1ehC5s8Smqam88u5NTX20Nw8AcPvInhcSt2QrKmbdDRG5ObdJbiwWC5YsWYJx48YhPT3dYdddtmwZdDqd7ZGYmOiwaxM5g1RUnH+p68vBjxdW4VBeJfwUjikkbqm5qJjTUkTk3twmucnKysKxY8ewevVqh1536dKl0Ov1tkd+fr5Dr0/kaD1p5Le6adRm+uAYRGl7XkjcUl+O3BCRh5C15kayePFifP3119i+fTsSEhz726ZGo4FG49h/5ImcqbvLwesbzPisqZD4DgcVErfUt2kDzZJqI/R1JugCVQ6/BxGRI8g6ciOKIhYvXox169Zh8+bNSE1NlTMcIrfQ3KW4a8nN10cuotrQiMTwAIzrHenwuLT+KsTr/AEAJ0s4ekNE7kvW5CYrKwsrV67EqlWroNVqUVRUhKKiItTXN9caLFiwAEuXLrV93dDQgOzsbGRnZ6OhoQEXLlxAdnY2Tp8+Lce3QORwLUduRFG0+zxnFRK3xKkpIvIEsiY3y5cvh16vx+TJkxEXF2d7rFmzxnZMXl4eCgsLbV9fvHgRw4YNw7Bhw1BYWIgXX3wRw4YNw3333SfHt0DkcPGhAVAIgLHRgtJqo13nnCiqwsGmQuJbRzh2arel/rFNyQ030CQiNyZrzY09v5Vu3bq11dcpKSld+m2WyNOolArE6QJwobIe+ZfqEB3i3+k5UkfiaQNjEK3t/PjukupuTnLFFBG5MbdZLUVEzbpSVFzfYMZnBwsAAHeMdnwhcUtSr5tTrLkhIjfG5IbIDdmSm/LOe918e7QQVYZGJIQFYEIfxxcSt9SnaeSmrKYBFbUNTr0XEVF3MbkhckO2FVN2bKApFRLfMcp5hcSSII0fEsKssbGomIjcFZMbIjeUaOe01Mniauw/fwlKhYBbHdyRuD22qSkmN0TkppjcELmhJDu7FEujNtMGRttVeOwIUnKTw+SGiNwUkxsiNyQlN0VVBhgbzW0eYzCZ8dlB53Ukbo+0xxRXTBGRu2JyQ+SGwoPUCFQrIYrAhXY20PzuWCH09Sb0Cg3AhL5RLout5bQU2zIQkTtickPkhgRB6HQ5+Ed7rL1tbh+ZCKWTC4lb6h0VDEEALtWZUFbDFVNE5H6Y3BC5qY52Bz9dUo295yqshcQjEl0aV4BaaUu8WFRMRO6IyQ2Rm0oMa0pu2piWWtU0anPNgGjE6lxTSNxS32juMUVE7ovJDZGbSmrqdZNX3nrkxmAy49OmjsR3urCQuKX+sdai4hwWFRORG2JyQ+SmkiLarrlZf6wI+noT4nX+mNjPdYXELbHXDRG5MyY3RG7KNi1VUddqVdKqpt4280YmubSQuKWW01JcMUVE7obJDZGbSmhKbqqNjdDXmwAAp0tqsPdsBRQCcNtI13QkbktaVBAUAlBlaERJtVG2OIiI2sLkhshNBaiViNZqADRPTa1uGrW5ZkA04nQBssXmr1IiJSIIAIuKicj9MLkhcmMte920KiQeLU8hcUtS3Q07FRORu2FyQ+TGmnvd1GPDT0W4VGdCnM4fk/pFyxxZi20YijhyQ0TuxU/uAIiofS13B992sgQAMM/FHYnb01cauSlhckNE7oXJDZEbk6aldpwuQ15FnbWQ2MUdidsjTUudLq6BKIoQBPkTLiJ3pK8zIVCjhErJyRJX4TtN5MYSw5oa+TUVFE/pH434UPkKiVtKjQyCn0JAtbERhXqD3OEQuaXTJdW4+i8b8cjHh+UOxacwuSFyY1IjP8kdMnUkbovaT4GUSK6YIurI3rOXYLaI+PLwRZwtq5U7HJ/B5IbIjcVo/aFuGsqODfHH5P7ydCRuT39bp2LHrZhasy8Pmcs24Z539+KNbbk4nF+JRrPFYdcncqX8S80dxj/YdV7GSHwLa26I3JhCISAhPABnSmtx28hE+LnZnH3fmGDgKJDjoJEbg8mMF9bnoLy2AYV6A7bklAIAgjV+GJkShjFpERiTFoHB8SFu914QtSW/xfYpaw/k45Hp/RCk4Y9eZ+M7TOTmHpiQhm+PFWFhZrLcoVzB0XtMfXX4IsprGxCv88evxqdi95ly7DlbgWpDI7bklLZKdka0SHbSmeyQm8q/VA8AEASg2tCIz7MvYP5o9/t/2dswuSFyc7ePSsLtblRr05LU6+ZUSQ0sFhGKHixRF0UR7+44BwC4KzMF901Iw30T0mC2iDheWIXdZ8qx+0wF9p4tR5WhEVtzSrG1KdkJUisxMjUcY9IiML5PJNJ76Xr8vRE5woWmaambhvXCZwcv4P2d53HnqCSuLnQyJjdE1G3JEUFQKQXUNZhxobLe1penO/aercDPhVXwVylwx6jm5e5KhYD0Xjqk99LZney8dufVuH5oXI+/P6KeqGtoRFlNAwDgd9P64bujRcgprsbuMxXI7B0hc3TejeO4RNRtKqUCaZHS6E3PpqakUZubhiUgNFDd7nFSsnPfhDS8vXAEDj0xHd/8djwenzUIQxOsIzabT5T0KBYiRyhompIK8fdDYnggbrq6FwDg/V3nZIzKNzC5IaIe6Rfb8z2m8ivq8N+fiwAA94xL6dK5SoWAwfE63Ds+Fb+7th8AYP/5im7HQuQoUjGxNKK5oKlu7r8/F+NiZb1scfkCJjdE1CP9onu+x9QHu8/DIgLj+0TaipS74+qkMAgCcL68DqXVxm5fh8gRpJGbhKZmnANiQzA6NRxmi4hVe/LkDM3rseaGiHqkp3tM1TU0YvVe6z/0XR21uZwuQIX+MVqcKKrGgfMVmJHu/nU3Fyrr8ca2XNQ1mGERRYgiYBFFWJr+K4oizBbr12KL56WvA9VKLJ7SF0MSWETtbmwjN2HNtWh3j03BnrMV+GhvHn4ztQ80fkq5wvNqTG6IqEekFVOnu7li6tODF1BlaERKRCCm9O/5bufDk8Nwoqga+85d8ojk5rlvjuObo4U9usa+c5fw+aJxV3S0JnlJDfxaFtpfOygGcTp/FOoN+PZoIW4aliBXeF6NyQ0R9UhyRBDUfgoYTBbkX6pDckSQ3edaLCJW7DgLAFg4NqVHS8klI1PC8eGePOw/f6nH13K2Ir0B63+y1hr99po+CNL4QSEIUCgEKARY/ywAgiBAIQhQKpr/LL3+zo9ncfSCHve+tw+fLhqLEH+VzN8VSaRpqcTw5v3g/JQKzB+dhBf/exLv7TzP5MZJmNwQUY8oFQL6RAXj58IqnCyu6VJy88PpMuSW1iJY44dbhjvmH/nhyWEAgJ8u6FHfYEaA2n2H/VftOQ+zRcSo1HD8fnr/bl0js3cEZr+6A6dKarB41SH8Z+EINjR0E9K0VEJY6xG120cl4V+bTiM7vxKH8yuRkRgqQ3Tejf8HEFGPSVNTXd1A892mUZtbRyRA66ARh4SwAMSEaNBoEZGdX+mQazpDQ6MFq/bmAwAWZqZ0+zoxIf54e+EIBKiU2H6yFH/55riDIqSe0NebUGVoBNBcUCyJDNbY+jC9z/2mnILJDRH1mK2ouAvJTW5pDbbmlEIQrEWWjiIIAkakhAMADrjxkvDvjhWirMaImBANpg+O6dG10nvp8Pd5VwEAVuw8hw/YR0V20qhNZLAageorJ0mkZeFfHbmI8hqu7HM0JjdE1GP9Yrre6+a9necAAFMHRHdpKsseI5qmpvadc9+6G+k39jtHJUPlgGmkGemx+J8Z1qmtp776GdtPlvb4mtR9Ur1Nr7C2i7yvSgzF0AQdGhotWLM/35Wh+QQmN0TUY9K0VG5pDcwWsdPjqwwmfHKgAABwz7hUh8czItk6cnMw7xIsdsTjascu6HHg/CWolALuGJ3Y+Ql2emhSb9x8dQLMFhFZHx7E6R52jabuK5BWSl02JSURBAELmqYjP9ydh0azxVWh+QQmN0TUY4lhgfBXKdDQaMH58tpOj/94Xz7qGszoFxOMsU7YY2dgnBaBaiWqDY3d7r/jTB80jdrMTI9DtNbfYdcVBAHPzU3HqJRwVBsb8asV+1FR2+Cw65P9Lu9O3JZZQ+MQHqTGhcp6fH+cW4Y4EpMbIuoxhUJA32j7pqbMFhHvNdWE3D021Sm7I/spFRiWFArA/aamKusa8Hn2BQDNdReOpPFT4vW7hiMpPBB5FXV48IMDMDaaHX4f6li+tAy8nWkpAPBXKXH7SOvIHfebciwmN0TkEH2bpqZOdVJUvOl4MfIr6hEaqMJNw3o5LR5paurAOfcqKl67vwDGRgsGxYXYlq07WniQGu8sHAGtxg97z1Xgfz87BlF0v+k5byZNS12+Uupy88ckQyEAO3PLO/1/h+zH5IaIHMJWVFzS8ciNtPv37SOTnNqDZkSKNXFwp2Z+ZouID3Zbp6QWjk12yqiVpG+MFq/OvxpKhYBPDxbg9W1nnHYvak0UReRXSA38Ou4a3Ss0ANcOsq6W47Jwx2FyQ0QOYet108EGmscLq7DrTDmUCsEpUzItDUsKg0Kwrlop0hucei97bTtZgryKOugCVLgxw3mjVpJJ/aLw5A2DAAAvbDiB9ceKnH5PAsprG1BvMkMQgPjQzmuqpD5Hnx4sQJXB5OTofAOTGyJyCKnm5kxZDUztrPxY0TRqM2NwLOJDOx6u76lgjR8GxoUAAPa7Sb8b6Tfz20YkuKxz8oLMFCzMTIYoAr9bk41jF/Quua8vk4qJY0P87doYM7N3BPpEB6OuwYzPmlYRUs8wuSEih+gVGoBAtRIms9jmiqmK2uZC2p7u/m0vqd/NfjcoKj5XVmtrWvjLMc4dtbrc47MGYWK/KNSbzLjvvf0ornKPkSxvJfW46azeRiIIAhY2jWS+v+u8w9oXiE27yvsiJjdE5BAKhdCiU/GVdTcf7c2DsdGCIb10TiukvZzUqdgdRm5WNtXaTO4X5fCmhZ3xUyrw6p3D0Dc6GEVVBtz33n7UN3AFlbPYdgPvYKXU5W66OgHBGj+cKavFjtyyHt1fFEWs3puH4X/5Hn/49EiPruWpmNwQkcP0i257jymT2WLr7XLPuBSnFtK2JBUV/3yxCjXGRpfcsy11DY34uKkL7QIHbjXRFSH+KryzcCTCg9Q4ekGPR9Zmu2WDQ28gFRMndFJM3FLLzWPf29n9wuKyGiPuf/8A/vjZUVTUNuDj/QVd3vPNGzC5ISKHkVZMnbps5Oa7Y0UoqjK02jDQFeJ0AegVGgCLCGTnVbrsvpf7IvsiqgyNSI4IxKS+UbLFkRQRiDfuGg61UoFvjxbh5Y0nZYvFm3XWnbg9dzVNTW06UWyr2+mK738uxnV/347vjxdDrVQgLdI6QvifH892+VqejskNETmM1Osm57LfFKXdv385JsmuAktHal4SLs/UlCiKtkLiu8YkQ6FwzahVe0amhGPZ3CEAgFe3nMaafXmyxuONmmtu7B+5AYDeUcGY0DcSogis3GP/6E2tsRFLPzuC+97fj/LaBvSP0eKLxePw11uGAgA+O3TB5zbnlDW5WbZsGUaOHAmtVovo6GjMmTMHOTk5nZ63du1aDBgwAP7+/hgyZAi+/fZbF0RLRJ2RRm7OldWiodG6Yio7vxKH8iqhViowf7RrC2kB+YuK95+/hOOFVfBXKXDrcMftI9UTNw9PwKLJvQEAf/zsKD7ex40bHcViEXFB6k4c3vUVgdKy8DX78mEwdV4XdeD8JfziXz/go735EATg/gmp+GLxOAyMC8GI5DDb5pyr9vhWEitrcrNt2zZkZWVh9+7d2LhxI0wmE6ZPn47a2vb3ptm5cyfuuOMO3HvvvTh06BDmzJmDOXPm4NixYy6MnIjaEqfzh1bjh0aLiLNl1v+PpVGbWRlxiNJqXB7T8KZOxYfyLsmyOaG0+/mcq3pBF6hy+f3b89h1/W1LxP/n0yP4aK9v/fBzluJqAxrMFvgpBMTpup7cTBkQjYSwAFTWmfBl9sV2jzOZLXjpvzm49fWdOF9eh3idPz68bzT+dP0g+Kuso6OCIODe8daNad/ffd6ntuGQNblZv3497r77bgwePBgZGRlYsWIF8vLycODAgXbP+ec//4kZM2bgsccew8CBA/HnP/8ZV199NV599VUXRk5EbREEwTY1dbK4GsVVBnxzpBAA8Csn7P5tj/6xWmg1fqhtMONEBw0GnaGkymBrnHeXk5sWdpUgCHjqxsG2ZflLPztqW9FF3ScVE8eHBkDZjSlIpULAXU2tAlbsPNfmUu7TJTWY+++deGXzaVhE4KZhvfDdkokY2zvyimN/MSQOMSEalFYb8fXhwi7H46ncquZGr7c2lwoPD2/3mF27dmHatGmtnrvuuuuwa9cup8ZGRPZpLiquxoe7z6PRImJkShjSe+lkiUepEDDMNjXl2rqbVXvzbN//4Hh5vv+OCIKAJ2YNwn1Nv93/3+fHuIFjD9m7p1RHbhuRCI2fAj8XVuFgXvN0qiiKeG/nOVz/rx9w9IIeugAVXr1zGP4+7yroAtoeFVQpFVjQNNX1zo9nfabvjdskNxaLBUuWLMG4ceOQnp7e7nFFRUWIiYlp9VxMTAyKitpuK240GlFVVdXqQUTOI/W6OXpBjw+b5vnvkWnURjIy2fX7TJnMzXUOdzX9cHFHgiDgT9cPxK8npgEAnvjiJ9tUInWdbU+pLhYTtxQWpMbsq+IBNC8LL64yYOG7+/Dklz/B2GjBhL6R2LBkImYNje/0evNHJ8FfZU2Wdp+Rv+eTK7hNcpOVlYVjx45h9erVDr3usmXLoNPpbI/ERPco6CPyVtIeU1tySlFe24B4nT+mD4rp5CznGp7SXFTsqt9cN/xUhJJqI6K0GswYHOuSe3aXIAj448wBeKipyPjpr37G2z9wo83usDXw60YxcUvSaMu3Rwuxcvd5XPeP7dh+shQaPwWeumEQ3rtnFGJ1ne9bBQChgWrcfLW1h85/fCRxdYvkZvHixfj666+xZcsWJCQkdHhsbGwsiouLWz1XXFyM2Ni2//FYunQp9Hq97ZGfz1UBRM4kTUtJ7spMgZ9S3n9qrkoMhVIhoKjKgAuV9S655/tNv3HfOSoJaj+3+Ke2Q4Ig4H+u64/FU/oAAP7yzXG8uT1X5qg8j9SfpqvLwC+X3tTJu9Ei4v8+P4bKOhPSe4Xgm9+Ox93jUrvcUuBXTVOP3x8vxrmy9hfteAtZ/48TRRGLFy/GunXrsHnzZqSmdj50nZmZiU2bNrV6buPGjcjMzGzzeI1Gg5CQkFYPInKeaK3GNv/vr1LgjlHyj5YGqv2QHm/9f/+AC6amjhdWYe+5CvgpBNw5Osnp93MUQRDwyPR+eHhqXwDAc9+ewPKtTHC6oqAHy8Avd3dTN2uFACye0gefPTQOfaK1HZ/Ujt5RwZjSPwqiaC1U9nayJjdZWVlYuXIlVq1aBa1Wi6KiIhQVFaG+vvk3qwULFmDp0qW2rx9++GGsX78eL730Ek6cOIGnnnoK+/fvx+LFi+X4FojoMoIg2KambhqWgNBAtcwRWUlLwve5oKhYatp3XXosYkLsmzpwF4Ig4HfX9sPvpvUDAPx1/Qm8tuW0zFF5BpPZgkJ9z2tuJLOGxuHVO4fhy8Xj8eh1/Xs8AiiN3ny8Px/6elOP43NnsiY3y5cvh16vx+TJkxEXF2d7rFmzxnZMXl4eCgubl6+NHTsWq1atwptvvomMjAx88skn+PzzzzssQiYi11o0pQ+mDYyxjQC4gxEprmnmp6834fND1t3PF7pxIXFnHp7WF49OtyY4f9uQg39tOiVzRO6vsNIAiwho/BQO6ekkCAJmDY132ErD8X0i0T9Gi7oGs9d3pvaT8+b2FPZt3br1iuduvfVW3HrrrU6IiIgcYUr/aEzpHy13GK1InYpziqtRZTAhxN85DfU+OVCAepMZA2K1GJnimt3PnWXxNX2hUAh4YX0OXt54EhZRxJKmER26krQMvFdYgMs2h+0KQRDwq/Ep+MOnR/HezvP41bhU2evhnMU7vysiostEh/gjKTwQoggcdFLdjcUi4oOmPjELMl23+7kzLZrcB0tnDgAA/OP7U3j5vzk+0yulq2wrpRwwJeUss6/qhYggNS5U1mPDT8Wdn+ChmNwQkc+QpqacVVS8/VQpzpXXQevvhznDOu8/4il+Pak3/u/6gQCAf20+jReZ4LTJ1uPGAcXEzuKvUmJ+Uwfkd3703uX+TG6IyGeMaCoqdlbdzQdNhcS3Dk9EoFrWWX+Hu29CGh6fNQgA8NqWXDy//gQTnMt4wsgNAPxyTBLUSgUO5lXiUJ48G8o6G5MbIvIZ0sjNofxLMDl4E8288jpszikB4H77SDnKveNT8fSNgwEAb2w7g7d/8I2GcPaSloH3tMeNs0Vr/XFDhnVk8Z0fvfPvkMkNEfmMPlHB0AWoYDBZ8PNFx27FsnLPeYgiMKlfFFIjgxx6bXeycGyKbYrqlc2nUGXw7iXFXSE18HPnaSmJtFv4d8eKXNbY0pWY3BCRz1AoBAxvWjXlyH439Q1mrNln7X6+wEtHbVq6Z1wq+kQHo8rQiPd2nJM7HLdgMJlRUm0E4P7TUgAwKD4EmWkRMFtEr9wslckNEfkUZxQVf5F9Afp6ExLDAzDZzZbAO4NSIeA311i3aXj7x7Oo5uiNbUoqWOOH0EDntBlwNGn05qM9eag1NsocjWMxuSEin2IrKj7vmE00qwwmvLTxJABr0z5lF/f88VSzhsajd1QQ9PUmW0dmXyb1uElw0x43bblmQDRSIgJRZWjEpwcL5A7HoZjcEJFPGZqgg0opoLTaiLymGomeeGlDDkqrjUiLDPLaQuK2WEdvrB2o3/rhDGq87Df/rsr3kGLilhQKAfeMs47evLvjHCwW71n9xuSGiHyKv0qJIU3t7Hu6JPxogR4f7LaOWvx5Tjo0fsoex+dJbsiIR1pkECrrTF5Zt9EVBR5UTNzSLcMTEOLvh7Nltdh8okTucByGyQ0R+ZwRKc1TU91ltoj40+dHYRGB2VfFY1yfSEeF5zGUCgGLm2pv3tp+xuvqNrrCU3rcXC5I44c7Rll3rv/PDu9ZFs7khoh8jrRian8PVkx9uOc8jhToofX3w5+alkb7ohsz4pESEYhLdSbbKJYvau5x41kjNwCwYKy1VmxnbrnDWyTIhckNEfkcaRPNUyU1qKxr6PL5JdUG/G19DgDgsev6I1rr79D4PImfUoHFUu3N9jOoa/DN0ZvmHjeeNXIDAL1CAzAjPRaA94zeMLkhIp8TEaxBWlOjve4sCX/2m+OoNjZiaIIO80f7ThFxe+ZcFY/kiECU1zZgpQ+O3tQYG3Gpzroc3hNHboDmZeFfZl9ESbVB5mh6jskNEfkkqd9NV+tufjxVhi+yL0IhAM/OGeIzS7874qdUIGuKtfbmze1nUN9gljki15JGbUIDVdD6e0aPm8tdnRSGYUmhaDBbsHJ3ntzh9BiTGyLySVK/mwNdWDFlbDTjiS+OAQDuGpOMIQk6p8TmiW4a1guJ4QEoq2nAh3t8a/RGqrfxtGLiy0mjNx/uPg+DybMTVCY3ROSThjeN3GQXVMLYaN8/5G9sO4MzZbWI0mrwyHX9nRmex1EpFciabB29eX3bGY//4dgVnrSnVEdmDI5FvM4f5bUN+DL7otzh9AiTGyLySWmRQQgPUqOh0YJjFzpfIXKurBavbjkNAHh81iCEeOj0gzPNvToBvUIDUFZjxKo9nj+1YS9PXQZ+OT+lAgvHpgCwFhY7ooO3XJjcEJFPEgTB7iXhoijiiS9/QkOjBRP6RuKGoXGuCNHjqP2aa29e35brM6M3+RWeuwz8crePSkKgWokTRdXYcbpc7nC6jckNEfmskXYWFX97tAjbT5ZC7afAM7PTPWbvIDncMtw6elNSbcTqvY4dvWlotGD9sUKU1Rgdet2esu0r5YHLwC+nC1Dh1uEJADx7WTiTGyLyWcOlouIONtGsNpjw9Fc/AQAemtQbqU1LyKltaj8FHprcGwCw3IGjN7XGRtz73j48uPIgnvzyJ4dc0xFEUfSagmLJXZkpAIDtJ0tR5aE7vjO5ISKfld4rBGo/BSpqG3CmrLbNY17eeBIl1UakRATafmhTx24dkYA4nT+Kq4z4eH9+j69XXmPEnW/txg+nygBYl+O7yyaPlXUm26ah3jAtBQB9ooORFhmERouIH5vec0/D5IaIfJbGT4mrEkIBtL0k/NgFPd7beQ6AdWNMf5VvbYzZXRo/JRZJozdbc+1ejdaWgkt1uPX1XThcoEdYoAoBKiX09SacKKp2VLg9IhUTR2k1XvX5mDIgGgCwxUM302RyQ0Q+bbit7qZ1UbF1Y8xjsIjArKFxmNA3So7wPNZtIxMRG+KPQr0BH+8v6NY1ThZX4+blO3GmrBa9QgOw9sGxGJ1mnUrcfcY9il2bp6S8Y9RGco2U3OSUus0oWVcwuSEinzbCtmKq9cjNR3vzcDi/ElqNHx6fNUiO0Dyaxk/ZXHuz5XSXR28OnK/Ara/vQnGVEf1igvHJQ5noEx2MMWkRANwnufHkPaU6MjIlHEFqJcpqjDh2US93OF3G5IaIfJq0HPxMWS3Km1bhlFYb8cL6EwCAR6b3Q0yI726M2RPzRiYiJkSDi3oDPjlg/+jN5hPFmP/2HujrTbg6KRQf/zoTcTrryIiU3Ow5W+EWIwre0uPmcmo/Bcb3jQQAbPbAqSkmN0Tk00ID1egbHQygeUn4c98eR5WhEem9QmwrR6jr/FVKPDjJOnrz7y25aGi0dHrOJwcKcP/7B2AwWTClfxQ+vG8MQgPVttfT40MQpHafuhtpWspbiolbusaD626Y3BCRzxuR0rwkfGduGdYdugCBG2M6xB2jkhCl1eBCZT0+Pdjx6M0b23Lx6NrDMFtEzL26F95cMAIB6tZFun5Khe3va89Z+aemvHVaCgCm9LcmN4cL9Citdq/eQp1hckNEPk+qu9mVW47HP7dujPnL0cnISAyVMSrv0HL05rUtp2EyXzl6Y7GIeO7b41j2nXUq8IGJaXjxlgyolG3/iHKXuhtv7HHTUnSIP9J7hQAAtuZ41ugNkxsi8nkjmlZMHb2gR25pLSKDNXiUG2M6zPzRSYgM1qDgUj3WHbzQ6jWT2YLHPjmCN7efAQAsnTkA//uLgVB0MGI2Jk0auZG37qa02ghjowUKAYgL9c66rGv6S6ummNwQEXmUpPBARGk1tq8fnzUQugBujOko1tGbNADAqy1Gb+obzPj1Bwfw6cECKBUC/nbLUPx6UueNEtN76RCkVqKyzoScYvnqbvKbRm3idAHtjjJ5OqnfzQ8ny9ocdXNX3vm3QUTUBYIg2PaZGtcnAjdmxMsckfeZPzoZkcFq5FXU4fNDF1BZ14BfvrMHm0+UQOOnwBu/HI5bRyTadS2VUoHhKfL3u7HtKeWFxcSSjIRQRASpUW1sxL5ONph1J0xuiIgA/P7afliYmYyXbr2KG2M6QYBaifsnWEdvXtl8Gre9sQsHzl9CiL8fPrxvNKYNiunS9ca4QTM/by4mligUAib1tzaw3JpTKnM09mNyQ0QEoE+0Fk/PTkeszjtrJ9zBXZnJCA+yjt6cLK5BTIgGax8ca1v91BVSUfFeGetu8iu8dxl4S9KScE/qd8PkhoiIXCJQ7WfbcyotMgifPDgW/WO13brWkF46BKqVuFRnwskSeepuCiq9s4Hf5Sb0jYJSIeB0SY1ttMrdMbkhIiKXuXd8Kj7+dSa+/M34Hk3nqJQKW3fp3bnyTE1JIzfePC0FALoAle299pTRGyY3RETkMoIgYFRqOII1fj2+VnO/G9cXupotIi5WSsmNd09LAZ43NcXkhoiIPFLzPlPlLq+7KdTXo9EiQqUUEK31/jotKbnZdaYcdQ2NMkfTOSY3RETkkYYm6BCgstbdnCqpcem9pc7EvUIDfGKLjr7RwegVGoCGRgt2npZ/24vOMLkhIiKPpFIqbN2lXb0k3BeWgbckCELz1JQHdCtmckNERB5Lrn2m8m27gftGcgO03iVcFOXb9sIeTG6IiMhjybXPVEGF93cnvlxm7wj4qxQo1Btwoki+bS/sweSGiIg81pBeoQhQKVFR2+DSuhvbbuA+Mi0FWPcIG9s7EoD7r5pickNERB5L7ddcd7PnrOumpvIvSQ38fGfkBmjeSHOrm9fdMLkhIiKP5uq6G2OjGUVVBgC+NXIDAFOa9pk6cP4SKusaZI6mfUxuiIjIo41OlTbRrHBJoevFSgNEEQhQKRERpHb6/dxJQlgg+sUEwyIC206670aaTG6IiMijDU0Ihb9K4bK6m4JLzcXEvriD/JQWq6bcFZMbIiLyaGo/BUYkS6M3zp+a8pU9pdpzTX9rcrPtZCnMMu3I3hkmN0RE5PGkJeEuSW58tJhYMjw5DCH+frhUZ0J2/iW5w2mTrMnN9u3bccMNNyA+Ph6CIODzzz/v9JzXXnsNAwcOREBAAPr374/333/f+YESEZFbs+0z5YK6m3xbjxvfHLnxUyowsZ+1sNhdl4TLmtzU1tYiIyMDr732ml3HL1++HEuXLsVTTz2Fn376CU8//TSysrLw1VdfOTlSIiJyZ1LdTXltA047ue6muceNb47cAC13CXfPouKe7znfAzNnzsTMmTPtPv6DDz7Ar3/9a8ybNw8AkJaWhn379uGvf/0rbrjhBmeFSUREbk7tp8Dw5DDsOF2O3WfK0TdG67R7NRcU++bIDQBM6hcFQQCOF1ahUF+POJ17JXoeVXNjNBrh7996a/mAgADs3bsXJpOp3XOqqqpaPYiIyPuMSZX63VQ47R51DY0oq7H2d0n04eQmIliDqxJDAQBb3HD0xqOSm+uuuw5vv/02Dhw4AFEUsX//frz99tswmUwoKytr85xly5ZBp9PZHomJiS6OmoiIXGFM76a6m7PlTqu7udA0JaX194MuUOWUe3gKadXUFjfsVuxRyc3jjz+OmTNnYsyYMVCpVJg9ezYWLlwIAFAo2v5Wli5dCr1eb3vk5+e7MmQiInKRoQk6+KsUKKtpQG6pc+pumldK+e6ojUTqd7PjdBmMjWaZo2nNo5KbgIAA/Oc//0FdXR3OnTuHvLw8pKSkQKvVIioqqs1zNBoNQkJCWj2IiMj7aPyUuDrJus/ULidNTTX3uHGvGhM5DI4PQbRWg7oGM/Y4cSqwOzwquZGoVCokJCRAqVRi9erVmDVrVrsjN0RE5Ducvc+Ury8Db0kQBEzpL62acq+pKVkzgpqaGmRnZyM7OxsAcPbsWWRnZyMvLw+AdUppwYIFtuNPnjyJlStX4tSpU9i7dy9uv/12HDt2DM8995wc4RMRkZtp7nfjnLob2zJwH23gdznbVgw5JS7Z18tesiY3+/fvx7BhwzBs2DAAwO9//3sMGzYMTzzxBACgsLDQlugAgNlsxksvvYSMjAxce+21MBgM2LlzJ1JSUuQIn4iI3ExGog4aP+fV3dhqbnx064XLje8bCZVSwPnyOpwpq5U7HBtZ+9xMnjy5w0xvxYoVrb4eOHAgDh065OSoiIjIU2n8lBieHIadueXYfaYCfaId2+9GmpZicmMVrPHD6NQI/Hi6DFtOlKB3VLDcIQHw0JobIiKi9oxOdU7djb7ehCpDIwCgVyinpSRTBrhf3Q2TGyIi8irNm2g6dp8pqTNxRJAaQRpZJz7cirQVw96zFag2tN1Q19WY3BARkVfJSAxtqrsxIrfUcXUg0jLwBE5JtZIaGYTUyCA0WkT8eKrthrquxuSGiIi8ir+qud+NI6emCmwN/DgldTl3WxLO5IaIiLyObUn4Wcc1l2OPm/ZJU1NbT5bCYpF/STiTGyIi8jqjbXU3jut3Y+txw+7EVxiZGoYgtRKl1Ub8dFH+DaqZ3BARkde5KjEUaj8FSquNDuu/wn2l2qfxU2Jcn0gA7jE1xeSGiIi8jrXuJhSAY+puRFFssa8Uk5u2SFNTm91gl3AmN0RE5JWa95nqed1NeW0D6k1mCAIQH+rf4+t5I6nfzZGCSpTVGGWNhckNERF5pZabaPa07kaqt4nR+kPjp+xxbN4oJsQfg+NDIIrA1pxSWWNhckNERF6pZd3N2R7W3TRvu8Bi4o5IU1NbZK67YXJDREReyV+lxLDEUAA9n5qSiom5DLxj0tTU9pOlMJktssXB5IaIiLxWy6mpnrAVE7OBX4cyEkJxx6hE/OWmdDhw54suY3JDRERey1F1N1J3Ym690DGlQsCyuUMx+6peUPvJl2IwuSEiIq81LMlad1PSw7obWwM/Tkt5BCY3RETktfxVSlzVVHfT3a0YLBYRF5qSmwROS3kEJjdEROTVelp3U1xtQIPZAqVCQJyOPW48AZMbIiLyamO6sc+UxSIir7wO3/9cjDe3nwFgbd7np+SPTU/gJ3cAREREznR1UhjUSgWKq4w4V16H1Mgg22uiKOJCZT1OFdfgZHE1Tjb993RJDepN5lbX6RetdXXo1E1MboiIyKtJdTd7z1Xgg13nER/qj5PF1cgprsHp4mrUNpjbPE+tVCAtKgj9Y7XoF6PF3Kt7uThy6i4mN0RE5PXGpIVj77kK/GfH2SteUykFpEYGoV+MtukRjL4xWiSHB3IaykMxuSEiIq9309UJWJd9AWqlokUSY01kUiKDoGIS41WY3BARkddLjQzCD/9zjdxhkIswVSUiIiKvwuSGiIiIvAqTGyIiIvIqTG6IiIjIqzC5ISIiIq/C5IaIiIi8CpMbIiIi8ipMboiIiMirMLkhIiIir8LkhoiIiLwKkxsiIiLyKkxuiIiIyKswuSEiIiKvwuSGiIiIvIqf3AG4miiKAICqqiqZIyEiIiJ7ST+3pZ/jHfG55Ka6uhoAkJiYKHMkRERE1FXV1dXQ6XQdHiOI9qRAXsRiseDixYvQarUQBOGK16uqqpCYmIj8/HyEhITIEKHn4HtlP75X9uN71TV8v+zH98p+7vheiaKI6upqxMfHQ6HouKrG50ZuFAoFEhISOj0uJCTEbf5C3R3fK/vxvbIf36uu4ftlP75X9nO396qzERsJC4qJiIjIqzC5ISIiIq/C5OYyGo0GTz75JDQajdyhuD2+V/bje2U/vlddw/fLfnyv7Ofp75XPFRQTERGRd+PIDREREXkVJjdERETkVZjcEBERkVdhckNERERehclNC6+99hpSUlLg7++P0aNHY+/evXKH5JaeeuopCILQ6jFgwAC5w3IL27dvxw033ID4+HgIgoDPP/+81euiKOKJJ55AXFwcAgICMG3aNJw6dUqeYGXW2Xt19913X/E5mzFjhjzBymzZsmUYOXIktFotoqOjMWfOHOTk5LQ6xmAwICsrCxEREQgODsbNN9+M4uJimSKWjz3v1eTJk6/4bD344IMyRSyf5cuXY+jQobZGfZmZmfjuu+9sr3vyZ4rJTZM1a9bg97//PZ588kkcPHgQGRkZuO6661BSUiJ3aG5p8ODBKCwstD1+/PFHuUNyC7W1tcjIyMBrr73W5usvvPAC/vWvf+H111/Hnj17EBQUhOuuuw4Gg8HFkcqvs/cKAGbMmNHqc/bRRx+5MEL3sW3bNmRlZWH37t3YuHEjTCYTpk+fjtraWtsxv/vd7/DVV19h7dq12LZtGy5evIi5c+fKGLU87HmvAOD+++9v9dl64YUXZIpYPgkJCXj++edx4MAB7N+/H9dccw1mz56Nn376CYCHf6ZEEkVRFEeNGiVmZWXZvjabzWJ8fLy4bNkyGaNyT08++aSYkZEhdxhuD4C4bt0629cWi0WMjY0V//a3v9meq6ysFDUajfjRRx/JEKH7uPy9EkVRXLhwoTh79mxZ4nF3JSUlIgBx27ZtoihaP0cqlUpcu3at7Zjjx4+LAMRdu3bJFaZbuPy9EkVRnDRpkvjwww/LF5QbCwsLE99++22P/0xx5AZAQ0MDDhw4gGnTptmeUygUmDZtGnbt2iVjZO7r1KlTiI+PR1paGubPn4+8vDy5Q3J7Z8+eRVFRUavPmU6nw+jRo/k5a8fWrVsRHR2N/v3746GHHkJ5ebncIbkFvV4PAAgPDwcAHDhwACaTqdVna8CAAUhKSvL5z9bl75Xkww8/RGRkJNLT07F06VLU1dXJEZ7bMJvNWL16NWpra5GZmenxnymf2zizLWVlZTCbzYiJiWn1fExMDE6cOCFTVO5r9OjRWLFiBfr374/CwkI8/fTTmDBhAo4dOwatVit3eG6rqKgIANr8nEmvUbMZM2Zg7ty5SE1NRW5uLv73f/8XM2fOxK5du6BUKuUOTzYWiwVLlizBuHHjkJ6eDsD62VKr1QgNDW11rK9/ttp6rwDgzjvvRHJyMuLj43HkyBH84Q9/QE5ODj777DMZo5XH0aNHkZmZCYPBgODgYKxbtw6DBg1Cdna2R3+mmNxQl82cOdP256FDh2L06NFITk7Gxx9/jHvvvVfGyMib3H777bY/DxkyBEOHDkXv3r2xdetWTJ06VcbI5JWVlYVjx46xzs0O7b1XDzzwgO3PQ4YMQVxcHKZOnYrc3Fz07t3b1WHKqn///sjOzoZer8cnn3yChQsXYtu2bXKH1WOclgIQGRkJpVJ5RRV4cXExYmNjZYrKc4SGhqJfv344ffq03KG4NemzxM9Z96SlpSEyMtKnP2eLFy/G119/jS1btiAhIcH2fGxsLBoaGlBZWdnqeF/+bLX3XrVl9OjRAOCTny21Wo0+ffpg+PDhWLZsGTIyMvDPf/7T4z9TTG5g/csdPnw4Nm3aZHvOYrFg06ZNyMzMlDEyz1BTU4Pc3FzExcXJHYpbS01NRWxsbKvPWVVVFfbs2cPPmR0KCgpQXl7uk58zURSxePFirFu3Dps3b0Zqamqr14cPHw6VStXqs5WTk4O8vDyf+2x19l61JTs7GwB88rN1OYvFAqPR6PmfKbkrmt3F6tWrRY1GI65YsUL8+eefxQceeEAMDQ0Vi4qK5A7N7TzyyCPi1q1bxbNnz4o7duwQp02bJkZGRoolJSVyhya76upq8dChQ+KhQ4dEAOLLL78sHjp0SDx//rwoiqL4/PPPi6GhoeIXX3whHjlyRJw9e7aYmpoq1tfXyxy563X0XlVXV4uPPvqouGvXLvHs2bPi999/L1599dVi3759RYPBIHfoLvfQQw+JOp1O3Lp1q1hYWGh71NXV2Y558MEHxaSkJHHz5s3i/v37xczMTDEzM1PGqOXR2Xt1+vRp8ZlnnhH3798vnj17Vvziiy/EtLQ0ceLEiTJH7np//OMfxW3btolnz54Vjxw5Iv7xj38UBUEQ//vf/4qi6NmfKSY3LbzyyitiUlKSqFarxVGjRom7d++WOyS3NG/ePDEuLk5Uq9Vir169xHnz5omnT5+WOyy3sGXLFhHAFY+FCxeKomhdDv7444+LMTExokajEadOnSrm5OTIG7RMOnqv6urqxOnTp4tRUVGiSqUSk5OTxfvvv99nf9lo630CIL777ru2Y+rr68VFixaJYWFhYmBgoHjTTTeJhYWF8gUtk87eq7y8PHHixIlieHi4qNFoxD59+oiPPfaYqNfr5Q1cBr/61a/E5ORkUa1Wi1FRUeLUqVNtiY0oevZnShBFUXTdOBERERGRc7HmhoiIiLwKkxsiIiLyKkxuiIiIyKswuSEiIiKvwuSGiIiIvAqTGyIiIvIqTG6IiIjIqzC5ISICIAgCPv/8c7nDICIHYHJDRLK7++67IQjCFY8ZM2bIHRoReSA/uQMgIgKAGTNm4N133231nEajkSkaIvJkHLkhIreg0WgQGxvb6hEWFgbAOmW0fPlyzJw5EwEBAUhLS8Mnn3zS6vyjR4/immuuQUBAACIiIvDAAw+gpqam1TH/+c9/MHjwYGg0GsTFxWHx4sWtXi8rK8NNN92EwMBA9O3bF19++aVzv2kicgomN0TkER5//HHcfPPNOHz4MObPn4/bb78dx48fBwDU1tbiuuuuQ1hYGPbt24e1a9fi+++/b5W8LF++HFlZWXjggQdw9OhRfPnll+jTp0+rezz99NO47bbbcOTIEfziF7/A/PnzUVFR4dLvk4gcQO6dO4mIFi5cKCqVSjEoKKjV49lnnxVF0brT84MPPtjqnNGjR4sPPfSQKIqi+Oabb4phYWFiTU2N7fVvvvlGVCgUtp3E4+PjxT/96U/txgBA/L//+z/b1zU1NSIA8bvvvnPY90lErsGaGyJyC1OmTMHy5ctbPRceHm77c2ZmZqvXMjMzkZ2dDQA4fvw4MjIyEBQUZHt93LhxsFgsyMnJgSAIuHjxIqZOndphDEOHDrX9OSgoCCEhISgpKenut0REMmFyQ0RuISgo6IppIkcJCAiw6ziVStXqa0EQYLFYnBESETkRa26IyCPs3r37iq8HDhwIABg4cCAOHz6M2tpa2+s7duyAQqFA//79odVqkZKSgk2bNrk0ZiKSB0duiMgtGI1GFBUVtXrOz88PkZGRAIC1a9dixIgRGD9+PD788EPs3bsX77zzDgBg/vz5ePLJJ7Fw4UI89dRTKC0txW9+8xvcddddiImJAQA89dRTePDBBxEdHY2ZM2eiuroaO3bswG9+8xvXfqNE5HRMbojILaxfvx5xcXGtnuvfvz9OnDgBwLqSafXq1Vi0aBHi4uLw0UcfYdCgQQCAwMBAbNiwAQ8//DBGjhyJwMBA3HzzzXj55Zdt11q4cCEMBgP+/ve/49FHH0VkZCRuueUW132DROQygiiKotxBEBF1RBAErFu3DnPmzJE7FCLyAKy5ISIiIq/C5IaIiIi8CmtuiMjtcfaciLqCIzdERETkVZjcEBERkVdhckNERERehckNEREReRUmN0RERORVmNwQERGRV2FyQ0RERF6FyQ0RERF5FSY3RERE5FX+H9JxX7lRbawnAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training Teacher\n",
      "Teacher weights and architecture saved and exported for lambda: 0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary for results\n",
    "lambda_results = {}\n",
    "\n",
    "# Loop for training the teacher model with different lambda values\n",
    "for i in lmda_list:\n",
    "    # Reset the teacher model for each lambda\n",
    "    teacher_model = torchvision.models.resnet34(weights=None).to(device)\n",
    "    teacher_model.fc = nn.Linear(512, num_classes)\n",
    "    teacher_optimizer = optim.Adam(teacher_model.parameters(), lr=best_lr_teacher)\n",
    "    \n",
    "    # Initialize the adversary for the teacher\n",
    "    adv = Adversary()\n",
    "    teacher_optimizer_adv = optim.Adam(adv.parameters(), lr=best_lr_teacher)\n",
    "\n",
    "    pretrain_teacher(teacher_model, trainloader, criterion_clf, teacher_optimizer, device, epochs_pretrain)\n",
    "    pretrain_adversary(adv, student_model, optimizer_adv, trainloader, adv_criterion, device, epochs_pretrain)\n",
    "    \n",
    "    # Train the teacher model with adversarial training\n",
    "    teacher_mean_abs_val_disparity = train_teacher(teacher_model, adv, trainloader, criterion_clf, adv_criterion, teacher_optimizer, teacher_optimizer_adv, device, epochs, i, patience=patience_teacher)\n",
    "\n",
    "    # Save the teacher model and its state\n",
    "    torch.save(teacher_model.state_dict(), f'teacher_model_weights_ckd_wider_lambda{i}.pth')\n",
    "    torch.save(teacher_model, f'teacher_model_ckd_wider_lambda{i}.pth')\n",
    "    print('Teacher weights and architecture saved and exported for lambda:', i)\n",
    "\n",
    "    # Store the teacher results in the dictionary\n",
    "    lambda_results[i] = {\n",
    "        'teacher_mean_abs_val_disparity': teacher_mean_abs_val_disparity\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f00ed527-6705-4f12-b7af-2c5d0a1e753f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:08<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 0: loss - 0.3896394794987094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:08<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 1: loss - 0.33395586379112735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 31/31 [02:09<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Epoch 2: loss - 0.31296479125176707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                   | 0/31 [00:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 14.75 GiB of which 825.06 MiB is free. Including non-PyTorch memory, this process has 13.94 GiB memory in use. Of the allocated memory 4.44 GiB is allocated by PyTorch, and 9.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m student_optimizer_adv \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(adv\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mbest_lr_student)\n\u001b[1;32m     17\u001b[0m pretrain_student(student_model, teacher_model, trainloader, criterion_clf, student_optimizer, device, alpha, temperature, epochs_pretrain)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mpretrain_adversary\u001b[49m\u001b[43m(\u001b[49m\u001b[43madv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_adv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madv_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs_pretrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m student_mean_abs_val_disparity \u001b[38;5;241m=\u001b[39m train_student_with_distillation_disparity(student_model, teacher_model, adv, trainloader, testloader, criterion_clf, adv_criterion, student_optimizer, device, alpha, temperature, epochs, lmda\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patience\u001b[38;5;241m=\u001b[39mpatience_student, optimizer_adv\u001b[38;5;241m=\u001b[39mstudent_optimizer_adv)\n\u001b[1;32m     22\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(student_model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudent_model_weights_ckd_wider_lambda\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 20\u001b[0m, in \u001b[0;36mpretrain_adversary\u001b[0;34m(adv, model, adversary_optimizer, trainloader, adv_criterion, device, epochs_pretrain)\u001b[0m\n\u001b[1;32m     18\u001b[0m adversary_output \u001b[38;5;241m=\u001b[39m adv(concatenated_output)\n\u001b[1;32m     19\u001b[0m adversary_loss \u001b[38;5;241m=\u001b[39m adv_criterion(adversary_output, targets) \u001b[38;5;66;03m# compute loss\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43madversary_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# back prop\u001b[39;00m\n\u001b[1;32m     21\u001b[0m adversary_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m adversary_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacty of 14.75 GiB of which 825.06 MiB is free. Including non-PyTorch memory, this process has 13.94 GiB memory in use. Of the allocated memory 4.44 GiB is allocated by PyTorch, and 9.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Loop for training the student model with different lambda values\n",
    "for i in lmda_list:\n",
    "    # load teacher model with lambda 0\n",
    "    teacher_model = torch.load('teacher_model_ckd_wider_lambda0.pth')\n",
    "    teacher_model.load_state_dict(torch.load('teacher_model_weights_ckd_wider_lambda0.pth'))\n",
    "    teacher_model = teacher_model.to(device)\n",
    "    \n",
    "    # Reset the student model for each lambda\n",
    "    student_model = torchvision.models.resnet18(weights=None).to(device)\n",
    "    student_model.fc = nn.Linear(512, num_classes)\n",
    "    student_optimizer = optim.Adam(student_model.parameters(), lr=best_lr_student)\n",
    "    student_scheduler = torch.optim.lr_scheduler.StepLR(student_optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    adv = Adversary()\n",
    "    student_optimizer_adv = optim.Adam(adv.parameters(), lr=best_lr_student)\n",
    "\n",
    "    pretrain_student(student_model, teacher_model, trainloader, criterion_clf, student_optimizer, device, alpha, temperature, epochs_pretrain)\n",
    "    pretrain_adversary(adv, teacher_model, optimizer_adv, trainloader, adv_criterion, device, epochs_pretrain)\n",
    "    \n",
    "    student_mean_abs_val_disparity = train_student_with_distillation_disparity(student_model, teacher_model, adv, trainloader, testloader, criterion_clf, adv_criterion, student_optimizer, device, alpha, temperature, epochs, lmda=0, patience=patience_student, optimizer_adv=student_optimizer_adv)\n",
    "\n",
    "    torch.save(student_model.state_dict(), f'student_model_weights_ckd_wider_lambda{i}.pth')\n",
    "    torch.save(student_model, f'student_model_ckd_wider_lambda{i}.pth')\n",
    "    print('Student weights and architecture saved and exported for lambda:', i)\n",
    "\n",
    "    # Update the dictionary with the student results\n",
    "    lambda_results[i].update({\n",
    "        'student_mean_abs_val_disparity': student_mean_abs_val_disparity\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073656a3-9d3d-469d-a66f-0afc3c289ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_performance_metrics(teacher, student, dataloader):\n",
    "    teacher.eval()\n",
    "    student.eval()\n",
    "    \n",
    "    all_labels = []\n",
    "    all_teacher_preds = []\n",
    "    all_student_preds = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        inputs = batch['img'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher(inputs)\n",
    "            student_outputs = student(inputs)\n",
    "            \n",
    "        teacher_preds = torch.argmax(teacher_outputs, dim=1).cpu().numpy()\n",
    "        student_preds = torch.argmax(student_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "        all_teacher_preds.append(teacher_preds)\n",
    "        all_student_preds.append(student_preds)\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_teacher_preds = np.concatenate(all_teacher_preds)\n",
    "    all_student_preds = np.concatenate(all_student_preds)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': (accuracy_score(all_labels, all_teacher_preds), accuracy_score(all_labels, all_student_preds)),\n",
    "        'precision': (precision_score(all_labels, all_teacher_preds, average='weighted', zero_division=0), precision_score(all_labels, all_student_preds, average='weighted', zero_division=0)),\n",
    "        'recall': (recall_score(all_labels, all_teacher_preds, average='weighted'), recall_score(all_labels, all_student_preds, average='weighted')),\n",
    "        'f1': (f1_score(all_labels, all_teacher_preds, average='weighted'), f1_score(all_labels, all_student_preds, average='weighted'))\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'all_labels': all_labels,\n",
    "        'all_teacher_preds': all_teacher_preds,\n",
    "        'all_student_preds': all_student_preds\n",
    "    }\n",
    "\n",
    "def compare_model_size(teacher, student):\n",
    "    teacher_params = sum(p.numel() for p in teacher.parameters())\n",
    "    student_params = sum(p.numel() for p in student.parameters())\n",
    "    return teacher_params, student_params\n",
    "\n",
    "def compare_inference_time(teacher, student, dataloader):\n",
    "    dataiter = iter(dataloader)\n",
    "    data = next(dataiter)\n",
    "    inputs = data['img']\n",
    "    \n",
    "    teacher = teacher.to(device)\n",
    "    student = student.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        teacher_outputs = teacher(inputs)\n",
    "    teacher_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        student_outputs = student(inputs)\n",
    "    student_time = time.time() - start_time\n",
    "    \n",
    "    return teacher_time, student_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e04fd-db83-4893-bfd5-31d8808243d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each lambda value\n",
    "for lmda in lmda_list:\n",
    "    # Load teacher and student models for the current lambda\n",
    "    teacher_model = torch.load(f'teacher_model_ckd_wider_lambda{lmda}.pth')\n",
    "    student_model = torch.load(f'student_model_ckd_wider_lambda{lmda}.pth')\n",
    "\n",
    "    # Compute performance metrics\n",
    "    performance_metrics = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "\n",
    "    # Compute model sizes and inference times\n",
    "    teacher_params, student_params = compare_model_size(teacher_model, student_model)\n",
    "    teacher_time, student_time = compare_inference_time(teacher_model, student_model, testloader)\n",
    "\n",
    "    # Update results for the current lambda value\n",
    "    if lmda in lambda_results:\n",
    "        lambda_results[lmda].update({\n",
    "            'performance_metrics': performance_metrics,\n",
    "            'teacher_params': teacher_params,\n",
    "            'student_params': student_params,\n",
    "            'teacher_time': teacher_time,\n",
    "            'student_time': student_time\n",
    "        })\n",
    "    else:\n",
    "        lambda_results[lmda] = {\n",
    "            'performance_metrics': performance_metrics,\n",
    "            'teacher_params': teacher_params,\n",
    "            'student_params': student_params,\n",
    "            'teacher_time': teacher_time,\n",
    "            'student_time': student_time\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c127f4e-cc52-45ff-a035-9e0184fb9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = list(lambda_results.keys())\n",
    "teacher_accuracies = [lambda_results[lmda]['performance_metrics']['metrics']['accuracy'][0] for lmda in lambdas]\n",
    "student_accuracies = [lambda_results[lmda]['performance_metrics']['metrics']['accuracy'][1] for lmda in lambdas]\n",
    "\n",
    "plt.plot(lambdas, teacher_accuracies, label='Teacher Accuracy', marker='o')\n",
    "plt.plot(lambdas, student_accuracies, label='Student Accuracy', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d58ea-0417-4a20-bc3f-4b69f15b9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "teacher_precisions = [lambda_results[lmda]['performance_metrics']['metrics']['precision'][0] for lmda in lambdas]\n",
    "student_precisions = [lambda_results[lmda]['performance_metrics']['metrics']['precision'][1] for lmda in lambdas]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambdas, teacher_precisions, label='Teacher Precision', marker='o')\n",
    "plt.plot(lambdas, student_precisions, label='Student Precision', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ee757-c1af-4f1a-85bd-136bc85e6e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "teacher_recalls = [lambda_results[lmda]['performance_metrics']['metrics']['recall'][0] for lmda in lambdas]\n",
    "student_recalls = [lambda_results[lmda]['performance_metrics']['metrics']['recall'][1] for lmda in lambdas]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambdas, teacher_recalls, label='Teacher Recall', marker='o')\n",
    "plt.plot(lambdas, student_recalls, label='Student Recall', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Recall Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4e93d-9344-49fc-978f-a00d8d8e8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 Score\n",
    "teacher_f1s = [lambda_results[lmda]['performance_metrics']['metrics']['f1'][0] for lmda in lambdas]\n",
    "student_f1s = [lambda_results[lmda]['performance_metrics']['metrics']['f1'][1] for lmda in lambdas]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambdas, teacher_f1s, label='Teacher F1 Score', marker='o')\n",
    "plt.plot(lambdas, student_f1s, label='Student F1 Score', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b769e1-25e1-423c-b77f-af275eb11152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Size\n",
    "teacher_sizes = [lambda_results[lmda]['teacher_params'] / 1e6 for lmda in lambdas]  # Convert to millions\n",
    "student_sizes = [lambda_results[lmda]['student_params'] / 1e6 for lmda in lambdas]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambdas, teacher_sizes, label='Teacher Model Size', marker='o')\n",
    "plt.plot(lambdas, student_sizes, label='Student Model Size', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Model Size (Millions of Parameters)')\n",
    "plt.title('Model Size Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8aae8d-9a0d-45b3-9fc2-c27bc5fcaa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference Time\n",
    "teacher_times = [lambda_results[lmda]['teacher_time'] for lmda in lambdas]\n",
    "student_times = [lambda_results[lmda]['student_time'] for lmda in lambdas]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambdas, teacher_times, label='Teacher Inference Time', marker='o')\n",
    "plt.plot(lambdas, student_times, label='Student Inference Time', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Inference Time (s)')\n",
    "plt.title('Inference Time Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7cb7f0-12a9-4cec-8188-048c3ffcadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting disparity values for both teacher and student models\n",
    "teacher_disparities = [lambda_results[lmda]['teacher_mean_abs_val_disparity'] for lmda in lambdas]\n",
    "student_disparities = [lambda_results[lmda]['student_mean_abs_val_disparity'] for lmda in lambdas]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lambdas, teacher_disparities, label='Teacher Average Disparity', marker='o')\n",
    "plt.plot(lambdas, student_disparities, label='Student Average Disparity', marker='o')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Average Disparity')\n",
    "plt.title('Average Disparity Comparison Across Lambdas')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80376f-d5b1-4008-8099-18693972c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_combined_distribution(teacher_preds, student_preds, class_names, lmda):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(x=teacher_preds)\n",
    "    plt.title(f'Teacher Model Predictions (Lambda={lmda})')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.countplot(x=student_preds)\n",
    "    plt.title(f'Student Model Predictions (Lambda={lmda})')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_combined_confusion_matrix(all_labels, teacher_preds, student_preds, class_names, lmda):\n",
    "    cm_teacher = confusion_matrix(all_labels, teacher_preds)\n",
    "    cm_student = confusion_matrix(all_labels, student_preds)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(pd.DataFrame(cm_teacher, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title(f'Teacher Confusion Matrix (Lambda={lmda})')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(pd.DataFrame(cm_student, index=class_names, columns=class_names), annot=True, fmt='g')\n",
    "    plt.title(f'Student Confusion Matrix (Lambda={lmda})')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Loop over each lambda value\n",
    "for lmda in lmda_list:\n",
    "    # Load teacher and student models\n",
    "    teacher_model = torch.load(f'teacher_model_ckd_wider_lambda{lmda}.pth')\n",
    "    student_model = torch.load(f'student_model_ckd_wider_lambda{lmda}.pth')\n",
    "\n",
    "    # Generate predictions and compute metrics\n",
    "    performance_metrics = compare_performance_metrics(teacher_model, student_model, testloader)\n",
    "    all_labels = performance_metrics['all_labels']\n",
    "    all_teacher_preds = performance_metrics['all_teacher_preds']\n",
    "    all_student_preds = performance_metrics['all_student_preds']\n",
    "\n",
    "    # Plot distribution and confusion matrices\n",
    "    plot_combined_distribution(all_teacher_preds, all_student_preds, class_names_new, lmda)\n",
    "    plot_combined_confusion_matrix(all_labels, all_teacher_preds, all_student_preds, class_names_new, lmda)\n",
    "\n",
    "    # Print classification reports\n",
    "    teacher_report = classification_report(all_labels, all_teacher_preds, target_names=class_names_new, zero_division=0)\n",
    "    student_report = classification_report(all_labels, all_student_preds, target_names=class_names_new, zero_division=0)\n",
    "    print(f'Classification Report - Teacher Model (Lambda={lmda})')\n",
    "    print(teacher_report)\n",
    "    print(f'Classification Report - Student Model (Lambda={lmda})')\n",
    "    print(student_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf516d7-2f71-4abd-b904-0e1364cca7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bias_variance_tradeoff(model_results, model_type, lambdas):\n",
    "    # Extract bias (disparity) and accuracy values\n",
    "    if model_type == 'teacher':\n",
    "        bias_values = [result['teacher_mean_abs_val_disparity'][0] for result in model_results.values()]\n",
    "        accuracy_values = [result['performance_metrics']['metrics']['accuracy'][0] for result in model_results.values()]\n",
    "        model_name = \"Teacher\"\n",
    "    elif model_type == 'student':\n",
    "        bias_values = [result['student_mean_abs_val_disparity'] for result in model_results.values()]\n",
    "        accuracy_values = [result['performance_metrics']['metrics']['accuracy'][1] for result in model_results.values()]\n",
    "        model_name = \"Student\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'teacher' or 'student'.\")\n",
    "\n",
    "    # Weight for the trade-off (can be adjusted based on preference)\n",
    "    bias_weight = 1\n",
    "\n",
    "    # Calculate the weighted ratio\n",
    "    weighted_ratios = np.array(accuracy_values) / (1 + bias_weight * np.array(bias_values))\n",
    "    closest_to_one_index = np.argmin(np.abs(weighted_ratios - 1))\n",
    "    optimal_bias = bias_values[closest_to_one_index]\n",
    "    optimal_accuracy = accuracy_values[closest_to_one_index]\n",
    "    optimal_ratio = weighted_ratios[closest_to_one_index]\n",
    "\n",
    "    # Plotting the bias-variance trade-off curve\n",
    "    plt.plot(bias_values, accuracy_values, marker='o', linestyle='-', label=f'{model_name} Trade-off Points')\n",
    "\n",
    "    # Mark all points with their lambda values\n",
    "    for i, (bias, acc, lmbda) in enumerate(zip(bias_values, accuracy_values, lambdas)):\n",
    "        plt.annotate(f'={lmbda}', (bias, acc), textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "\n",
    "    # Highlight the optimal point\n",
    "    plt.scatter(optimal_bias, optimal_accuracy, color='r', s=100, marker='X', label=f'Optimal Point (={lambdas[closest_to_one_index]})')\n",
    "    plt.xlabel('Disparity')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{model_name} Accuracy-Fairness Trade-off Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Print optimal values\n",
    "    print(f\"Optimal Lambda for {model_name}: {lambdas[closest_to_one_index]}\")\n",
    "    print(f\"Optimal Bias/Disparity for {model_name}: {optimal_bias}\")\n",
    "    print(f\"Optimal Accuracy for {model_name}: {optimal_accuracy}\")\n",
    "    print(f\"Optimal Weighted Ratio for {model_name}: {optimal_ratio:.2f}\")\n",
    "\n",
    "# Plot for Teacher\n",
    "plot_bias_variance_tradeoff(lambda_results, 'teacher', lmda_list)\n",
    "\n",
    "# Plot for Student\n",
    "plot_bias_variance_tradeoff(lambda_results, 'student', lmda_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b0ac6-bf11-4263-8d58-e3a0f6ca29a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfad1e-f278-4c44-bbaa-46da0763eddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2caff4-753e-4960-8043-3e5029d0193a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7caf96-e434-472e-88c5-0bb0b3d300a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd96b9-a3f7-4f06-9dbd-48c8f4ed8762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
