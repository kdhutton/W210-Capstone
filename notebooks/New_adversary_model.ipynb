{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed182ac-bc78-4d44-b703-561a052cfc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances_argmin_min, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Subset, Dataset, DataLoader\n",
    "from torchvision.models import EfficientNet\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7437867-ecd5-4643-9fb8-a2fc1d1f15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "teacher_learning_rate = 0.0005 # 0.096779\n",
    "student_learning_rate = teacher_learning_rate\n",
    "teacher_epochs = 2 #200\n",
    "student_epochs = teacher_epochs\n",
    "teacher_patience = 10\n",
    "student_patience = 6\n",
    "temperature = 4.0\n",
    "alpha = 0.9\n",
    "momentum = 0.9\n",
    "step_size = 30\n",
    "gamma = 0.1\n",
    "batch_size = 54\n",
    "num_workers = 4\n",
    "epsilon = 0.05\n",
    "margin = 0.01\n",
    "num_classes = 16\n",
    "base_save_dir = \"Test_Dir2\"\n",
    "\n",
    "# list of lambda values to loop through for grid search\n",
    "teacher_lambda_factor_list = [0,50]\n",
    "student_lambda_factor_list = [0,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "689e9799-abe8-4878-88f0-b2402d0fa78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels used including for plotting\n",
    "class_labels = [0, 1, 3, 4, 6, 7, 11, 15, 17, 18, 19, 20, 22, 25, 27, 28, 30, 31, 33, 35, 36, 37, 39, 43, 44, 50, 51, 54, 57, 58]\n",
    "class_labels_new = torch.tensor([i for i in range(len(class_labels))])\n",
    "class_names_new = [f\"Class {label}\" for label in range(num_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a11b671f-0b71-438a-bf75-7ceb293b72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "\n",
    "# Count the number of GPUs available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "print(\"CUDA Available:\", cuda_available)\n",
    "print(\"Number of GPUs:\", num_gpus)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eabaae7-724f-4ee9-9df8-9463d205b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your JSON file is named 'your_file.json'\n",
    "file_path = './WIDER/Annotations/wider_attribute_trainval.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    # Load the JSON data from the file\n",
    "    data = json.load(file)\n",
    "\n",
    "class_idx = data['scene_id_map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c142a7d7-9627-48b6-a5aa-86527150ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_mapping = {\n",
    "    0: \"Team_Sports\",\n",
    "    1: \"Celebration\",\n",
    "    2: \"Parade\",\n",
    "    3: \"Waiter_Or_Waitress\",\n",
    "    4: \"Individual_Sports\",\n",
    "    5: \"Surgeons\",\n",
    "    6: \"Spa\",\n",
    "    7: \"Law_Enforcement\",\n",
    "    8: \"Business\",\n",
    "    9: \"Dresses\",\n",
    "    10: \"Water_Activities\",\n",
    "    11: \"Picnic\",\n",
    "    12: \"Rescue\",\n",
    "    13: \"Cheering\",\n",
    "    14: \"Performance_And_Entertainment\",\n",
    "    15: \"Family\"\n",
    "}\n",
    "\n",
    "# Ensure that all 16 new classes are covered\n",
    "# If some classes are not explicitly mentioned in new_label_mapping, add them\n",
    "for i in range(num_classes):\n",
    "    if i not in new_label_mapping:\n",
    "        new_label_mapping[i] = \"Additional Category {}\".format(i)\n",
    "\n",
    "class_idx = new_label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab11dc9-d6c6-4c45-8452-cff149af8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, ann_files, augs, img_size, dataset):\n",
    "\n",
    "        # Create a mapping from old labels to new labels\n",
    "        self.label_mapping = {old_label: new_label for new_label, old_label in enumerate(sorted(class_labels))}\n",
    "\n",
    "        self.new_label_mapping = {\n",
    "            0: 2,  # Parade\n",
    "            1: 8,  # Business\n",
    "            2: 7,  # Law Enforcement\n",
    "            3: 14,  # Performance and Entertainment\n",
    "            4: 1,  # Celebration\n",
    "            5: 13,  # Cheering\n",
    "            6: 8,  # Business\n",
    "            7: 8,  # Business\n",
    "            8: 1,  # Celebration\n",
    "            9: 14,  # Performance and Entertainment\n",
    "            10: 15, # Family\n",
    "            11: 15, # Family\n",
    "            12: 11, # Picnic\n",
    "            13: 7, # Law Enforcement\n",
    "            14: 6, # Spa\n",
    "            15: 13, # Cheering\n",
    "            16: 5, # Surgeons\n",
    "            17: 3, # Waiter or Waitress\n",
    "            18: 4, # Individual Sports\n",
    "            19: 0, # Team Sports\n",
    "            20: 0, # Team Sports\n",
    "            21: 0, # Team Sports\n",
    "            22: 4, # Individual Sports\n",
    "            23: 10, # Water Activities\n",
    "            24: 4, # Individual Sports\n",
    "            25: 1, # Celebration\n",
    "            26: 9, # Dresses\n",
    "            27: 12, # Rescue\n",
    "            28: 10,# Water Activities\n",
    "            29: 0  # Team Sports\n",
    "        }\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.ann_files = ann_files\n",
    "        self.augment = self.augs_function(augs, img_size)\n",
    "        # Initialize transformations directly\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[1, 1, 1])\n",
    "            ] \n",
    "        )\n",
    "        if self.dataset == \"wider\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                ] \n",
    "            )        \n",
    "\n",
    "        self.anns = []\n",
    "        self.load_anns()\n",
    "        print(self.augment)\n",
    "\n",
    "    def augs_function(self, augs, img_size):            \n",
    "        t = []\n",
    "        if 'randomflip' in augs:\n",
    "            t.append(transforms.RandomHorizontalFlip())\n",
    "        if 'ColorJitter' in augs:\n",
    "            t.append(transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0))\n",
    "        if 'resizedcrop' in augs:\n",
    "            t.append(transforms.RandomResizedCrop(img_size, scale=(0.7, 1.0)))\n",
    "        if 'RandAugment' in augs:\n",
    "            t.append(transforms.RandAugment())\n",
    "\n",
    "        t.append(transforms.Resize((img_size, img_size)))\n",
    "\n",
    "        return transforms.Compose(t)\n",
    "    \n",
    "    def load_anns(self):\n",
    "        self.anns = []\n",
    "        for ann_file in self.ann_files:\n",
    "            json_data = json.load(open(ann_file, \"r\"))\n",
    "            self.anns += json_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anns)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Make sure the index is within bounds\n",
    "        idx = idx % len(self)\n",
    "        ann = self.anns[idx]\n",
    "        \n",
    "        try:\n",
    "            # Attempt to open the image file\n",
    "            img = Image.open(f'WIDER/Image/{ann[\"file_name\"]}').convert(\"RGB\")\n",
    "\n",
    "            # If this is the wider dataset, proceed with specific processing\n",
    "            # x, y, w, h = ann['bbox']\n",
    "            # img_area = img.crop([x, y, x+w, y+h])\n",
    "            img_area = self.augment(img)\n",
    "            img_area = self.transform(img_area)\n",
    "            attributes_list = [target['attribute'] for target in ann['targets']]\n",
    "            num_people = len(attributes_list)\n",
    "            attributes_distribution = [max(sum(attribute), 0)/num_people for attribute in zip(*attributes_list)]\n",
    "            # Extract label from image path\n",
    "            img_path = f'WIDER/Image/{ann[\"file_name\"]}'\n",
    "            label = self.extract_label(img_path)  # You might need to implement this method\n",
    "            \n",
    "            return {\n",
    "                \"label\": label,\n",
    "                \"target\": torch.tensor([attributes_distribution[0]], dtype=torch.float32),\n",
    "                \"img\": img_area\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # If any error occurs during the processing of an image, log the error and the index\n",
    "            print(f\"Error processing image at index {idx}: {e}\")\n",
    "            # Instead of returning None, raise the exception\n",
    "            raise\n",
    "\n",
    "    def extract_label(self, img_path):\n",
    "        original_label = None\n",
    "    \n",
    "        if \"WIDER/Image/train\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/train/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/test\" in img_path:\n",
    "            label_str = img_path.split(\"WIDER/Image/test/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "        elif \"WIDER/Image/val\" in img_path:  # Handle validation images\n",
    "            label_str = img_path.split(\"WIDER/Image/val/\")[1].split(\"/\")[0]\n",
    "            original_label = int(label_str.split(\"--\")[0])\n",
    "    \n",
    "        if original_label is not None:\n",
    "            remapped_label = self.label_mapping[original_label]\n",
    "            new_label_mapping = self.new_label_mapping[remapped_label]\n",
    "            return new_label_mapping\n",
    "        else:\n",
    "            raise ValueError(f\"Label could not be extracted from path: {img_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "742c75bb-56ba-497e-8160-745d070907fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = ['data/wider/trainval_wider.json']\n",
    "test_file = ['data/wider/test_wider.json']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c07e8c-9d6a-4f00-9b72-dbb9f35f6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    # Filter out any None items in the batch\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    # If after filtering the batch is empty, handle this case by either returning an empty tensor or raising an exception\n",
    "    if len(batch) == 0:\n",
    "        raise ValueError(\"Batch is empty after filtering out None items.\")\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e188300a-7896-4ed7-ba20-549a3057fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(226, 226), interpolation=bilinear, max_size=None, antialias=warn)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = DataSet(train_file, augs = ['RandAugment'], img_size = 226, dataset = 'wider')\n",
    "train_dataset = DataSet(train_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "test_dataset = DataSet(test_file, augs = [], img_size = 226, dataset = 'wider')\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                         num_workers=num_workers, collate_fn=custom_collate)\n",
    "testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, collate_fn=custom_collate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b6bb60-dc13-4d86-b5a9-f84b376823dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, num_classes):\n",
    "    return np.eye(num_classes)[labels]\n",
    "\n",
    "def calculate_recall_multiclass(conf_matrix):\n",
    "    recalls = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)\n",
    "    recalls[np.isnan(recalls)] = 0  # Replace NaN with 0\n",
    "    return recalls\n",
    "\n",
    "def evaluate_model_with_gender_multiclass(pred, label, gender, num_classes):\n",
    "    predictions = pred.cpu()\n",
    "    true_labels = label.cpu()\n",
    "    gender = gender.cpu()\n",
    "\n",
    "    # Identify male and female indices based on the gender threshold\n",
    "    male_indices = np.where(gender >= 0.5)[0]\n",
    "    female_indices = np.where(gender < 0.5)[0]\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    one_hot_labels = one_hot_encode(true_labels, num_classes=num_classes)\n",
    "    one_hot_preds = one_hot_encode(predictions, num_classes=num_classes)\n",
    "\n",
    "    # Initialize recall arrays\n",
    "    male_recall = np.zeros(num_classes)\n",
    "    female_recall = np.zeros(num_classes)\n",
    "\n",
    "    # Extract predictions and labels for male and female indices\n",
    "    male_predictions = np.argmax(one_hot_preds[male_indices], axis=1)\n",
    "    female_predictions = np.argmax(one_hot_preds[female_indices], axis=1)\n",
    "    male_labels = np.argmax(one_hot_labels[male_indices], axis=1)\n",
    "    female_labels = np.argmax(one_hot_labels[female_indices], axis=1)\n",
    "\n",
    "    # Check if the class labels are within the expected range\n",
    "    assert (0 <= male_predictions.min() < num_classes) and (0 <= male_predictions.max() < num_classes), \"Invalid class indices in male predictions\"\n",
    "    assert (0 <= female_predictions.min() < num_classes) and (0 <= female_predictions.max() < num_classes), \"Invalid class indices in female predictions\"\n",
    "    assert (0 <= male_labels.min() < num_classes) and (0 <= male_labels.max() < num_classes), \"Invalid class indices in male labels\"\n",
    "    assert (0 <= female_labels.min() < num_classes) and (0 <= female_labels.max() < num_classes), \"Invalid class indices in female labels\"\n",
    "\n",
    "    # Calculate confusion matrices for each gender\n",
    "    male_conf_matrix = confusion_matrix(male_labels, male_predictions, labels=np.arange(num_classes))\n",
    "    female_conf_matrix = confusion_matrix(female_labels, female_predictions, labels=np.arange(num_classes))\n",
    "\n",
    "    # Calculate recall for each class and gender\n",
    "    male_recall[:len(male_conf_matrix)] = calculate_recall_multiclass(male_conf_matrix)\n",
    "    female_recall[:len(female_conf_matrix)] = calculate_recall_multiclass(female_conf_matrix)\n",
    "\n",
    "    return male_recall - female_recall, male_conf_matrix, female_conf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df5bc74-4a24-42a0-9ca4-a4e04861d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=256):\n",
    "        super(Critic, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)  # Outputting a single value for bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c18d2428-0165-453f-a3a9-341cb7cf0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_teacher(teacher, teacher_optimizer, teacher_loss_fn, critic, critic_optimizer, critic_loss_fn,\n",
    "                  lambda_factor, epsilon=epsilon, margin=margin, patience=teacher_patience, \n",
    "                  epochs=teacher_epochs, device=device, base_save_dir=base_save_dir):\n",
    "    \n",
    "    train_accuracies = []\n",
    "    train_disparities = []\n",
    "    train_mean_non_zero_abs_disparities = []\n",
    "    train_losses = []\n",
    "    train_main_losses = []\n",
    "    train_critic_losses = []\n",
    "    val_accuracies = []\n",
    "    val_disparities = []\n",
    "    val_mean_non_zero_abs_disparities = []\n",
    "    val_losses = []\n",
    "    val_main_losses = []\n",
    "    val_critic_losses = []\n",
    "    \n",
    "    patience_counter = 0 \n",
    "    best_val_accuracy = 0\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_mean_abs_disparity = 0\n",
    "    teacher_best_model_state = None\n",
    "\n",
    "    # Create a subdirectory for the current lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_{lambda_factor}')\n",
    "    os.makedirs(lambda_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Training Teacher with Lambda Value of {lambda_factor}')\n",
    "    \n",
    "    # Training and Validation Loop\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize metrics for each epoch\n",
    "        epoch_train_disparities = []\n",
    "        epoch_train_losses = []\n",
    "        epoch_train_accuracies = []\n",
    "        epoch_val_disparities = []\n",
    "        epoch_val_losses = []\n",
    "        epoch_val_accuracies = []\n",
    "    \n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Training\n",
    "        teacher.train()\n",
    "        for batch_data in tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs}, Training'):\n",
    "            # Load data to device\n",
    "            images = batch_data[\"img\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "            gender_scores = batch_data[\"target\"].to(device)\n",
    "    \n",
    "            # Forward pass through actor\n",
    "            teacher_output = teacher(images)\n",
    "            class_predictions = torch.argmax(teacher_output, dim=1)\n",
    "    \n",
    "            # Compute bias\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (class_predictions == labels).sum().item()\n",
    "            num_batches += 1\n",
    "            recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "            confusion_male += recall_diff[1]\n",
    "            confusion_female += recall_diff[2]\n",
    "            bias = np.mean(recall_diff[0])\n",
    "            bias_mean = torch.tensor([bias], device=device, dtype=torch.float32)\n",
    "    \n",
    "            critic_optimizer.zero_grad()\n",
    "            \n",
    "            for param in critic.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in teacher.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "            critic.train()\n",
    "            teacher.eval()\n",
    "            \n",
    "            critic_output = critic(teacher_output)\n",
    "            critic_loss = critic_loss_fn(critic_output, bias_mean)\n",
    "            critic_loss.backward(retain_graph=True)\n",
    "    \n",
    "            critic_optimizer.step()\n",
    "    \n",
    "            for param in critic.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in teacher.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            teacher.train()\n",
    "            critic.eval()\n",
    "    \n",
    "            teacher_optimizer.zero_grad()\n",
    "    \n",
    "            critic_output = critic(teacher_output)\n",
    "            main_loss = teacher_loss_fn(teacher_output, labels)\n",
    "    \n",
    "            combined_loss = max(1, lambda_factor * (abs(critic_output[0][0]) - epsilon + margin) + 1) * main_loss\n",
    "    \n",
    "            combined_loss.backward(retain_graph=True)\n",
    "            teacher_optimizer.step()\n",
    "    \n",
    "            # Calculate and accumulate metrics\n",
    "            accuracy = (class_predictions == labels).float().mean().item()\n",
    "            epoch_train_accuracies.append(accuracy)\n",
    "            epoch_train_disparities.append(bias)\n",
    "        \n",
    "            # Record the losses\n",
    "            epoch_train_losses.append((combined_loss.item(), main_loss.item(), critic_loss.item()))\n",
    "    \n",
    "        confusion_male /= num_batches\n",
    "        confusion_female /= num_batches\n",
    "    \n",
    "        # Calculate training metrics for the epoch\n",
    "        train_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "        train_non_zero_abs_values = np.abs(train_epoch_disparity[train_epoch_disparity != 0])\n",
    "        \n",
    "        # Store average training metrics for the epoch\n",
    "        train_accuracy = np.mean(epoch_train_accuracies)\n",
    "        train_disparity = np.mean(epoch_train_disparities)\n",
    "        train_mean_non_zero_abs_disparity = np.mean(train_non_zero_abs_values)\n",
    "        train_combined_loss = np.mean([x[0] for x in epoch_train_losses])\n",
    "        train_main_loss = np.mean([x[1] for x in epoch_train_losses])\n",
    "        train_critic_loss = np.mean([x[2] for x in epoch_train_losses])\n",
    "    \n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_disparities.append(train_disparity)\n",
    "        train_mean_non_zero_abs_disparities.append(train_mean_non_zero_abs_disparity)\n",
    "        train_losses.append(train_combined_loss)\n",
    "        train_main_losses.append(train_main_loss)\n",
    "        train_critic_losses.append(train_critic_loss)\n",
    "    \n",
    "        # Validation Phase\n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        teacher.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(testloader, desc=f'Epoch {epoch+1}/{epochs}, Validation'):\n",
    "                # Load data to device\n",
    "                images = batch_data[\"img\"].to(device)\n",
    "                labels = batch_data[\"label\"].to(device)\n",
    "                gender_scores = batch_data[\"target\"].to(device)\n",
    "        \n",
    "                # Forward pass\n",
    "                teacher_output = teacher(images)\n",
    "                val_critic_output = critic(teacher_output)\n",
    "                class_predictions = torch.argmax(teacher_output, dim=1)\n",
    "        \n",
    "                # Calculate and accumulate validation metrics\n",
    "                accuracy = (class_predictions == labels).float().mean().item()\n",
    "    \n",
    "                # Compute bias\n",
    "                num_batches += 1\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "                \n",
    "                # Calculate validation losses (similar to training losses)\n",
    "                batch_bias = np.mean(recall_diff[0])\n",
    "                mean_batch_bias = torch.tensor([batch_bias], device=device, dtype=torch.float32)\n",
    "                val_main_loss = teacher_loss_fn(teacher_output, labels)\n",
    "                val_critic_loss = critic_loss_fn(val_critic_output, mean_batch_bias)\n",
    "        \n",
    "                val_combined_loss = max(1, lambda_factor * (abs(val_critic_output[0][0]) - epsilon + margin) + 1) * val_main_loss\n",
    "    \n",
    "                epoch_val_accuracies.append(accuracy)\n",
    "                epoch_val_losses.append((val_combined_loss.item(), val_main_loss.item(), val_critic_loss.item()))\n",
    "                \n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "    \n",
    "            val_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_non_zero_abs_values = np.abs(val_epoch_disparity[val_epoch_disparity != 0])\n",
    "    \n",
    "            # Store average training metrics for the epoch\n",
    "            val_accuracy = np.mean(epoch_val_accuracies)\n",
    "            val_disparity = np.mean(epoch_val_disparities)\n",
    "            val_mean_non_zero_abs_disparity = np.mean(val_non_zero_abs_values)\n",
    "            val_combined_loss = np.mean([x[0] for x in epoch_val_losses])\n",
    "            val_main_loss = np.mean([x[1] for x in epoch_val_losses])\n",
    "            val_critic_loss = np.mean([x[2] for x in epoch_val_losses])\n",
    "        \n",
    "            val_accuracies.append(val_accuracy)\n",
    "            val_disparities.append(val_disparity)\n",
    "            val_mean_non_zero_abs_disparities.append(val_mean_non_zero_abs_disparity)\n",
    "            val_losses.append(val_combined_loss)\n",
    "            val_main_losses.append(val_main_loss)\n",
    "            val_critic_losses.append(val_critic_loss)\n",
    "\n",
    "            # Check if current validation combined loss is lower than the best combined loss\n",
    "        if val_combined_loss < best_val_loss:\n",
    "            best_val_loss = val_combined_loss\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_mean_non_zero_abs_disparity = val_mean_non_zero_abs_disparity\n",
    "        \n",
    "            # Create a mapping of class recall disparities\n",
    "            class_recall_mapping = {class_name: val_epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "        \n",
    "            teacher_best_model_state = {\n",
    "                'epoch': epoch,\n",
    "                'teacher_state_dict': teacher.state_dict(),\n",
    "                'critic_state_dict': critic.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'best_val_mean_abs_disparity': best_val_mean_non_zero_abs_disparity,\n",
    "                'class_recall_mapping': class_recall_mapping\n",
    "            }\n",
    "            save_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_{lambda_factor}.pth')\n",
    "            torch.save(teacher_best_model_state, save_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"TEACHER - Lambda {lambda_factor} - Epoch {epoch + 1} Metrics:\")\n",
    "        print(\"-\"*50)\n",
    "        print(f\"TRAINING Accuracy: {train_accuracy:.6f}, VALIDATION Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"TRAINING Disparity: {train_mean_non_zero_abs_disparity:.6f}, VALIDATION Disparity: {val_mean_non_zero_abs_disparity:.4f}\")\n",
    "        print(f\"TRAINING Combined Loss: {train_combined_loss:.6f}, VALIDATION Combined Loss: {val_combined_loss:.4f}\")\n",
    "        print(\"-\"*50 + \"\\n\")\n",
    "        # Print disparities by class label\n",
    "        for class_label, recall_diff in class_recall_mapping.items():\n",
    "            print(f\"Class {class_label}: Val Disparity = {recall_diff}\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "      \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot Training and Validation Accuracy\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(train_accuracies, label='Training Accuracy')\n",
    "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "        plt.title('Teacher Training and Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training and Validation Disparity\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(train_mean_non_zero_abs_disparities, label='Training Mean Absolute Disparity')\n",
    "        plt.plot(val_mean_non_zero_abs_disparities, label='Validation Mean Absolute Disparity')\n",
    "        plt.title('Teacher Training and Validation Mean Absolute Disparity')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Absolute Disparity')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(train_losses, label='Training Combined Loss')\n",
    "        plt.plot(train_main_losses, label='Training Main Loss')\n",
    "        plt.plot(train_critic_losses, label='Training Critic Loss')\n",
    "        plt.title('Teacher Training Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    \n",
    "        # Plot Validation Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(val_losses, label='Validation Combined Loss')\n",
    "        plt.plot(val_main_losses, label='Validation Main Loss')\n",
    "        plt.plot(val_critic_losses, label='Validation Critic Loss')\n",
    "        plt.title('Teacher Validation Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    best_epoch = teacher_best_model_state['epoch'] + 1 if teacher_best_model_state else epochs\n",
    "    print(f\"Finished Training TEACHER with lambda value of {lambda_factor}. Best epoch number: {best_epoch}\")\n",
    "\n",
    "    return teacher_best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2777235b-0ae2-47e8-a1a8-562402565000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_student(student, teacher, student_optimizer, student_loss_fn, critic, critic_optimizer, critic_loss_fn,\n",
    "                  lambda_factor, epsilon=epsilon, margin=margin, patience=student_patience, \n",
    "                  epochs=student_epochs, device=device, base_save_dir=base_save_dir):\n",
    "    \n",
    "    train_accuracies = []\n",
    "    train_disparities = []\n",
    "    train_mean_non_zero_abs_disparities = []\n",
    "    train_losses = []\n",
    "    train_main_losses = []\n",
    "    train_critic_losses = []\n",
    "    val_accuracies = []\n",
    "    val_disparities = []\n",
    "    val_mean_non_zero_abs_disparities = []\n",
    "    val_losses = []\n",
    "    val_main_losses = []\n",
    "    val_critic_losses = []\n",
    "    \n",
    "    patience_counter = 0 \n",
    "    best_val_accuracy = 0\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_mean_abs_disparity = 0\n",
    "    student_best_model_state = None\n",
    "\n",
    "    teacher.eval()\n",
    "    teacher.to(device)\n",
    "    \n",
    "    # Create a subdirectory for the current lambda_factor\n",
    "    lambda_dir = os.path.join(base_save_dir, f'STUDENT_lambda_{lambda_factor}')\n",
    "    os.makedirs(lambda_dir, exist_ok=True)\n",
    "\n",
    "    print(f'Training Student with Lambda Value of {lambda_factor}')\n",
    "\n",
    "    # Training and Validation Loop\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize metrics for each epoch\n",
    "        epoch_train_disparities = []\n",
    "        epoch_train_losses = []\n",
    "        epoch_train_accuracies = []\n",
    "        epoch_val_disparities = []\n",
    "        epoch_val_losses = []\n",
    "        epoch_val_accuracies = []\n",
    "    \n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        total_val_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        # Training\n",
    "        student.train()\n",
    "        for batch_data in tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs}, Training'):\n",
    "            # Load data to device\n",
    "            images = batch_data[\"img\"].to(device)\n",
    "            labels = batch_data[\"label\"].to(device)\n",
    "            gender_scores = batch_data[\"target\"].to(device)\n",
    "    \n",
    "            # Forward pass through actor\n",
    "            student_output = student(images)\n",
    "            class_predictions = torch.argmax(student_output, dim=1)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                teacher_outputs = teacher(images)\n",
    "                \n",
    "            # Compute bias\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (class_predictions == labels).sum().item()\n",
    "            num_batches += 1\n",
    "            recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "            confusion_male += recall_diff[1]\n",
    "            confusion_female += recall_diff[2]\n",
    "            bias = np.mean(recall_diff[0])\n",
    "            bias_mean = torch.tensor([bias], device=device, dtype=torch.float32)\n",
    "    \n",
    "            critic_optimizer.zero_grad()\n",
    "            \n",
    "            for param in critic.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in student.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "            critic.train()\n",
    "            student.eval()\n",
    "            \n",
    "            critic_output = critic(student_output)\n",
    "            critic_loss = critic_loss_fn(critic_output, bias_mean)\n",
    "            critic_loss.backward(retain_graph=True)\n",
    "    \n",
    "            critic_optimizer.step()\n",
    "    \n",
    "            for param in critic.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in student.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            student.train()\n",
    "            critic.eval()\n",
    "    \n",
    "            student_optimizer.zero_grad()\n",
    "    \n",
    "            critic_output = critic(student_output)\n",
    "            main_loss = student_loss_fn(student_output, labels)\n",
    "\n",
    "            kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)\n",
    "            \n",
    "            if kd_loss.ndim != 0:\n",
    "                kd_loss = kd_loss.sum()\n",
    "            else:\n",
    "                kd_loss = 0 \n",
    "            \n",
    "            combined_loss = alpha * kd_loss + (1 - alpha) * max(1, lambda_factor * (abs(critic_output[0][0]) - epsilon + margin) + 1) * main_loss\n",
    "    \n",
    "            combined_loss.backward(retain_graph=True)\n",
    "            student_optimizer.step()\n",
    "    \n",
    "            # Calculate and accumulate metrics\n",
    "            accuracy = (class_predictions == labels).float().mean().item()\n",
    "            epoch_train_accuracies.append(accuracy)\n",
    "            epoch_train_disparities.append(bias)\n",
    "        \n",
    "            # Record the losses\n",
    "            epoch_train_losses.append((combined_loss.item(), main_loss.item(), critic_loss.item()))\n",
    "    \n",
    "        confusion_male /= num_batches\n",
    "        confusion_female /= num_batches\n",
    "    \n",
    "        # Calculate training metrics for the epoch\n",
    "        train_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "        train_non_zero_abs_values = np.abs(train_epoch_disparity[train_epoch_disparity != 0])\n",
    "        \n",
    "        # Store average training metrics for the epoch\n",
    "        train_accuracy = np.mean(epoch_train_accuracies)\n",
    "        train_disparity = np.mean(epoch_train_disparities)\n",
    "        train_mean_non_zero_abs_disparity = np.mean(train_non_zero_abs_values)\n",
    "        train_combined_loss = np.mean([x[0] for x in epoch_train_losses])\n",
    "        train_main_loss = np.mean([x[1] for x in epoch_train_losses])\n",
    "        train_critic_loss = np.mean([x[2] for x in epoch_train_losses])\n",
    "    \n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_disparities.append(train_disparity)\n",
    "        train_mean_non_zero_abs_disparities.append(train_mean_non_zero_abs_disparity)\n",
    "        train_losses.append(train_combined_loss)\n",
    "        train_main_losses.append(train_main_loss)\n",
    "        train_critic_losses.append(train_critic_loss)\n",
    "    \n",
    "        # Validation Phase\n",
    "        confusion_male = np.zeros((num_classes, num_classes))\n",
    "        confusion_female = np.zeros((num_classes, num_classes))\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        student.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_data in tqdm(testloader, desc=f'Epoch {epoch+1}/{epochs}, Validation'):\n",
    "                # Load data to device\n",
    "                images = batch_data[\"img\"].to(device)\n",
    "                labels = batch_data[\"label\"].to(device)\n",
    "                gender_scores = batch_data[\"target\"].to(device)\n",
    "        \n",
    "                # Forward pass\n",
    "                student_output = student(images)\n",
    "                val_critic_output = critic(student_output)\n",
    "                class_predictions = torch.argmax(student_output, dim=1)\n",
    "                teacher_output = teacher(images)\n",
    "                \n",
    "                # Calculate and accumulate validation metrics\n",
    "                accuracy = (class_predictions == labels).float().mean().item()\n",
    "    \n",
    "                # Compute bias\n",
    "                num_batches += 1\n",
    "                recall_diff = evaluate_model_with_gender_multiclass(class_predictions, labels, gender_scores, num_classes=num_classes)\n",
    "                confusion_male += recall_diff[1]\n",
    "                confusion_female += recall_diff[2]\n",
    "                \n",
    "                # Calculate validation losses (similar to training losses)\n",
    "                batch_bias = np.mean(recall_diff[0])\n",
    "                mean_batch_bias = torch.tensor([batch_bias], device=device, dtype=torch.float32)\n",
    "                val_main_loss = student_loss_fn(student_output, labels)\n",
    "                val_critic_loss = critic_loss_fn(val_critic_output, mean_batch_bias)\n",
    "                kd_loss = tkd_kdloss(student_outputs, teacher_outputs, temperature=temperature)\n",
    "                \n",
    "                if val_kd_loss.ndim != 0:\n",
    "                    val_kd_loss = kd_loss.sum()\n",
    "                else:\n",
    "                    val_kd_loss = 0     \n",
    "                \n",
    "                val_combined_loss = alpha * val_kd_loss + (1 - alpha) * max(1, lambda_factor * (abs(val_critic_output[0][0]) - epsilon + margin) + 1) * val_main_loss\n",
    "    \n",
    "                epoch_val_accuracies.append(accuracy)\n",
    "                epoch_val_losses.append((val_combined_loss.item(), val_main_loss.item(), val_critic_loss.item()))\n",
    "                \n",
    "            confusion_male /= num_batches\n",
    "            confusion_female /= num_batches\n",
    "    \n",
    "            val_epoch_disparity = calculate_recall_multiclass(confusion_male) - calculate_recall_multiclass(confusion_female)\n",
    "            val_non_zero_abs_values = np.abs(val_epoch_disparity[val_epoch_disparity != 0])\n",
    "    \n",
    "            # Store average training metrics for the epoch\n",
    "            val_accuracy = np.mean(epoch_val_accuracies)\n",
    "            val_disparity = np.mean(epoch_val_disparities)\n",
    "            val_mean_non_zero_abs_disparity = np.mean(val_non_zero_abs_values)\n",
    "            val_combined_loss = np.mean([x[0] for x in epoch_val_losses])\n",
    "            val_main_loss = np.mean([x[1] for x in epoch_val_losses])\n",
    "            val_critic_loss = np.mean([x[2] for x in epoch_val_losses])\n",
    "        \n",
    "            val_accuracies.append(val_accuracy)\n",
    "            val_disparities.append(val_disparity)\n",
    "            val_mean_non_zero_abs_disparities.append(val_mean_non_zero_abs_disparity)\n",
    "            val_losses.append(val_combined_loss)\n",
    "            val_main_losses.append(val_main_loss)\n",
    "            val_critic_losses.append(val_critic_loss)\n",
    "\n",
    "            # Check if current validation combined loss is lower than the best combined loss\n",
    "        if val_combined_loss < best_val_loss:\n",
    "            best_val_loss = val_combined_loss\n",
    "            best_val_accuracy = val_accuracy\n",
    "            best_val_mean_non_zero_abs_disparity = val_mean_non_zero_abs_disparity\n",
    "        \n",
    "            # Create a mapping of class recall disparities\n",
    "            class_recall_mapping = {class_name: val_epoch_disparity[int(class_label)] for class_label, class_name in class_idx.items()}\n",
    "        \n",
    "            student_best_model_state = {\n",
    "                'epoch': epoch,\n",
    "                'student_state_dict': student.state_dict(),\n",
    "                'critic_state_dict': critic.state_dict(),\n",
    "                'best_val_loss': best_val_loss,\n",
    "                'best_val_accuracy': best_val_accuracy,\n",
    "                'best_val_mean_abs_disparity': best_val_mean_non_zero_abs_disparity,\n",
    "                'class_recall_mapping': class_recall_mapping\n",
    "            }\n",
    "            save_path = os.path.join(lambda_dir, f'STUDENT_best_model_lambda_{lambda_factor}.pth')\n",
    "            torch.save(student_best_model_state, save_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"STUDENT - Lambda {lambda_factor} - Epoch {epoch + 1} Metrics:\")\n",
    "        print(\"-\"*50)\n",
    "        print(f\"TRAINING Accuracy: {train_accuracy:.6f}, VALIDATION Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"TRAINING Disparity: {train_mean_non_zero_abs_disparity:.6f}, VALIDATION Disparity: {val_mean_non_zero_abs_disparity:.4f}\")\n",
    "        print(f\"TRAINING Combined Loss: {train_combined_loss:.6f}, VALIDATION Combined Loss: {val_combined_loss:.4f}\")\n",
    "        print(\"-\"*50 + \"\\n\")\n",
    "        # Print disparities by class label\n",
    "        for class_label, recall_diff in class_recall_mapping.items():\n",
    "            print(f\"Class {class_label}: Val Disparity = {recall_diff}\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "      \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        # Plot Training and Validation Accuracy\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(train_accuracies, label='Training Accuracy')\n",
    "        plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "        plt.title('Student Training and Validation Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training and Validation Disparity\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(train_mean_non_zero_abs_disparities, label='Training Mean Absolute Disparity')\n",
    "        plt.plot(val_mean_non_zero_abs_disparities, label='Validation Mean Absolute Disparity')\n",
    "        plt.title('Student Training and Validation Mean Absolute Disparity')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Mean Absolute Disparity')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot Training Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(train_losses, label='Training Combined Loss')\n",
    "        plt.plot(train_main_losses, label='Training Main Loss')\n",
    "        plt.plot(train_critic_losses, label='Training Critic Loss')\n",
    "        plt.title('Student Training Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "    \n",
    "        # Plot Validation Loss Components, Including Combined Loss\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(val_losses, label='Validation Combined Loss')\n",
    "        plt.plot(val_main_losses, label='Validation Main Loss')\n",
    "        plt.plot(val_critic_losses, label='Validation Critic Loss')\n",
    "        plt.title('Student Validation Loss Components')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    best_epoch = student_best_model_state['epoch'] + 1 if student_best_model_state else epochs\n",
    "    print(f\"Finished Training STUDENT with lambda value of {lambda_factor}. Best epoch number: {best_epoch}\")\n",
    "\n",
    "    return student_best_model_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69469e9d-e2f6-4ad7-882c-da526ce3676b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Teacher with Lambda Value of 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Training:   1%|▍                                                                                            | 1/192 [00:03<11:13,  3.53s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 14.73 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 265.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m teacher_loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m best_model_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_teacher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic_loss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mlambda_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmargin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_save_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m all_best_model_states[lambda_factor] \u001b[38;5;241m=\u001b[39m best_model_state\n",
      "Cell \u001b[0;32mIn[13], line 81\u001b[0m, in \u001b[0;36mtrain_teacher\u001b[0;34m(teacher, teacher_optimizer, teacher_loss_fn, critic, critic_optimizer, critic_loss_fn, lambda_factor, epsilon, margin, patience, epochs, device, base_save_dir)\u001b[0m\n\u001b[1;32m     79\u001b[0m critic_output \u001b[38;5;241m=\u001b[39m critic(teacher_output)\n\u001b[1;32m     80\u001b[0m critic_loss \u001b[38;5;241m=\u001b[39m critic_loss_fn(critic_output, bias_mean)\n\u001b[0;32m---> 81\u001b[0m \u001b[43mcritic_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m critic_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m critic\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 14.73 GiB memory in use. Of the allocated memory 14.32 GiB is allocated by PyTorch, and 265.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# TEACHER\n",
    "# Create dict to store best model states\n",
    "teacher_model_states_best = {}\n",
    "\n",
    "# Loop through the lambda_factor_list\n",
    "for lambda_factor in teacher_lambda_factor_list:\n",
    "    # Load EfficientNet B2 model for Teacher\n",
    "    teacher = models.efficientnet_b2(pretrained=True)\n",
    "    \n",
    "    # Determine the number of output features from the feature extractor part of EfficientNet B2\n",
    "    num_ftrs = teacher.classifier[1].in_features\n",
    "    \n",
    "    # Modify the classifier layer of the EfficientNet model to match your number of classes\n",
    "    teacher.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Move the EfficientNet model to the GPU\n",
    "    teacher = teacher.to(device)\n",
    "\n",
    "    # Initialize the Critic model\n",
    "    critic = Critic(input_size=num_classes).to(device)  # Adjust the input size based on your model's output\n",
    "    critic_optimizer = optim.Adam(critic.parameters(), lr=teacher_learning_rate)\n",
    "    critic_loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    # Redefine your main model optimizer if needed\n",
    "    teacher_optimizer = optim.Adam(teacher.parameters(), lr=teacher_learning_rate)\n",
    "    teacher_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    best_model_state = train_teacher(teacher, teacher_optimizer, teacher_loss_fn, critic, critic_optimizer, critic_loss_fn,\n",
    "                                   lambda_factor, epsilon, margin, teacher_patience, teacher_epochs, device, base_save_dir=base_save_dir)\n",
    "    all_best_model_states[lambda_factor] = best_model_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a59ae3e-ff0e-4b4b-a054-183eafd2e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STUDENT\n",
    "# Create dict to store best model states\n",
    "student_model_states_best = {}\n",
    "\n",
    "# load teacher model with lambda 0\n",
    "lambda_dir = os.path.join(base_save_dir, f'TEACHER_lambda_0')\n",
    "teacher_lambda_0_path = os.path.join(lambda_dir, f'TEACHER_best_model_lambda_0.pth')\n",
    "teacher = torch.load(teacher_lambda_0_path)\n",
    "\n",
    "# Loop through the lambda_factor_list\n",
    "for lambda_factor in student_lambda_factor_list:\n",
    "    # Load EfficientNet B0 model for Student\n",
    "    student = models.efficientnet_b0(pretrained=True)\n",
    "    \n",
    "    # Determine the number of output features from the feature extractor part of EfficientNet B0\n",
    "    num_ftrs = student.classifier[1].in_features  # This is the correct number of input features for your adversarial classifier\n",
    "    \n",
    "    # Modify the classifier layer of the EfficientNet model to match your number of classes\n",
    "    student.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "    \n",
    "    # Move the EfficientNet model to the GPU\n",
    "    student = student.to(device)\n",
    "\n",
    "    # Initialize the Critic model\n",
    "    critic = Critic(input_size=num_classes).to(device)  # Adjust the input size based on your model's output\n",
    "    critic_optimizer = optim.Adam(critic.parameters(), lr=student_learning_rate)\n",
    "    critic_loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    # Redefine your main model optimizer if needed\n",
    "    student_optimizer = optim.Adam(student.parameters(), lr=student_learning_rate)\n",
    "    student_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model\n",
    "    best_model_state = train_student(student, tacher, student_optimizer, student_loss_fn, critic, critic_optimizer, critic_loss_fn,\n",
    "                                   lambda_factor, epsilon, margin, student_patience, student_epochs, device, base_save_dir=base_save_dir)\n",
    "    student_model_states_best[lambda_factor] = best_model_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d96960-7dec-414b-a22d-2044772c2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "collective_save_path = os.path.join(base_save_dir, 'student_model_states_best.pth')\n",
    "\n",
    "# Load the saved model states\n",
    "student_model_states_best = torch.load(collective_save_path)\n",
    "\n",
    "# Example: Accessing the best_val_accuracy for a specific lambda value\n",
    "lambda_value = 50\n",
    "    if lambda_value in all_best_model_states:\n",
    "        best_model_state = all_best_model_states[lambda_value]\n",
    "        best_val_accuracy = best_model_state['best_val_accuracy']\n",
    "        print(f\"Best validation accuracy for lambda {lambda_value}: {best_val_accuracy}\")\n",
    "    else:\n",
    "        print(f\"No model state found for lambda {lambda_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8d2be-db17-4f32-ac35-594f77f550ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836d70b-6686-4e3a-a9e6-e5266f7227ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53514c47-79ca-481f-a3d9-8b9f3abffbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
